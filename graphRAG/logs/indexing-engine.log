2025-10-06 13:40:00.0708 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0845 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0907 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0968 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0029 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0090 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0151 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0214 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0277 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0339 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0342 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0348 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:50:20.0918 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0036 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0163 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0394 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0541 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0653 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0769 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0965 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0077 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0195 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0197 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0201 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 14:14:03.0354 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0443 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0545 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0637 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0726 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0823 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0825 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0830 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:16:08.0881 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:15.0000 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:21.0317 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:27.0579 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:33.0720 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:45.0257 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:16:45.0484 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:45.0695 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:45.0900 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0111 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0334 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0570 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0786 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0996 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0217 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0429 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0642 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0644 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0648 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:28:57.0838 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:57.0925 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0012 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0104 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0188 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0277 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0279 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0283 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:29:56.0688 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:56.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:56.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:56.0944 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0027 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0106 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0108 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0111 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:38:56.0458 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:38:58.0336 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:38:59.0491 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:01.0940 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:03.0885 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:04.0799 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:05.0748 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:07.0016 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:09.0331 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:11.0469 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:12.0576 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:14.0331 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:14.0423 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:14.0628 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:45:49.0342 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:45:50.0062 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:50.0465 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:50.0938 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:51.0521 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:52.0344 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:52.0642 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:53.0235 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:53.0810 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:54.0713 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0189 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0644 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0692 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0755 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Not Found

2025-10-06 14:57:55.0057 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:57:55.0844 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:56.0539 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:58.0376 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:59.0030 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:59.0874 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:00.0546 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:01.0185 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:04.0887 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:05.0884 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:06.0457 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:07.0765 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:07.0798 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:09.0629 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Not Found

2025-10-06 15:10:03.0475 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:10:03.0660 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:03.0821 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0081 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0237 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0649 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0836 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0992 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0155 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0423 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0584 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0781 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0783 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0787 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences


2025-10-06 15:19:45.0612 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:19:45.0835 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0064 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0245 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0457 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0671 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0877 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0084 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0284 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0503 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0711 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:48.0298 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:48.0302 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:48.0309 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:09.0948 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:24:10.0164 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0374 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0577 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0781 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0417 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0603 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0788 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0958 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0143 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0347 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0351 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0357 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:35.0880 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:26:36.0061 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0259 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0471 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0642 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0819 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0027 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0202 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0411 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0588 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0797 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:38.0055 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:38.0060 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:38.0065 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0154 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:28:23.0351 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0552 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0735 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0938 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0105 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0269 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0446 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0648 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0132 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0330 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0334 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0339 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0098 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:30:48.0293 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0499 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0756 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0928 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0115 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0282 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0453 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0625 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0797 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0982 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:50.0180 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:50.0184 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:50.0190 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:50.0951 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:31:51.0289 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:51.0467 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:51.0670 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:51.0841 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0061 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0266 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0467 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0667 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0918 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0155 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0367 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0371 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0377 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:18.0656 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:32:18.0985 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0194 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0408 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0580 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0789 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0990 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0220 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0436 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0727 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0963 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:21.0160 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:21.0164 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:21.0170 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0162 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:33:02.0385 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0596 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0783 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0983 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0192 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0394 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0574 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0747 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0171 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0341 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0345 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0351 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local



2025-10-06 15:36:11.0146 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:36:11.0373 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:11.0556 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:11.0919 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0140 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0382 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0595 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0789 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0198 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0402 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0656 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0661 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0668 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:41.0230 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:36:41.0486 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:41.0698 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:41.0879 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0100 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0451 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0680 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0862 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0041 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0269 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0515 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0521 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0528 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:39:39.0094 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:39:39.0125 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0152 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0177 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0202 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0227 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0255 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0280 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0305 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0329 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0354 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0379 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0384 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0391 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0218 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:40:51.0248 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0300 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0326 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0351 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0379 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0404 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0429 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0453 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0478 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0503 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0508 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0516 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-09 19:49:43.0592 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.563s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.563s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.563s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:43.0725 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.413999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.413999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.413999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:43.0831 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.306999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.306999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.306999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:43.0952 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0073 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0209 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0213 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0221 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0096 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m54.058s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m54.058s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m54.058s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0249 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0426 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0707 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.435s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.435s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.435s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0898 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0903 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0912 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-12 14:55:52.0998 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
2025-10-12 14:58:55.0909 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
2025-10-12 15:02:00.0263 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
2025-10-12 15:05:09.0062 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
2025-10-12 15:19:26.0722 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds
2025-10-12 15:53:55.0563 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds
2025-10-12 16:08:52.0894 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 16:08:55.0354 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 16:08:55.0354 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 16:08:55.0355 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "DESCRIPTION",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 512,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "SEVERITY_LEVEL",
            "ORGANIZATION",
            "WORKPLACE",
            "WORK_PROCESS",
            "DESCRIPTION_SUMMARY"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": null,
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": null,
        "text_prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": null,
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 16:08:55.0356 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 16:08:55.0356 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 16:08:55.0356 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:08:55.0356 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 16:08:55.0357 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 16:08:55.0357 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 16:08:55.0369 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 16:08:55.0369 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 16:08:55.0372 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 16:08:55.0372 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:08:55.0372 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-10-12 16:08:55.0372 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.txt$
2025-10-12 16:08:55.0373 - ERROR - graphrag.index.run.run_pipeline - error running workflow load_input_documents
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 26, in run_workflow
    output = await load_input_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 43, in load_input_documents
    return await create_input(config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/factory.py", line 37, in create_input
    result = await loader(config, storage)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/text.py", line 35, in load_text
    return await load_files(load_file, config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/util.py", line 34, in load_files
    raise ValueError(msg)
ValueError: No InputFileType.text files found in /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:08:55.0375 - ERROR - graphrag.api.index - Workflow load_input_documents completed with errors
2025-10-12 16:08:55.0376 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 16:23:25.0727 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 16:23:27.0435 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 16:23:27.0435 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 16:23:27.0436 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "DESCRIPTION",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 512,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "SEVERITY_LEVEL",
            "ORGANIZATION",
            "WORKPLACE",
            "WORK_PROCESS",
            "DESCRIPTION_SUMMARY"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": null,
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": null,
        "text_prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": null,
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 16:23:27.0437 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 16:23:27.0437 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 16:23:27.0439 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 16:23:27.0439 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 16:23:27.0441 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 16:23:27.0441 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:23:27.0441 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-10-12 16:23:27.0442 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.txt$
2025-10-12 16:23:27.0442 - ERROR - graphrag.index.run.run_pipeline - error running workflow load_input_documents
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 26, in run_workflow
    output = await load_input_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 43, in load_input_documents
    return await create_input(config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/factory.py", line 37, in create_input
    result = await loader(config, storage)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/text.py", line 35, in load_text
    return await load_files(load_file, config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/util.py", line 34, in load_files
    raise ValueError(msg)
ValueError: No InputFileType.text files found in /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:23:27.0445 - ERROR - graphrag.api.index - Workflow load_input_documents completed with errors
2025-10-12 16:23:27.0445 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 16:44:56.0670 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 16:44:58.0328 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 16:44:58.0328 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 16:44:58.0329 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "DESCRIPTION",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 512,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "SEVERITY_LEVEL",
            "ORGANIZATION",
            "WORKPLACE",
            "WORK_PROCESS",
            "DESCRIPTION_SUMMARY"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": null,
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": null,
        "text_prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": null,
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 16:44:58.0330 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 16:44:58.0330 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 16:44:58.0330 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:44:58.0331 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 16:44:58.0331 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 16:44:58.0331 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 16:44:58.0333 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 16:44:58.0333 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 16:44:58.0335 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 16:44:58.0335 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:44:58.0335 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-10-12 16:44:58.0336 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.txt$
2025-10-12 16:44:58.0337 - ERROR - graphrag.index.run.run_pipeline - error running workflow load_input_documents
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 26, in run_workflow
    output = await load_input_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 43, in load_input_documents
    return await create_input(config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/factory.py", line 37, in create_input
    result = await loader(config, storage)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/text.py", line 35, in load_text
    return await load_files(load_file, config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/util.py", line 34, in load_files
    raise ValueError(msg)
ValueError: No InputFileType.text files found in /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:44:58.0339 - ERROR - graphrag.api.index - Workflow load_input_documents completed with errors
2025-10-12 16:44:58.0339 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 17:07:27.0193 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 17:07:29.0138 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 17:07:29.0138 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 17:07:29.0139 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 17:07:29.0140 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 17:07:29.0140 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 17:07:29.0140 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:07:29.0140 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 17:07:29.0141 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 17:07:29.0141 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 17:07:29.0143 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 17:07:29.0143 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 17:07:29.0145 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 17:07:29.0145 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:07:29.0145 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 17:07:29.0145 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:07:29.0146 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 17:07:29.0167 - WARNING - graphrag.index.input.util - text_column text not found in csv file dev_sample.csv
2025-10-12 17:07:29.0168 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 17:07:29.0169 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 80
2025-10-12 17:07:29.0169 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 80
2025-10-12 17:07:29.0204 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 17:07:29.0235 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 17:07:29.0236 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 17:07:29.0270 - ERROR - graphrag.index.run.run_pipeline - error running workflow create_base_text_units
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pandas/_libs/index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'text'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/create_base_text_units.py", line 35, in run_workflow
    output = create_base_text_units(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/create_base_text_units.py", line 68, in create_base_text_units
    zip(*[sort[col] for col in ["id", "text"]], strict=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/create_base_text_units.py", line 68, in <listcomp>
    zip(*[sort[col] for col in ["id", "text"]], strict=True)
          ~~~~^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/frame.py", line 4113, in __getitem__
    indexer = self.columns.get_loc(key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3819, in get_loc
    raise KeyError(key) from err
KeyError: 'text'
2025-10-12 17:07:29.0275 - ERROR - graphrag.api.index - Workflow create_base_text_units completed with errors
2025-10-12 17:07:29.0275 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 17:20:48.0277 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 17:20:50.0037 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 17:20:50.0037 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 17:20:50.0037 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 17:20:50.0039 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 17:20:50.0039 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 17:20:50.0039 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:20:50.0039 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 17:20:50.0040 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 17:20:50.0040 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 17:20:50.0043 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 17:20:50.0043 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 17:20:50.0045 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 17:20:50.0045 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:20:50.0045 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 17:20:50.0046 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:20:50.0046 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 17:20:50.0066 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 17:20:50.0067 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 80
2025-10-12 17:20:50.0067 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 80
2025-10-12 17:20:50.0082 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 17:20:50.0110 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 17:20:50.0110 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 17:20:50.0153 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 68 documents
2025-10-12 17:20:50.0155 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/68
2025-10-12 17:20:50.0155 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/68
2025-10-12 17:20:50.0156 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/68
2025-10-12 17:20:50.0157 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/68
2025-10-12 17:20:50.0157 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/68
2025-10-12 17:20:50.0158 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/68
2025-10-12 17:20:50.0158 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/68
2025-10-12 17:20:50.0159 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/68
2025-10-12 17:20:50.0159 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/68
2025-10-12 17:20:50.0160 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/68
2025-10-12 17:20:50.0160 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/68
2025-10-12 17:20:50.0161 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/68
2025-10-12 17:20:50.0162 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/68
2025-10-12 17:20:50.0162 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/68
2025-10-12 17:20:50.0163 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/68
2025-10-12 17:20:50.0163 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/68
2025-10-12 17:20:50.0164 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/68
2025-10-12 17:20:50.0164 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/68
2025-10-12 17:20:50.0165 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/68
2025-10-12 17:20:50.0165 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/68
2025-10-12 17:20:50.0166 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/68
2025-10-12 17:20:50.0166 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/68
2025-10-12 17:20:50.0167 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/68
2025-10-12 17:20:50.0167 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/68
2025-10-12 17:20:50.0168 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/68
2025-10-12 17:20:50.0168 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/68
2025-10-12 17:20:50.0169 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/68
2025-10-12 17:20:50.0169 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/68
2025-10-12 17:20:50.0170 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/68
2025-10-12 17:20:50.0170 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/68
2025-10-12 17:20:50.0171 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/68
2025-10-12 17:20:50.0171 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/68
2025-10-12 17:20:50.0172 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/68
2025-10-12 17:20:50.0172 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/68
2025-10-12 17:20:50.0173 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/68
2025-10-12 17:20:50.0173 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/68
2025-10-12 17:20:50.0174 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/68
2025-10-12 17:20:50.0174 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/68
2025-10-12 17:20:50.0175 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/68
2025-10-12 17:20:50.0175 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/68
2025-10-12 17:20:50.0176 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/68
2025-10-12 17:20:50.0176 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/68
2025-10-12 17:20:50.0177 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/68
2025-10-12 17:20:50.0177 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/68
2025-10-12 17:20:50.0178 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/68
2025-10-12 17:20:50.0178 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/68
2025-10-12 17:20:50.0179 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/68
2025-10-12 17:20:50.0179 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/68
2025-10-12 17:20:50.0180 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/68
2025-10-12 17:20:50.0181 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/68
2025-10-12 17:20:50.0181 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/68
2025-10-12 17:20:50.0182 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/68
2025-10-12 17:20:50.0182 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/68
2025-10-12 17:20:50.0183 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/68
2025-10-12 17:20:50.0183 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/68
2025-10-12 17:20:50.0184 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/68
2025-10-12 17:20:50.0184 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/68
2025-10-12 17:20:50.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/68
2025-10-12 17:20:50.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/68
2025-10-12 17:20:50.0186 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/68
2025-10-12 17:20:50.0186 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/68
2025-10-12 17:20:50.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/68
2025-10-12 17:20:50.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/68
2025-10-12 17:20:50.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/68
2025-10-12 17:20:50.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/68
2025-10-12 17:20:50.0189 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/68
2025-10-12 17:20:50.0189 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/68
2025-10-12 17:20:50.0190 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/68
2025-10-12 17:20:50.0199 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-12 17:20:50.0199 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-12 17:20:50.0203 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-12 17:20:50.0203 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 17:20:50.0214 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:20:50.0227 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-12 17:20:50.0227 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-12 17:20:50.0231 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-12 17:20:50.0232 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:20:50.0241 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/extract_graph
2025-10-12 17:20:53.0297 - INFO - graphrag.logger.progress - extract graph progress: 1/68
2025-10-12 17:20:53.0300 - INFO - graphrag.logger.progress - extract graph progress: 2/68
2025-10-12 17:20:53.0301 - INFO - graphrag.logger.progress - extract graph progress: 3/68
2025-10-12 17:20:53.0303 - INFO - graphrag.logger.progress - extract graph progress: 4/68
2025-10-12 17:20:53.0306 - INFO - graphrag.logger.progress - extract graph progress: 5/68
2025-10-12 17:20:53.0307 - INFO - graphrag.logger.progress - extract graph progress: 6/68
2025-10-12 17:20:53.0309 - INFO - graphrag.logger.progress - extract graph progress: 7/68
2025-10-12 17:20:53.0311 - INFO - graphrag.logger.progress - extract graph progress: 8/68
2025-10-12 17:20:53.0313 - INFO - graphrag.logger.progress - extract graph progress: 9/68
2025-10-12 17:20:53.0315 - INFO - graphrag.logger.progress - extract graph progress: 10/68
2025-10-12 17:20:53.0317 - INFO - graphrag.logger.progress - extract graph progress: 11/68
2025-10-12 17:20:53.0319 - INFO - graphrag.logger.progress - extract graph progress: 12/68
2025-10-12 17:20:53.0321 - INFO - graphrag.logger.progress - extract graph progress: 13/68
2025-10-12 17:20:56.0195 - INFO - graphrag.logger.progress - extract graph progress: 14/68
2025-10-12 17:20:56.0197 - INFO - graphrag.logger.progress - extract graph progress: 15/68
2025-10-12 17:20:56.0199 - INFO - graphrag.logger.progress - extract graph progress: 16/68
2025-10-12 17:20:56.0201 - INFO - graphrag.logger.progress - extract graph progress: 17/68
2025-10-12 17:20:56.0203 - INFO - graphrag.logger.progress - extract graph progress: 18/68
2025-10-12 17:20:56.0205 - INFO - graphrag.logger.progress - extract graph progress: 19/68
2025-10-12 17:20:56.0207 - INFO - graphrag.logger.progress - extract graph progress: 20/68
2025-10-12 17:20:56.0209 - INFO - graphrag.logger.progress - extract graph progress: 21/68
2025-10-12 17:20:56.0211 - INFO - graphrag.logger.progress - extract graph progress: 22/68
2025-10-12 17:20:59.0282 - INFO - graphrag.logger.progress - extract graph progress: 23/68
2025-10-12 17:20:59.0287 - INFO - graphrag.logger.progress - extract graph progress: 24/68
2025-10-12 17:20:59.0291 - INFO - graphrag.logger.progress - extract graph progress: 25/68
2025-10-12 17:20:59.0294 - INFO - graphrag.logger.progress - extract graph progress: 26/68
2025-10-12 17:20:59.0298 - INFO - graphrag.logger.progress - extract graph progress: 27/68
2025-10-12 17:20:59.0301 - INFO - graphrag.logger.progress - extract graph progress: 28/68
2025-10-12 17:20:59.0304 - INFO - graphrag.logger.progress - extract graph progress: 29/68
2025-10-12 17:20:59.0307 - INFO - graphrag.logger.progress - extract graph progress: 30/68
2025-10-12 17:20:59.0310 - INFO - graphrag.logger.progress - extract graph progress: 31/68
2025-10-12 17:20:59.0312 - INFO - graphrag.logger.progress - extract graph progress: 32/68
2025-10-12 17:20:59.0313 - INFO - graphrag.logger.progress - extract graph progress: 33/68
2025-10-12 17:20:59.0316 - INFO - graphrag.logger.progress - extract graph progress: 34/68
2025-10-12 17:20:59.0319 - INFO - graphrag.logger.progress - extract graph progress: 35/68
2025-10-12 17:20:59.0322 - INFO - graphrag.logger.progress - extract graph progress: 36/68
2025-10-12 17:20:59.0324 - INFO - graphrag.logger.progress - extract graph progress: 37/68
2025-10-12 17:20:59.0328 - INFO - graphrag.logger.progress - extract graph progress: 38/68
2025-10-12 17:20:59.0330 - INFO - graphrag.logger.progress - extract graph progress: 39/68
2025-10-12 17:20:59.0332 - INFO - graphrag.logger.progress - extract graph progress: 40/68
2025-10-12 17:20:59.0333 - INFO - graphrag.logger.progress - extract graph progress: 41/68
2025-10-12 17:20:59.0336 - INFO - graphrag.logger.progress - extract graph progress: 42/68
2025-10-12 17:20:59.0339 - INFO - graphrag.logger.progress - extract graph progress: 43/68
2025-10-12 17:20:59.0342 - INFO - graphrag.logger.progress - extract graph progress: 44/68
2025-10-12 17:20:59.0345 - INFO - graphrag.logger.progress - extract graph progress: 45/68
2025-10-12 17:21:03.0591 - INFO - graphrag.logger.progress - extract graph progress: 46/68
2025-10-12 17:21:03.0593 - INFO - graphrag.logger.progress - extract graph progress: 47/68
2025-10-12 17:21:03.0595 - INFO - graphrag.logger.progress - extract graph progress: 48/68
2025-10-12 17:21:03.0597 - INFO - graphrag.logger.progress - extract graph progress: 49/68
2025-10-12 17:21:03.0598 - INFO - graphrag.logger.progress - extract graph progress: 50/68
2025-10-12 17:21:03.0600 - INFO - graphrag.logger.progress - extract graph progress: 51/68
2025-10-12 17:21:03.0602 - INFO - graphrag.logger.progress - extract graph progress: 52/68
2025-10-12 17:21:03.0604 - INFO - graphrag.logger.progress - extract graph progress: 53/68
2025-10-12 17:21:03.0606 - INFO - graphrag.logger.progress - extract graph progress: 54/68
2025-10-12 17:21:03.0608 - INFO - graphrag.logger.progress - extract graph progress: 55/68
2025-10-12 17:21:03.0610 - INFO - graphrag.logger.progress - extract graph progress: 56/68
2025-10-12 17:21:03.0612 - INFO - graphrag.logger.progress - extract graph progress: 57/68
2025-10-12 17:21:03.0614 - INFO - graphrag.logger.progress - extract graph progress: 58/68
2025-10-12 17:21:03.0618 - INFO - graphrag.logger.progress - extract graph progress: 59/68
2025-10-12 17:21:03.0622 - INFO - graphrag.logger.progress - extract graph progress: 60/68
2025-10-12 17:21:03.0625 - INFO - graphrag.logger.progress - extract graph progress: 61/68
2025-10-12 17:21:03.0629 - INFO - graphrag.logger.progress - extract graph progress: 62/68
2025-10-12 17:21:03.0634 - INFO - graphrag.logger.progress - extract graph progress: 63/68
2025-10-12 17:21:03.0638 - INFO - graphrag.logger.progress - extract graph progress: 64/68
2025-10-12 17:21:03.0642 - INFO - graphrag.logger.progress - extract graph progress: 65/68
2025-10-12 17:21:03.0646 - INFO - graphrag.logger.progress - extract graph progress: 66/68
2025-10-12 17:21:03.0650 - INFO - graphrag.logger.progress - extract graph progress: 67/68
2025-10-12 17:21:03.0653 - INFO - graphrag.logger.progress - extract graph progress: 68/68
2025-10-12 17:21:03.0674 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/summarize_descriptions
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/23
2025-10-12 17:21:04.0499 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/23
2025-10-12 17:21:04.0512 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-10-12 17:21:04.0512 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-10-12 17:21:04.0519 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-10-12 17:21:04.0519 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0524 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0540 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-10-12 17:21:04.0540 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-10-12 17:21:04.0547 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-10-12 17:21:04.0547 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-10-12 17:21:04.0547 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-10-12 17:21:04.0547 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-10-12 17:21:04.0547 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0551 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0574 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-10-12 17:21:04.0574 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-10-12 17:21:04.0579 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-10-12 17:21:04.0579 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:21:04.0583 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0586 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0604 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-10-12 17:21:04.0604 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-10-12 17:21:04.0609 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-10-12 17:21:04.0609 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0613 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0616 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-10-12 17:21:04.0625 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 5
2025-10-12 17:21:04.0646 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/community_reporting
2025-10-12 17:21:10.0323 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/1
2025-10-12 17:21:10.0331 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-10-12 17:21:10.0331 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-10-12 17:21:10.0337 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-10-12 17:21:10.0337 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-10-12 17:21:10.0337 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:21:10.0341 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:10.0345 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-10-12 17:21:10.0350 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-10-12 17:21:10.0350 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-10-12 17:21:10.0372 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 17:21:10.0372 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/text_embedding
2025-10-12 17:21:10.0376 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 14 inputs via 14 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 17:21:23.0050 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-10-12 17:21:23.0177 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-10-12 17:21:23.0179 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 17:21:23.0180 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 17:21:23.0247 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-10-12 17:21:23.0308 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-10-12 17:21:23.0310 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 17:21:23.0311 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 68 inputs via 68 snippets using 5 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 17:21:38.0615 - INFO - graphrag.logger.progress - generate embeddings progress: 1/5
2025-10-12 17:21:54.0730 - INFO - graphrag.logger.progress - generate embeddings progress: 2/5
2025-10-12 17:22:11.0917 - INFO - graphrag.logger.progress - generate embeddings progress: 3/5
2025-10-12 17:22:30.0282 - INFO - graphrag.logger.progress - generate embeddings progress: 4/5
2025-10-12 17:22:33.0887 - INFO - graphrag.logger.progress - generate embeddings progress: 5/5
2025-10-12 17:22:33.0935 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-10-12 17:22:33.0935 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-10-12 17:22:33.0948 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-10-12 17:22:33.0953 - INFO - graphrag.cli.index - All workflows completed successfully.
2025-10-12 18:13:32.0877 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 18:13:34.0933 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 18:13:34.0933 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 18:13:34.0934 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "EQUIPMENT",
            "LOCATION",
            "ORGANIZATION",
            "DATE"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 18:13:34.0935 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 18:13:34.0935 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 18:13:34.0935 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:13:34.0935 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 18:13:34.0936 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 18:13:34.0936 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 18:13:34.0938 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 18:13:34.0938 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 18:13:34.0940 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 18:13:34.0940 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:13:34.0940 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 18:13:34.0940 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:13:34.0941 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 18:13:35.0084 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 18:13:35.0084 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 718
2025-10-12 18:13:35.0084 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 718
2025-10-12 18:13:35.0117 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 18:13:35.0151 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 18:13:35.0151 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:13:35.0212 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 527 documents
2025-10-12 18:13:35.0213 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/527
2025-10-12 18:13:35.0214 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/527
2025-10-12 18:13:35.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/527
2025-10-12 18:13:35.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/527
2025-10-12 18:13:35.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/527
2025-10-12 18:13:35.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/527
2025-10-12 18:13:35.0217 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/527
2025-10-12 18:13:35.0218 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/527
2025-10-12 18:13:35.0218 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/527
2025-10-12 18:13:35.0219 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/527
2025-10-12 18:13:35.0219 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/527
2025-10-12 18:13:35.0220 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/527
2025-10-12 18:13:35.0220 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/527
2025-10-12 18:13:35.0221 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/527
2025-10-12 18:13:35.0221 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/527
2025-10-12 18:13:35.0222 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/527
2025-10-12 18:13:35.0222 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/527
2025-10-12 18:13:35.0223 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/527
2025-10-12 18:13:35.0223 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/527
2025-10-12 18:13:35.0224 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/527
2025-10-12 18:13:35.0224 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/527
2025-10-12 18:13:35.0225 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/527
2025-10-12 18:13:35.0225 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/527
2025-10-12 18:13:35.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/527
2025-10-12 18:13:35.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/527
2025-10-12 18:13:35.0227 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/527
2025-10-12 18:13:35.0227 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/527
2025-10-12 18:13:35.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/527
2025-10-12 18:13:35.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/527
2025-10-12 18:13:35.0229 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/527
2025-10-12 18:13:35.0229 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/527
2025-10-12 18:13:35.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/527
2025-10-12 18:13:35.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/527
2025-10-12 18:13:35.0231 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/527
2025-10-12 18:13:35.0231 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/527
2025-10-12 18:13:35.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/527
2025-10-12 18:13:35.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/527
2025-10-12 18:13:35.0233 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/527
2025-10-12 18:13:35.0233 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/527
2025-10-12 18:13:35.0234 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/527
2025-10-12 18:13:35.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/527
2025-10-12 18:13:35.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/527
2025-10-12 18:13:35.0236 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/527
2025-10-12 18:13:35.0236 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/527
2025-10-12 18:13:35.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/527
2025-10-12 18:13:35.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/527
2025-10-12 18:13:35.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/527
2025-10-12 18:13:35.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/527
2025-10-12 18:13:35.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/527
2025-10-12 18:13:35.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/527
2025-10-12 18:13:35.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/527
2025-10-12 18:13:35.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/527
2025-10-12 18:13:35.0241 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/527
2025-10-12 18:13:35.0241 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/527
2025-10-12 18:13:35.0242 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/527
2025-10-12 18:13:35.0242 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/527
2025-10-12 18:13:35.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/527
2025-10-12 18:13:35.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/527
2025-10-12 18:13:35.0244 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/527
2025-10-12 18:13:35.0244 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/527
2025-10-12 18:13:35.0245 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/527
2025-10-12 18:13:35.0245 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/527
2025-10-12 18:13:35.0246 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/527
2025-10-12 18:13:35.0246 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/527
2025-10-12 18:13:35.0247 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/527
2025-10-12 18:13:35.0247 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/527
2025-10-12 18:13:35.0248 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/527
2025-10-12 18:13:35.0248 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/527
2025-10-12 18:13:35.0249 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  69/527
2025-10-12 18:13:35.0249 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  70/527
2025-10-12 18:13:35.0250 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  71/527
2025-10-12 18:13:35.0250 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  72/527
2025-10-12 18:13:35.0251 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  73/527
2025-10-12 18:13:35.0251 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  74/527
2025-10-12 18:13:35.0252 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  75/527
2025-10-12 18:13:35.0252 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  76/527
2025-10-12 18:13:35.0253 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  77/527
2025-10-12 18:13:35.0253 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  78/527
2025-10-12 18:13:35.0254 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  79/527
2025-10-12 18:13:35.0254 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  80/527
2025-10-12 18:13:35.0255 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  81/527
2025-10-12 18:13:35.0255 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  82/527
2025-10-12 18:13:35.0256 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  83/527
2025-10-12 18:13:35.0256 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  84/527
2025-10-12 18:13:35.0257 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  85/527
2025-10-12 18:13:35.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  86/527
2025-10-12 18:13:35.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  87/527
2025-10-12 18:13:35.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  88/527
2025-10-12 18:13:35.0259 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  89/527
2025-10-12 18:13:35.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  90/527
2025-10-12 18:13:35.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  91/527
2025-10-12 18:13:35.0261 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  92/527
2025-10-12 18:13:35.0261 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  93/527
2025-10-12 18:13:35.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  94/527
2025-10-12 18:13:35.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  95/527
2025-10-12 18:13:35.0263 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  96/527
2025-10-12 18:13:35.0263 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  97/527
2025-10-12 18:13:35.0264 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  98/527
2025-10-12 18:13:35.0264 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  99/527
2025-10-12 18:13:35.0265 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  100/527
2025-10-12 18:13:35.0265 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  101/527
2025-10-12 18:13:35.0266 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  102/527
2025-10-12 18:13:35.0266 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  103/527
2025-10-12 18:13:35.0267 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  104/527
2025-10-12 18:13:35.0267 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  105/527
2025-10-12 18:13:35.0268 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  106/527
2025-10-12 18:13:35.0268 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  107/527
2025-10-12 18:13:35.0269 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  108/527
2025-10-12 18:13:35.0269 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  109/527
2025-10-12 18:13:35.0270 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  110/527
2025-10-12 18:13:35.0270 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  111/527
2025-10-12 18:13:35.0271 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  112/527
2025-10-12 18:13:35.0271 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  113/527
2025-10-12 18:13:35.0272 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  114/527
2025-10-12 18:13:35.0272 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  115/527
2025-10-12 18:13:35.0273 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  116/527
2025-10-12 18:13:35.0273 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  117/527
2025-10-12 18:13:35.0274 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  118/527
2025-10-12 18:13:35.0274 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  119/527
2025-10-12 18:13:35.0275 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  120/527
2025-10-12 18:13:35.0275 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  121/527
2025-10-12 18:13:35.0276 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  122/527
2025-10-12 18:13:35.0276 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  123/527
2025-10-12 18:13:35.0277 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  124/527
2025-10-12 18:13:35.0277 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  125/527
2025-10-12 18:13:35.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  126/527
2025-10-12 18:13:35.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  127/527
2025-10-12 18:13:35.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  128/527
2025-10-12 18:13:35.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  129/527
2025-10-12 18:13:35.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  130/527
2025-10-12 18:13:35.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  131/527
2025-10-12 18:13:35.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  132/527
2025-10-12 18:13:35.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  133/527
2025-10-12 18:13:35.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  134/527
2025-10-12 18:13:35.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  135/527
2025-10-12 18:13:35.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  136/527
2025-10-12 18:13:35.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  137/527
2025-10-12 18:13:35.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  138/527
2025-10-12 18:13:35.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  139/527
2025-10-12 18:13:35.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  140/527
2025-10-12 18:13:35.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  141/527
2025-10-12 18:13:35.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  142/527
2025-10-12 18:13:35.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  143/527
2025-10-12 18:13:35.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  144/527
2025-10-12 18:13:35.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  145/527
2025-10-12 18:13:35.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  146/527
2025-10-12 18:13:35.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  147/527
2025-10-12 18:13:35.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  148/527
2025-10-12 18:13:35.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  149/527
2025-10-12 18:13:35.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  150/527
2025-10-12 18:13:35.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  151/527
2025-10-12 18:13:35.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  152/527
2025-10-12 18:13:35.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  153/527
2025-10-12 18:13:35.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  154/527
2025-10-12 18:13:35.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  155/527
2025-10-12 18:13:35.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  156/527
2025-10-12 18:13:35.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  157/527
2025-10-12 18:13:35.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  158/527
2025-10-12 18:13:35.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  159/527
2025-10-12 18:13:35.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  160/527
2025-10-12 18:13:35.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  161/527
2025-10-12 18:13:35.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  162/527
2025-10-12 18:13:35.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  163/527
2025-10-12 18:13:35.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  164/527
2025-10-12 18:13:35.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  165/527
2025-10-12 18:13:35.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  166/527
2025-10-12 18:13:35.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  167/527
2025-10-12 18:13:35.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  168/527
2025-10-12 18:13:35.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  169/527
2025-10-12 18:13:35.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  170/527
2025-10-12 18:13:35.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  171/527
2025-10-12 18:13:35.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  172/527
2025-10-12 18:13:35.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  173/527
2025-10-12 18:13:35.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  174/527
2025-10-12 18:13:35.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  175/527
2025-10-12 18:13:35.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  176/527
2025-10-12 18:13:35.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  177/527
2025-10-12 18:13:35.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  178/527
2025-10-12 18:13:35.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  179/527
2025-10-12 18:13:35.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  180/527
2025-10-12 18:13:35.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  181/527
2025-10-12 18:13:35.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  182/527
2025-10-12 18:13:35.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  183/527
2025-10-12 18:13:35.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  184/527
2025-10-12 18:13:35.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  185/527
2025-10-12 18:13:35.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  186/527
2025-10-12 18:13:35.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  187/527
2025-10-12 18:13:35.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  188/527
2025-10-12 18:13:35.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  189/527
2025-10-12 18:13:35.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  190/527
2025-10-12 18:13:35.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  191/527
2025-10-12 18:13:35.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  192/527
2025-10-12 18:13:35.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  193/527
2025-10-12 18:13:35.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  194/527
2025-10-12 18:13:35.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  195/527
2025-10-12 18:13:35.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  196/527
2025-10-12 18:13:35.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  197/527
2025-10-12 18:13:35.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  198/527
2025-10-12 18:13:35.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  199/527
2025-10-12 18:13:35.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  200/527
2025-10-12 18:13:35.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  201/527
2025-10-12 18:13:35.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  202/527
2025-10-12 18:13:35.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  203/527
2025-10-12 18:13:35.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  204/527
2025-10-12 18:13:35.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  205/527
2025-10-12 18:13:35.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  206/527
2025-10-12 18:13:35.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  207/527
2025-10-12 18:13:35.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  208/527
2025-10-12 18:13:35.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  209/527
2025-10-12 18:13:35.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  210/527
2025-10-12 18:13:35.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  211/527
2025-10-12 18:13:35.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  212/527
2025-10-12 18:13:35.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  213/527
2025-10-12 18:13:35.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  214/527
2025-10-12 18:13:35.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  215/527
2025-10-12 18:13:35.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  216/527
2025-10-12 18:13:35.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  217/527
2025-10-12 18:13:35.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  218/527
2025-10-12 18:13:35.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  219/527
2025-10-12 18:13:35.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  220/527
2025-10-12 18:13:35.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  221/527
2025-10-12 18:13:35.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  222/527
2025-10-12 18:13:35.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  223/527
2025-10-12 18:13:35.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  224/527
2025-10-12 18:13:35.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  225/527
2025-10-12 18:13:35.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  226/527
2025-10-12 18:13:35.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  227/527
2025-10-12 18:13:35.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  228/527
2025-10-12 18:13:35.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  229/527
2025-10-12 18:13:35.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  230/527
2025-10-12 18:13:35.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  231/527
2025-10-12 18:13:35.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  232/527
2025-10-12 18:13:35.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  233/527
2025-10-12 18:13:35.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  234/527
2025-10-12 18:13:35.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  235/527
2025-10-12 18:13:35.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  236/527
2025-10-12 18:13:35.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  237/527
2025-10-12 18:13:35.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  238/527
2025-10-12 18:13:35.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  239/527
2025-10-12 18:13:35.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  240/527
2025-10-12 18:13:35.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  241/527
2025-10-12 18:13:35.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  242/527
2025-10-12 18:13:35.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  243/527
2025-10-12 18:13:35.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  244/527
2025-10-12 18:13:35.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  245/527
2025-10-12 18:13:35.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  246/527
2025-10-12 18:13:35.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  247/527
2025-10-12 18:13:35.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  248/527
2025-10-12 18:13:35.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  249/527
2025-10-12 18:13:35.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  250/527
2025-10-12 18:13:35.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  251/527
2025-10-12 18:13:35.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  252/527
2025-10-12 18:13:35.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  253/527
2025-10-12 18:13:35.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  254/527
2025-10-12 18:13:35.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  255/527
2025-10-12 18:13:35.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  256/527
2025-10-12 18:13:35.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  257/527
2025-10-12 18:13:35.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  258/527
2025-10-12 18:13:35.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  259/527
2025-10-12 18:13:35.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  260/527
2025-10-12 18:13:35.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  261/527
2025-10-12 18:13:35.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  262/527
2025-10-12 18:13:35.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  263/527
2025-10-12 18:13:35.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  264/527
2025-10-12 18:13:35.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  265/527
2025-10-12 18:13:35.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  266/527
2025-10-12 18:13:35.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  267/527
2025-10-12 18:13:35.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  268/527
2025-10-12 18:13:35.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  269/527
2025-10-12 18:13:35.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  270/527
2025-10-12 18:13:35.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  271/527
2025-10-12 18:13:35.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  272/527
2025-10-12 18:13:35.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  273/527
2025-10-12 18:13:35.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  274/527
2025-10-12 18:13:35.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  275/527
2025-10-12 18:13:35.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  276/527
2025-10-12 18:13:35.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  277/527
2025-10-12 18:13:35.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  278/527
2025-10-12 18:13:35.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  279/527
2025-10-12 18:13:35.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  280/527
2025-10-12 18:13:35.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  281/527
2025-10-12 18:13:35.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  282/527
2025-10-12 18:13:35.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  283/527
2025-10-12 18:13:35.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  284/527
2025-10-12 18:13:35.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  285/527
2025-10-12 18:13:35.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  286/527
2025-10-12 18:13:35.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  287/527
2025-10-12 18:13:35.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  288/527
2025-10-12 18:13:35.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  289/527
2025-10-12 18:13:35.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  290/527
2025-10-12 18:13:35.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  291/527
2025-10-12 18:13:35.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  292/527
2025-10-12 18:13:35.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  293/527
2025-10-12 18:13:35.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  294/527
2025-10-12 18:13:35.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  295/527
2025-10-12 18:13:35.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  296/527
2025-10-12 18:13:35.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  297/527
2025-10-12 18:13:35.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  298/527
2025-10-12 18:13:35.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  299/527
2025-10-12 18:13:35.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  300/527
2025-10-12 18:13:35.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  301/527
2025-10-12 18:13:35.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  302/527
2025-10-12 18:13:35.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  303/527
2025-10-12 18:13:35.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  304/527
2025-10-12 18:13:35.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  305/527
2025-10-12 18:13:35.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  306/527
2025-10-12 18:13:35.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  307/527
2025-10-12 18:13:35.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  308/527
2025-10-12 18:13:35.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  309/527
2025-10-12 18:13:35.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  310/527
2025-10-12 18:13:35.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  311/527
2025-10-12 18:13:35.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  312/527
2025-10-12 18:13:35.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  313/527
2025-10-12 18:13:35.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  314/527
2025-10-12 18:13:35.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  315/527
2025-10-12 18:13:35.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  316/527
2025-10-12 18:13:35.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  317/527
2025-10-12 18:13:35.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  318/527
2025-10-12 18:13:35.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  319/527
2025-10-12 18:13:35.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  320/527
2025-10-12 18:13:35.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  321/527
2025-10-12 18:13:35.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  322/527
2025-10-12 18:13:35.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  323/527
2025-10-12 18:13:35.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  324/527
2025-10-12 18:13:35.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  325/527
2025-10-12 18:13:35.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  326/527
2025-10-12 18:13:35.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  327/527
2025-10-12 18:13:35.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  328/527
2025-10-12 18:13:35.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  329/527
2025-10-12 18:13:35.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  330/527
2025-10-12 18:13:35.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  331/527
2025-10-12 18:13:35.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  332/527
2025-10-12 18:13:35.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  333/527
2025-10-12 18:13:35.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  334/527
2025-10-12 18:13:35.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  335/527
2025-10-12 18:13:35.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  336/527
2025-10-12 18:13:35.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  337/527
2025-10-12 18:13:35.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  338/527
2025-10-12 18:13:35.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  339/527
2025-10-12 18:13:35.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  340/527
2025-10-12 18:13:35.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  341/527
2025-10-12 18:13:35.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  342/527
2025-10-12 18:13:35.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  343/527
2025-10-12 18:13:35.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  344/527
2025-10-12 18:13:35.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  345/527
2025-10-12 18:13:35.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  346/527
2025-10-12 18:13:35.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  347/527
2025-10-12 18:13:35.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  348/527
2025-10-12 18:13:35.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  349/527
2025-10-12 18:13:35.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  350/527
2025-10-12 18:13:35.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  351/527
2025-10-12 18:13:35.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  352/527
2025-10-12 18:13:35.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  353/527
2025-10-12 18:13:35.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  354/527
2025-10-12 18:13:35.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  355/527
2025-10-12 18:13:35.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  356/527
2025-10-12 18:13:35.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  357/527
2025-10-12 18:13:35.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  358/527
2025-10-12 18:13:35.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  359/527
2025-10-12 18:13:35.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  360/527
2025-10-12 18:13:35.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  361/527
2025-10-12 18:13:35.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  362/527
2025-10-12 18:13:35.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  363/527
2025-10-12 18:13:35.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  364/527
2025-10-12 18:13:35.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  365/527
2025-10-12 18:13:35.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  366/527
2025-10-12 18:13:35.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  367/527
2025-10-12 18:13:35.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  368/527
2025-10-12 18:13:35.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  369/527
2025-10-12 18:13:35.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  370/527
2025-10-12 18:13:35.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  371/527
2025-10-12 18:13:35.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  372/527
2025-10-12 18:13:35.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  373/527
2025-10-12 18:13:35.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  374/527
2025-10-12 18:13:35.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  375/527
2025-10-12 18:13:35.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  376/527
2025-10-12 18:13:35.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  377/527
2025-10-12 18:13:35.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  378/527
2025-10-12 18:13:35.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  379/527
2025-10-12 18:13:35.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  380/527
2025-10-12 18:13:35.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  381/527
2025-10-12 18:13:35.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  382/527
2025-10-12 18:13:35.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  383/527
2025-10-12 18:13:35.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  384/527
2025-10-12 18:13:35.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  385/527
2025-10-12 18:13:35.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  386/527
2025-10-12 18:13:35.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  387/527
2025-10-12 18:13:35.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  388/527
2025-10-12 18:13:35.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  389/527
2025-10-12 18:13:35.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  390/527
2025-10-12 18:13:35.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  391/527
2025-10-12 18:13:35.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  392/527
2025-10-12 18:13:35.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  393/527
2025-10-12 18:13:35.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  394/527
2025-10-12 18:13:35.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  395/527
2025-10-12 18:13:35.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  396/527
2025-10-12 18:13:35.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  397/527
2025-10-12 18:13:35.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  398/527
2025-10-12 18:13:35.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  399/527
2025-10-12 18:13:35.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  400/527
2025-10-12 18:13:35.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  401/527
2025-10-12 18:13:35.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  402/527
2025-10-12 18:13:35.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  403/527
2025-10-12 18:13:35.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  404/527
2025-10-12 18:13:35.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  405/527
2025-10-12 18:13:35.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  406/527
2025-10-12 18:13:35.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  407/527
2025-10-12 18:13:35.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  408/527
2025-10-12 18:13:35.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  409/527
2025-10-12 18:13:35.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  410/527
2025-10-12 18:13:35.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  411/527
2025-10-12 18:13:35.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  412/527
2025-10-12 18:13:35.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  413/527
2025-10-12 18:13:35.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  414/527
2025-10-12 18:13:35.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  415/527
2025-10-12 18:13:35.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  416/527
2025-10-12 18:13:35.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  417/527
2025-10-12 18:13:35.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  418/527
2025-10-12 18:13:35.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  419/527
2025-10-12 18:13:35.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  420/527
2025-10-12 18:13:35.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  421/527
2025-10-12 18:13:35.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  422/527
2025-10-12 18:13:35.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  423/527
2025-10-12 18:13:35.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  424/527
2025-10-12 18:13:35.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  425/527
2025-10-12 18:13:35.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  426/527
2025-10-12 18:13:35.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  427/527
2025-10-12 18:13:35.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  428/527
2025-10-12 18:13:35.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  429/527
2025-10-12 18:13:35.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  430/527
2025-10-12 18:13:35.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  431/527
2025-10-12 18:13:35.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  432/527
2025-10-12 18:13:35.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  433/527
2025-10-12 18:13:35.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  434/527
2025-10-12 18:13:35.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  435/527
2025-10-12 18:13:35.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  436/527
2025-10-12 18:13:35.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  437/527
2025-10-12 18:13:35.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  438/527
2025-10-12 18:13:35.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  439/527
2025-10-12 18:13:35.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  440/527
2025-10-12 18:13:35.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  441/527
2025-10-12 18:13:35.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  442/527
2025-10-12 18:13:35.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  443/527
2025-10-12 18:13:35.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  444/527
2025-10-12 18:13:35.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  445/527
2025-10-12 18:13:35.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  446/527
2025-10-12 18:13:35.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  447/527
2025-10-12 18:13:35.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  448/527
2025-10-12 18:13:35.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  449/527
2025-10-12 18:13:35.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  450/527
2025-10-12 18:13:35.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  451/527
2025-10-12 18:13:35.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  452/527
2025-10-12 18:13:35.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  453/527
2025-10-12 18:13:35.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  454/527
2025-10-12 18:13:35.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  455/527
2025-10-12 18:13:35.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  456/527
2025-10-12 18:13:35.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  457/527
2025-10-12 18:13:35.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  458/527
2025-10-12 18:13:35.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  459/527
2025-10-12 18:13:35.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  460/527
2025-10-12 18:13:35.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  461/527
2025-10-12 18:13:35.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  462/527
2025-10-12 18:13:35.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  463/527
2025-10-12 18:13:35.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  464/527
2025-10-12 18:13:35.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  465/527
2025-10-12 18:13:35.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  466/527
2025-10-12 18:13:35.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  467/527
2025-10-12 18:13:35.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  468/527
2025-10-12 18:13:35.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  469/527
2025-10-12 18:13:35.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  470/527
2025-10-12 18:13:35.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  471/527
2025-10-12 18:13:35.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  472/527
2025-10-12 18:13:35.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  473/527
2025-10-12 18:13:35.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  474/527
2025-10-12 18:13:35.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  475/527
2025-10-12 18:13:35.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  476/527
2025-10-12 18:13:35.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  477/527
2025-10-12 18:13:35.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  478/527
2025-10-12 18:13:35.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  479/527
2025-10-12 18:13:35.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  480/527
2025-10-12 18:13:35.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  481/527
2025-10-12 18:13:35.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  482/527
2025-10-12 18:13:35.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  483/527
2025-10-12 18:13:35.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  484/527
2025-10-12 18:13:35.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  485/527
2025-10-12 18:13:35.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  486/527
2025-10-12 18:13:35.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  487/527
2025-10-12 18:13:35.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  488/527
2025-10-12 18:13:35.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  489/527
2025-10-12 18:13:35.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  490/527
2025-10-12 18:13:35.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  491/527
2025-10-12 18:13:35.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  492/527
2025-10-12 18:13:35.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  493/527
2025-10-12 18:13:35.0672 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  494/527
2025-10-12 18:13:35.0673 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  495/527
2025-10-12 18:13:35.0674 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  496/527
2025-10-12 18:13:35.0674 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  497/527
2025-10-12 18:13:35.0675 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  498/527
2025-10-12 18:13:35.0675 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  499/527
2025-10-12 18:13:35.0676 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  500/527
2025-10-12 18:13:35.0676 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  501/527
2025-10-12 18:13:35.0677 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  502/527
2025-10-12 18:13:35.0677 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  503/527
2025-10-12 18:13:35.0678 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  504/527
2025-10-12 18:13:35.0679 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  505/527
2025-10-12 18:13:35.0679 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  506/527
2025-10-12 18:13:35.0680 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  507/527
2025-10-12 18:13:35.0680 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  508/527
2025-10-12 18:13:35.0681 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  509/527
2025-10-12 18:13:35.0681 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  510/527
2025-10-12 18:13:35.0682 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  511/527
2025-10-12 18:13:35.0682 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  512/527
2025-10-12 18:13:35.0683 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  513/527
2025-10-12 18:13:35.0683 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  514/527
2025-10-12 18:13:35.0684 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  515/527
2025-10-12 18:13:35.0684 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  516/527
2025-10-12 18:13:35.0685 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  517/527
2025-10-12 18:13:35.0685 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  518/527
2025-10-12 18:13:35.0686 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  519/527
2025-10-12 18:13:35.0687 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  520/527
2025-10-12 18:13:35.0687 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  521/527
2025-10-12 18:13:35.0688 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  522/527
2025-10-12 18:13:35.0688 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  523/527
2025-10-12 18:13:35.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  524/527
2025-10-12 18:13:35.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  525/527
2025-10-12 18:13:35.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  526/527
2025-10-12 18:13:35.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  527/527
2025-10-12 18:13:35.0713 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-12 18:13:35.0713 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-12 18:13:35.0717 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-12 18:13:35.0717 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:13:35.0736 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:13:35.0776 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-12 18:13:35.0776 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-12 18:13:35.0780 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-12 18:13:35.0781 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:13:35.0799 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/extract_graph
2025-10-12 18:13:44.0170 - INFO - graphrag.logger.progress - extract graph progress: 1/527
2025-10-12 18:13:44.0175 - INFO - graphrag.logger.progress - extract graph progress: 2/527
2025-10-12 18:13:44.0179 - INFO - graphrag.logger.progress - extract graph progress: 3/527
2025-10-12 18:13:44.0184 - INFO - graphrag.logger.progress - extract graph progress: 4/527
2025-10-12 18:13:44.0188 - INFO - graphrag.logger.progress - extract graph progress: 5/527
2025-10-12 18:13:44.0192 - INFO - graphrag.logger.progress - extract graph progress: 6/527
2025-10-12 18:13:44.0196 - INFO - graphrag.logger.progress - extract graph progress: 7/527
2025-10-12 18:13:44.0200 - INFO - graphrag.logger.progress - extract graph progress: 8/527
2025-10-12 18:13:44.0203 - INFO - graphrag.logger.progress - extract graph progress: 9/527
2025-10-12 18:13:44.0206 - INFO - graphrag.logger.progress - extract graph progress: 10/527
2025-10-12 18:13:44.0210 - INFO - graphrag.logger.progress - extract graph progress: 11/527
2025-10-12 18:13:44.0214 - INFO - graphrag.logger.progress - extract graph progress: 12/527
2025-10-12 18:13:44.0218 - INFO - graphrag.logger.progress - extract graph progress: 13/527
2025-10-12 18:13:44.0222 - INFO - graphrag.logger.progress - extract graph progress: 14/527
2025-10-12 18:13:44.0225 - INFO - graphrag.logger.progress - extract graph progress: 15/527
2025-10-12 18:13:44.0228 - INFO - graphrag.logger.progress - extract graph progress: 16/527
2025-10-12 18:13:44.0231 - INFO - graphrag.logger.progress - extract graph progress: 17/527
2025-10-12 18:13:44.0234 - INFO - graphrag.logger.progress - extract graph progress: 18/527
2025-10-12 18:13:44.0238 - INFO - graphrag.logger.progress - extract graph progress: 19/527
2025-10-12 18:13:44.0242 - INFO - graphrag.logger.progress - extract graph progress: 20/527
2025-10-12 18:13:44.0244 - INFO - graphrag.logger.progress - extract graph progress: 21/527
2025-10-12 18:13:44.0246 - INFO - graphrag.logger.progress - extract graph progress: 22/527
2025-10-12 18:13:44.0249 - INFO - graphrag.logger.progress - extract graph progress: 23/527
2025-10-12 18:13:44.0251 - INFO - graphrag.logger.progress - extract graph progress: 24/527
2025-10-12 18:13:44.0255 - INFO - graphrag.logger.progress - extract graph progress: 25/527
2025-10-12 18:13:44.0258 - INFO - graphrag.logger.progress - extract graph progress: 26/527
2025-10-12 18:13:44.0261 - INFO - graphrag.logger.progress - extract graph progress: 27/527
2025-10-12 18:13:44.0265 - INFO - graphrag.logger.progress - extract graph progress: 28/527
2025-10-12 18:13:44.0269 - INFO - graphrag.logger.progress - extract graph progress: 29/527
2025-10-12 18:13:44.0273 - INFO - graphrag.logger.progress - extract graph progress: 30/527
2025-10-12 18:13:56.0513 - INFO - graphrag.logger.progress - extract graph progress: 31/527
2025-10-12 18:13:56.0518 - INFO - graphrag.logger.progress - extract graph progress: 32/527
2025-10-12 18:13:56.0520 - INFO - graphrag.logger.progress - extract graph progress: 33/527
2025-10-12 18:13:56.0523 - INFO - graphrag.logger.progress - extract graph progress: 34/527
2025-10-12 18:13:56.0527 - INFO - graphrag.logger.progress - extract graph progress: 35/527
2025-10-12 18:13:56.0531 - INFO - graphrag.logger.progress - extract graph progress: 36/527
2025-10-12 18:13:56.0534 - INFO - graphrag.logger.progress - extract graph progress: 37/527
2025-10-12 18:13:56.0538 - INFO - graphrag.logger.progress - extract graph progress: 38/527
2025-10-12 18:13:56.0542 - INFO - graphrag.logger.progress - extract graph progress: 39/527
2025-10-12 18:13:56.0547 - INFO - graphrag.logger.progress - extract graph progress: 40/527
2025-10-12 18:13:56.0550 - INFO - graphrag.logger.progress - extract graph progress: 41/527
2025-10-12 18:13:56.0552 - INFO - graphrag.logger.progress - extract graph progress: 42/527
2025-10-12 18:13:56.0555 - INFO - graphrag.logger.progress - extract graph progress: 43/527
2025-10-12 18:13:56.0559 - INFO - graphrag.logger.progress - extract graph progress: 44/527
2025-10-12 18:13:56.0563 - INFO - graphrag.logger.progress - extract graph progress: 45/527
2025-10-12 18:13:56.0567 - INFO - graphrag.logger.progress - extract graph progress: 46/527
2025-10-12 18:13:56.0572 - INFO - graphrag.logger.progress - extract graph progress: 47/527
2025-10-12 18:13:56.0576 - INFO - graphrag.logger.progress - extract graph progress: 48/527
2025-10-12 18:13:56.0580 - INFO - graphrag.logger.progress - extract graph progress: 49/527
2025-10-12 18:13:56.0584 - INFO - graphrag.logger.progress - extract graph progress: 50/527
2025-10-12 18:13:56.0588 - INFO - graphrag.logger.progress - extract graph progress: 51/527
2025-10-12 18:13:56.0591 - INFO - graphrag.logger.progress - extract graph progress: 52/527
2025-10-12 18:13:56.0594 - INFO - graphrag.logger.progress - extract graph progress: 53/527
2025-10-12 18:13:56.0598 - INFO - graphrag.logger.progress - extract graph progress: 54/527
2025-10-12 18:13:56.0603 - INFO - graphrag.logger.progress - extract graph progress: 55/527
2025-10-12 18:14:16.0973 - INFO - graphrag.logger.progress - extract graph progress: 56/527
2025-10-12 18:14:16.0976 - INFO - graphrag.logger.progress - extract graph progress: 57/527
2025-10-12 18:14:16.0979 - INFO - graphrag.logger.progress - extract graph progress: 58/527
2025-10-12 18:14:16.0981 - INFO - graphrag.logger.progress - extract graph progress: 59/527
2025-10-12 18:14:16.0983 - INFO - graphrag.logger.progress - extract graph progress: 60/527
2025-10-12 18:14:16.0985 - INFO - graphrag.logger.progress - extract graph progress: 61/527
2025-10-12 18:14:16.0987 - INFO - graphrag.logger.progress - extract graph progress: 62/527
2025-10-12 18:14:16.0989 - INFO - graphrag.logger.progress - extract graph progress: 63/527
2025-10-12 18:14:16.0991 - INFO - graphrag.logger.progress - extract graph progress: 64/527
2025-10-12 18:14:16.0994 - INFO - graphrag.logger.progress - extract graph progress: 65/527
2025-10-12 18:14:16.0996 - INFO - graphrag.logger.progress - extract graph progress: 66/527
2025-10-12 18:14:16.0998 - INFO - graphrag.logger.progress - extract graph progress: 67/527
2025-10-12 18:14:17.0002 - INFO - graphrag.logger.progress - extract graph progress: 68/527
2025-10-12 18:14:17.0004 - INFO - graphrag.logger.progress - extract graph progress: 69/527
2025-10-12 18:14:17.0007 - INFO - graphrag.logger.progress - extract graph progress: 70/527
2025-10-12 18:14:17.0009 - INFO - graphrag.logger.progress - extract graph progress: 71/527
2025-10-12 18:14:17.0011 - INFO - graphrag.logger.progress - extract graph progress: 72/527
2025-10-12 18:14:17.0013 - INFO - graphrag.logger.progress - extract graph progress: 73/527
2025-10-12 18:14:17.0015 - INFO - graphrag.logger.progress - extract graph progress: 74/527
2025-10-12 18:14:17.0017 - INFO - graphrag.logger.progress - extract graph progress: 75/527
2025-10-12 18:14:17.0019 - INFO - graphrag.logger.progress - extract graph progress: 76/527
2025-10-12 18:14:17.0021 - INFO - graphrag.logger.progress - extract graph progress: 77/527
2025-10-12 18:14:17.0023 - INFO - graphrag.logger.progress - extract graph progress: 78/527
2025-10-12 18:14:17.0025 - INFO - graphrag.logger.progress - extract graph progress: 79/527
2025-10-12 18:14:17.0026 - INFO - graphrag.logger.progress - extract graph progress: 80/527
2025-10-12 18:14:17.0028 - INFO - graphrag.logger.progress - extract graph progress: 81/527
2025-10-12 18:14:17.0031 - INFO - graphrag.logger.progress - extract graph progress: 82/527
2025-10-12 18:14:17.0032 - INFO - graphrag.logger.progress - extract graph progress: 83/527
2025-10-12 18:14:17.0035 - INFO - graphrag.logger.progress - extract graph progress: 84/527
2025-10-12 18:14:17.0036 - INFO - graphrag.logger.progress - extract graph progress: 85/527
2025-10-12 18:14:17.0039 - INFO - graphrag.logger.progress - extract graph progress: 86/527
2025-10-12 18:14:17.0041 - INFO - graphrag.logger.progress - extract graph progress: 87/527
2025-10-12 18:14:17.0043 - INFO - graphrag.logger.progress - extract graph progress: 88/527
2025-10-12 18:14:17.0045 - INFO - graphrag.logger.progress - extract graph progress: 89/527
2025-10-12 18:14:17.0047 - INFO - graphrag.logger.progress - extract graph progress: 90/527
2025-10-12 18:14:17.0049 - INFO - graphrag.logger.progress - extract graph progress: 91/527
2025-10-12 18:14:17.0051 - INFO - graphrag.logger.progress - extract graph progress: 92/527
2025-10-12 18:14:17.0053 - INFO - graphrag.logger.progress - extract graph progress: 93/527
2025-10-12 18:14:17.0055 - INFO - graphrag.logger.progress - extract graph progress: 94/527
2025-10-12 18:14:17.0057 - INFO - graphrag.logger.progress - extract graph progress: 95/527
2025-10-12 18:14:17.0059 - INFO - graphrag.logger.progress - extract graph progress: 96/527
2025-10-12 18:14:17.0062 - INFO - graphrag.logger.progress - extract graph progress: 97/527
2025-10-12 18:14:17.0064 - INFO - graphrag.logger.progress - extract graph progress: 98/527
2025-10-12 18:14:17.0065 - INFO - graphrag.logger.progress - extract graph progress: 99/527
2025-10-12 18:14:17.0067 - INFO - graphrag.logger.progress - extract graph progress: 100/527
2025-10-12 18:14:17.0069 - INFO - graphrag.logger.progress - extract graph progress: 101/527
2025-10-12 18:14:17.0071 - INFO - graphrag.logger.progress - extract graph progress: 102/527
2025-10-12 18:14:17.0073 - INFO - graphrag.logger.progress - extract graph progress: 103/527
2025-10-12 18:14:17.0075 - INFO - graphrag.logger.progress - extract graph progress: 104/527
2025-10-12 18:14:17.0077 - INFO - graphrag.logger.progress - extract graph progress: 105/527
2025-10-12 18:14:17.0079 - INFO - graphrag.logger.progress - extract graph progress: 106/527
2025-10-12 18:14:17.0081 - INFO - graphrag.logger.progress - extract graph progress: 107/527
2025-10-12 18:14:17.0083 - INFO - graphrag.logger.progress - extract graph progress: 108/527
2025-10-12 18:14:17.0086 - INFO - graphrag.logger.progress - extract graph progress: 109/527
2025-10-12 18:14:17.0088 - INFO - graphrag.logger.progress - extract graph progress: 110/527
2025-10-12 18:14:17.0090 - INFO - graphrag.logger.progress - extract graph progress: 111/527
2025-10-12 18:14:17.0092 - INFO - graphrag.logger.progress - extract graph progress: 112/527
2025-10-12 18:14:17.0094 - INFO - graphrag.logger.progress - extract graph progress: 113/527
2025-10-12 18:14:17.0096 - INFO - graphrag.logger.progress - extract graph progress: 114/527
2025-10-12 18:14:17.0098 - INFO - graphrag.logger.progress - extract graph progress: 115/527
2025-10-12 18:14:17.0100 - INFO - graphrag.logger.progress - extract graph progress: 116/527
2025-10-12 18:14:17.0102 - INFO - graphrag.logger.progress - extract graph progress: 117/527
2025-10-12 18:14:17.0104 - INFO - graphrag.logger.progress - extract graph progress: 118/527
2025-10-12 18:14:17.0106 - INFO - graphrag.logger.progress - extract graph progress: 119/527
2025-10-12 18:14:17.0108 - INFO - graphrag.logger.progress - extract graph progress: 120/527
2025-10-12 18:14:17.0111 - INFO - graphrag.logger.progress - extract graph progress: 121/527
2025-10-12 18:14:29.0571 - INFO - graphrag.logger.progress - extract graph progress: 122/527
2025-10-12 18:14:29.0576 - INFO - graphrag.logger.progress - extract graph progress: 123/527
2025-10-12 18:14:29.0580 - INFO - graphrag.logger.progress - extract graph progress: 124/527
2025-10-12 18:14:29.0583 - INFO - graphrag.logger.progress - extract graph progress: 125/527
2025-10-12 18:14:39.0074 - INFO - graphrag.logger.progress - extract graph progress: 126/527
2025-10-12 18:14:39.0078 - INFO - graphrag.logger.progress - extract graph progress: 127/527
2025-10-12 18:14:39.0083 - INFO - graphrag.logger.progress - extract graph progress: 128/527
2025-10-12 18:14:39.0087 - INFO - graphrag.logger.progress - extract graph progress: 129/527
2025-10-12 18:14:39.0091 - INFO - graphrag.logger.progress - extract graph progress: 130/527
2025-10-12 18:14:39.0095 - INFO - graphrag.logger.progress - extract graph progress: 131/527
2025-10-12 18:14:39.0099 - INFO - graphrag.logger.progress - extract graph progress: 132/527
2025-10-12 18:14:39.0103 - INFO - graphrag.logger.progress - extract graph progress: 133/527
2025-10-12 18:14:39.0107 - INFO - graphrag.logger.progress - extract graph progress: 134/527
2025-10-12 18:14:39.0111 - INFO - graphrag.logger.progress - extract graph progress: 135/527
2025-10-12 18:14:39.0113 - INFO - graphrag.logger.progress - extract graph progress: 136/527
2025-10-12 18:14:39.0116 - INFO - graphrag.logger.progress - extract graph progress: 137/527
2025-10-12 18:14:39.0118 - INFO - graphrag.logger.progress - extract graph progress: 138/527
2025-10-12 18:14:39.0120 - INFO - graphrag.logger.progress - extract graph progress: 139/527
2025-10-12 18:14:39.0122 - INFO - graphrag.logger.progress - extract graph progress: 140/527
2025-10-12 18:14:39.0125 - INFO - graphrag.logger.progress - extract graph progress: 141/527
2025-10-12 18:14:39.0129 - INFO - graphrag.logger.progress - extract graph progress: 142/527
2025-10-12 18:14:39.0133 - INFO - graphrag.logger.progress - extract graph progress: 143/527
2025-10-12 18:14:39.0137 - INFO - graphrag.logger.progress - extract graph progress: 144/527
2025-10-12 18:14:39.0141 - INFO - graphrag.logger.progress - extract graph progress: 145/527
2025-10-12 18:14:39.0145 - INFO - graphrag.logger.progress - extract graph progress: 146/527
2025-10-12 18:14:39.0148 - INFO - graphrag.logger.progress - extract graph progress: 147/527
2025-10-12 18:14:39.0151 - INFO - graphrag.logger.progress - extract graph progress: 148/527
2025-10-12 18:14:39.0155 - INFO - graphrag.logger.progress - extract graph progress: 149/527
2025-10-12 18:14:58.0008 - INFO - graphrag.logger.progress - extract graph progress: 150/527
2025-10-12 18:14:58.0012 - INFO - graphrag.logger.progress - extract graph progress: 151/527
2025-10-12 18:14:58.0017 - INFO - graphrag.logger.progress - extract graph progress: 152/527
2025-10-12 18:14:58.0020 - INFO - graphrag.logger.progress - extract graph progress: 153/527
2025-10-12 18:15:08.0192 - INFO - graphrag.logger.progress - extract graph progress: 154/527
2025-10-12 18:15:08.0196 - INFO - graphrag.logger.progress - extract graph progress: 155/527
2025-10-12 18:15:08.0200 - INFO - graphrag.logger.progress - extract graph progress: 156/527
2025-10-12 18:15:08.0204 - INFO - graphrag.logger.progress - extract graph progress: 157/527
2025-10-12 18:15:08.0206 - INFO - graphrag.logger.progress - extract graph progress: 158/527
2025-10-12 18:15:08.0209 - INFO - graphrag.logger.progress - extract graph progress: 159/527
2025-10-12 18:15:08.0212 - INFO - graphrag.logger.progress - extract graph progress: 160/527
2025-10-12 18:15:08.0216 - INFO - graphrag.logger.progress - extract graph progress: 161/527
2025-10-12 18:15:08.0220 - INFO - graphrag.logger.progress - extract graph progress: 162/527
2025-10-12 18:15:08.0224 - INFO - graphrag.logger.progress - extract graph progress: 163/527
2025-10-12 18:15:08.0227 - INFO - graphrag.logger.progress - extract graph progress: 164/527
2025-10-12 18:15:08.0230 - INFO - graphrag.logger.progress - extract graph progress: 165/527
2025-10-12 18:15:08.0233 - INFO - graphrag.logger.progress - extract graph progress: 166/527
2025-10-12 18:15:08.0236 - INFO - graphrag.logger.progress - extract graph progress: 167/527
2025-10-12 18:15:08.0240 - INFO - graphrag.logger.progress - extract graph progress: 168/527
2025-10-12 18:15:08.0243 - INFO - graphrag.logger.progress - extract graph progress: 169/527
2025-10-12 18:15:08.0245 - INFO - graphrag.logger.progress - extract graph progress: 170/527
2025-10-12 18:15:12.0877 - INFO - graphrag.logger.progress - extract graph progress: 171/527
2025-10-12 18:15:12.0879 - INFO - graphrag.logger.progress - extract graph progress: 172/527
2025-10-12 18:15:12.0882 - INFO - graphrag.logger.progress - extract graph progress: 173/527
2025-10-12 18:15:12.0884 - INFO - graphrag.logger.progress - extract graph progress: 174/527
2025-10-12 18:15:12.0886 - INFO - graphrag.logger.progress - extract graph progress: 175/527
2025-10-12 18:15:12.0888 - INFO - graphrag.logger.progress - extract graph progress: 176/527
2025-10-12 18:15:12.0891 - INFO - graphrag.logger.progress - extract graph progress: 177/527
2025-10-12 18:15:12.0893 - INFO - graphrag.logger.progress - extract graph progress: 178/527
2025-10-12 18:15:12.0895 - INFO - graphrag.logger.progress - extract graph progress: 179/527
2025-10-12 18:15:12.0897 - INFO - graphrag.logger.progress - extract graph progress: 180/527
2025-10-12 18:15:12.0899 - INFO - graphrag.logger.progress - extract graph progress: 181/527
2025-10-12 18:15:12.0903 - INFO - graphrag.logger.progress - extract graph progress: 182/527
2025-10-12 18:15:12.0905 - INFO - graphrag.logger.progress - extract graph progress: 183/527
2025-10-12 18:15:12.0907 - INFO - graphrag.logger.progress - extract graph progress: 184/527
2025-10-12 18:15:12.0909 - INFO - graphrag.logger.progress - extract graph progress: 185/527
2025-10-12 18:15:12.0911 - INFO - graphrag.logger.progress - extract graph progress: 186/527
2025-10-12 18:15:12.0914 - INFO - graphrag.logger.progress - extract graph progress: 187/527
2025-10-12 18:15:12.0916 - INFO - graphrag.logger.progress - extract graph progress: 188/527
2025-10-12 18:15:12.0919 - INFO - graphrag.logger.progress - extract graph progress: 189/527
2025-10-12 18:15:12.0921 - INFO - graphrag.logger.progress - extract graph progress: 190/527
2025-10-12 18:15:12.0923 - INFO - graphrag.logger.progress - extract graph progress: 191/527
2025-10-12 18:15:12.0925 - INFO - graphrag.logger.progress - extract graph progress: 192/527
2025-10-12 18:15:12.0928 - INFO - graphrag.logger.progress - extract graph progress: 193/527
2025-10-12 18:15:12.0930 - INFO - graphrag.logger.progress - extract graph progress: 194/527
2025-10-12 18:15:12.0932 - INFO - graphrag.logger.progress - extract graph progress: 195/527
2025-10-12 18:15:12.0934 - INFO - graphrag.logger.progress - extract graph progress: 196/527
2025-10-12 18:15:12.0936 - INFO - graphrag.logger.progress - extract graph progress: 197/527
2025-10-12 18:15:12.0939 - INFO - graphrag.logger.progress - extract graph progress: 198/527
2025-10-12 18:15:12.0941 - INFO - graphrag.logger.progress - extract graph progress: 199/527
2025-10-12 18:15:12.0943 - INFO - graphrag.logger.progress - extract graph progress: 200/527
2025-10-12 18:15:12.0945 - INFO - graphrag.logger.progress - extract graph progress: 201/527
2025-10-12 18:15:12.0947 - INFO - graphrag.logger.progress - extract graph progress: 202/527
2025-10-12 18:15:12.0950 - INFO - graphrag.logger.progress - extract graph progress: 203/527
2025-10-12 18:15:12.0952 - INFO - graphrag.logger.progress - extract graph progress: 204/527
2025-10-12 18:15:12.0954 - INFO - graphrag.logger.progress - extract graph progress: 205/527
2025-10-12 18:15:12.0956 - INFO - graphrag.logger.progress - extract graph progress: 206/527
2025-10-12 18:15:12.0958 - INFO - graphrag.logger.progress - extract graph progress: 207/527
2025-10-12 18:15:12.0960 - INFO - graphrag.logger.progress - extract graph progress: 208/527
2025-10-12 18:15:12.0962 - INFO - graphrag.logger.progress - extract graph progress: 209/527
2025-10-12 18:15:12.0965 - INFO - graphrag.logger.progress - extract graph progress: 210/527
2025-10-12 18:15:12.0967 - INFO - graphrag.logger.progress - extract graph progress: 211/527
2025-10-12 18:15:12.0969 - INFO - graphrag.logger.progress - extract graph progress: 212/527
2025-10-12 18:15:12.0971 - INFO - graphrag.logger.progress - extract graph progress: 213/527
2025-10-12 18:15:12.0973 - INFO - graphrag.logger.progress - extract graph progress: 214/527
2025-10-12 18:15:12.0976 - INFO - graphrag.logger.progress - extract graph progress: 215/527
2025-10-12 18:15:12.0978 - INFO - graphrag.logger.progress - extract graph progress: 216/527
2025-10-12 18:15:12.0980 - INFO - graphrag.logger.progress - extract graph progress: 217/527
2025-10-12 18:15:12.0982 - INFO - graphrag.logger.progress - extract graph progress: 218/527
2025-10-12 18:15:12.0984 - INFO - graphrag.logger.progress - extract graph progress: 219/527
2025-10-12 18:15:12.0986 - INFO - graphrag.logger.progress - extract graph progress: 220/527
2025-10-12 18:15:12.0988 - INFO - graphrag.logger.progress - extract graph progress: 221/527
2025-10-12 18:15:12.0990 - INFO - graphrag.logger.progress - extract graph progress: 222/527
2025-10-12 18:15:12.0993 - INFO - graphrag.logger.progress - extract graph progress: 223/527
2025-10-12 18:15:12.0996 - INFO - graphrag.logger.progress - extract graph progress: 224/527
2025-10-12 18:15:12.0998 - INFO - graphrag.logger.progress - extract graph progress: 225/527
2025-10-12 18:15:13.0000 - INFO - graphrag.logger.progress - extract graph progress: 226/527
2025-10-12 18:15:13.0002 - INFO - graphrag.logger.progress - extract graph progress: 227/527
2025-10-12 18:15:13.0004 - INFO - graphrag.logger.progress - extract graph progress: 228/527
2025-10-12 18:15:13.0006 - INFO - graphrag.logger.progress - extract graph progress: 229/527
2025-10-12 18:15:13.0008 - INFO - graphrag.logger.progress - extract graph progress: 230/527
2025-10-12 18:15:13.0011 - INFO - graphrag.logger.progress - extract graph progress: 231/527
2025-10-12 18:15:13.0013 - INFO - graphrag.logger.progress - extract graph progress: 232/527
2025-10-12 18:15:13.0015 - INFO - graphrag.logger.progress - extract graph progress: 233/527
2025-10-12 18:15:13.0017 - INFO - graphrag.logger.progress - extract graph progress: 234/527
2025-10-12 18:15:13.0019 - INFO - graphrag.logger.progress - extract graph progress: 235/527
2025-10-12 18:15:13.0021 - INFO - graphrag.logger.progress - extract graph progress: 236/527
2025-10-12 18:15:13.0024 - INFO - graphrag.logger.progress - extract graph progress: 237/527
2025-10-12 18:15:13.0026 - INFO - graphrag.logger.progress - extract graph progress: 238/527
2025-10-12 18:15:13.0028 - INFO - graphrag.logger.progress - extract graph progress: 239/527
2025-10-12 18:15:13.0030 - INFO - graphrag.logger.progress - extract graph progress: 240/527
2025-10-12 18:15:13.0032 - INFO - graphrag.logger.progress - extract graph progress: 241/527
2025-10-12 18:15:13.0034 - INFO - graphrag.logger.progress - extract graph progress: 242/527
2025-10-12 18:15:13.0036 - INFO - graphrag.logger.progress - extract graph progress: 243/527
2025-10-12 18:15:13.0038 - INFO - graphrag.logger.progress - extract graph progress: 244/527
2025-10-12 18:15:13.0041 - INFO - graphrag.logger.progress - extract graph progress: 245/527
2025-10-12 18:15:13.0043 - INFO - graphrag.logger.progress - extract graph progress: 246/527
2025-10-12 18:15:13.0045 - INFO - graphrag.logger.progress - extract graph progress: 247/527
2025-10-12 18:15:13.0047 - INFO - graphrag.logger.progress - extract graph progress: 248/527
2025-10-12 18:15:13.0050 - INFO - graphrag.logger.progress - extract graph progress: 249/527
2025-10-12 18:15:13.0052 - INFO - graphrag.logger.progress - extract graph progress: 250/527
2025-10-12 18:15:13.0054 - INFO - graphrag.logger.progress - extract graph progress: 251/527
2025-10-12 18:15:13.0056 - INFO - graphrag.logger.progress - extract graph progress: 252/527
2025-10-12 18:15:13.0059 - INFO - graphrag.logger.progress - extract graph progress: 253/527
2025-10-12 18:15:13.0060 - INFO - graphrag.logger.progress - extract graph progress: 254/527
2025-10-12 18:15:13.0062 - INFO - graphrag.logger.progress - extract graph progress: 255/527
2025-10-12 18:15:13.0065 - INFO - graphrag.logger.progress - extract graph progress: 256/527
2025-10-12 18:15:13.0067 - INFO - graphrag.logger.progress - extract graph progress: 257/527
2025-10-12 18:15:13.0069 - INFO - graphrag.logger.progress - extract graph progress: 258/527
2025-10-12 18:15:13.0071 - INFO - graphrag.logger.progress - extract graph progress: 259/527
2025-10-12 18:15:13.0073 - INFO - graphrag.logger.progress - extract graph progress: 260/527
2025-10-12 18:15:13.0075 - INFO - graphrag.logger.progress - extract graph progress: 261/527
2025-10-12 18:15:13.0078 - INFO - graphrag.logger.progress - extract graph progress: 262/527
2025-10-12 18:15:13.0080 - INFO - graphrag.logger.progress - extract graph progress: 263/527
2025-10-12 18:15:13.0082 - INFO - graphrag.logger.progress - extract graph progress: 264/527
2025-10-12 18:15:13.0084 - INFO - graphrag.logger.progress - extract graph progress: 265/527
2025-10-12 18:15:13.0086 - INFO - graphrag.logger.progress - extract graph progress: 266/527
2025-10-12 18:15:13.0088 - INFO - graphrag.logger.progress - extract graph progress: 267/527
2025-10-12 18:15:13.0090 - INFO - graphrag.logger.progress - extract graph progress: 268/527
2025-10-12 18:15:13.0093 - INFO - graphrag.logger.progress - extract graph progress: 269/527
2025-10-12 18:15:13.0095 - INFO - graphrag.logger.progress - extract graph progress: 270/527
2025-10-12 18:15:13.0097 - INFO - graphrag.logger.progress - extract graph progress: 271/527
2025-10-12 18:15:13.0099 - INFO - graphrag.logger.progress - extract graph progress: 272/527
2025-10-12 18:15:13.0101 - INFO - graphrag.logger.progress - extract graph progress: 273/527
2025-10-12 18:15:13.0104 - INFO - graphrag.logger.progress - extract graph progress: 274/527
2025-10-12 18:15:13.0106 - INFO - graphrag.logger.progress - extract graph progress: 275/527
2025-10-12 18:15:13.0108 - INFO - graphrag.logger.progress - extract graph progress: 276/527
2025-10-12 18:15:13.0110 - INFO - graphrag.logger.progress - extract graph progress: 277/527
2025-10-12 18:15:13.0112 - INFO - graphrag.logger.progress - extract graph progress: 278/527
2025-10-12 18:15:13.0114 - INFO - graphrag.logger.progress - extract graph progress: 279/527
2025-10-12 18:15:13.0117 - INFO - graphrag.logger.progress - extract graph progress: 280/527
2025-10-12 18:15:13.0119 - INFO - graphrag.logger.progress - extract graph progress: 281/527
2025-10-12 18:15:13.0121 - INFO - graphrag.logger.progress - extract graph progress: 282/527
2025-10-12 18:15:13.0123 - INFO - graphrag.logger.progress - extract graph progress: 283/527
2025-10-12 18:15:13.0125 - INFO - graphrag.logger.progress - extract graph progress: 284/527
2025-10-12 18:15:13.0128 - INFO - graphrag.logger.progress - extract graph progress: 285/527
2025-10-12 18:15:13.0130 - INFO - graphrag.logger.progress - extract graph progress: 286/527
2025-10-12 18:15:13.0132 - INFO - graphrag.logger.progress - extract graph progress: 287/527
2025-10-12 18:15:13.0134 - INFO - graphrag.logger.progress - extract graph progress: 288/527
2025-10-12 18:15:13.0137 - INFO - graphrag.logger.progress - extract graph progress: 289/527
2025-10-12 18:15:13.0139 - INFO - graphrag.logger.progress - extract graph progress: 290/527
2025-10-12 18:15:13.0141 - INFO - graphrag.logger.progress - extract graph progress: 291/527
2025-10-12 18:15:13.0143 - INFO - graphrag.logger.progress - extract graph progress: 292/527
2025-10-12 18:15:13.0145 - INFO - graphrag.logger.progress - extract graph progress: 293/527
2025-10-12 18:15:13.0147 - INFO - graphrag.logger.progress - extract graph progress: 294/527
2025-10-12 18:15:13.0150 - INFO - graphrag.logger.progress - extract graph progress: 295/527
2025-10-12 18:15:13.0152 - INFO - graphrag.logger.progress - extract graph progress: 296/527
2025-10-12 18:15:13.0154 - INFO - graphrag.logger.progress - extract graph progress: 297/527
2025-10-12 18:15:13.0156 - INFO - graphrag.logger.progress - extract graph progress: 298/527
2025-10-12 18:15:13.0158 - INFO - graphrag.logger.progress - extract graph progress: 299/527
2025-10-12 18:15:13.0160 - INFO - graphrag.logger.progress - extract graph progress: 300/527
2025-10-12 18:15:13.0163 - INFO - graphrag.logger.progress - extract graph progress: 301/527
2025-10-12 18:15:13.0165 - INFO - graphrag.logger.progress - extract graph progress: 302/527
2025-10-12 18:15:13.0167 - INFO - graphrag.logger.progress - extract graph progress: 303/527
2025-10-12 18:15:13.0169 - INFO - graphrag.logger.progress - extract graph progress: 304/527
2025-10-12 18:15:13.0172 - INFO - graphrag.logger.progress - extract graph progress: 305/527
2025-10-12 18:15:13.0174 - INFO - graphrag.logger.progress - extract graph progress: 306/527
2025-10-12 18:15:13.0176 - INFO - graphrag.logger.progress - extract graph progress: 307/527
2025-10-12 18:15:13.0178 - INFO - graphrag.logger.progress - extract graph progress: 308/527
2025-10-12 18:15:13.0180 - INFO - graphrag.logger.progress - extract graph progress: 309/527
2025-10-12 18:15:13.0183 - INFO - graphrag.logger.progress - extract graph progress: 310/527
2025-10-12 18:15:13.0185 - INFO - graphrag.logger.progress - extract graph progress: 311/527
2025-10-12 18:15:13.0187 - INFO - graphrag.logger.progress - extract graph progress: 312/527
2025-10-12 18:15:13.0189 - INFO - graphrag.logger.progress - extract graph progress: 313/527
2025-10-12 18:15:13.0192 - INFO - graphrag.logger.progress - extract graph progress: 314/527
2025-10-12 18:15:13.0194 - INFO - graphrag.logger.progress - extract graph progress: 315/527
2025-10-12 18:15:13.0196 - INFO - graphrag.logger.progress - extract graph progress: 316/527
2025-10-12 18:15:13.0198 - INFO - graphrag.logger.progress - extract graph progress: 317/527
2025-10-12 18:15:13.0200 - INFO - graphrag.logger.progress - extract graph progress: 318/527
2025-10-12 18:15:13.0202 - INFO - graphrag.logger.progress - extract graph progress: 319/527
2025-10-12 18:15:13.0204 - INFO - graphrag.logger.progress - extract graph progress: 320/527
2025-10-12 18:15:13.0207 - INFO - graphrag.logger.progress - extract graph progress: 321/527
2025-10-12 18:15:13.0209 - INFO - graphrag.logger.progress - extract graph progress: 322/527
2025-10-12 18:15:13.0211 - INFO - graphrag.logger.progress - extract graph progress: 323/527
2025-10-12 18:15:13.0213 - INFO - graphrag.logger.progress - extract graph progress: 324/527
2025-10-12 18:15:13.0215 - INFO - graphrag.logger.progress - extract graph progress: 325/527
2025-10-12 18:15:13.0219 - INFO - graphrag.logger.progress - extract graph progress: 326/527
2025-10-12 18:15:13.0221 - INFO - graphrag.logger.progress - extract graph progress: 327/527
2025-10-12 18:15:13.0223 - INFO - graphrag.logger.progress - extract graph progress: 328/527
2025-10-12 18:15:13.0225 - INFO - graphrag.logger.progress - extract graph progress: 329/527
2025-10-12 18:15:13.0227 - INFO - graphrag.logger.progress - extract graph progress: 330/527
2025-10-12 18:15:13.0229 - INFO - graphrag.logger.progress - extract graph progress: 331/527
2025-10-12 18:15:13.0232 - INFO - graphrag.logger.progress - extract graph progress: 332/527
2025-10-12 18:15:13.0234 - INFO - graphrag.logger.progress - extract graph progress: 333/527
2025-10-12 18:15:13.0236 - INFO - graphrag.logger.progress - extract graph progress: 334/527
2025-10-12 18:15:13.0239 - INFO - graphrag.logger.progress - extract graph progress: 335/527
2025-10-12 18:15:13.0241 - INFO - graphrag.logger.progress - extract graph progress: 336/527
2025-10-12 18:15:13.0243 - INFO - graphrag.logger.progress - extract graph progress: 337/527
2025-10-12 18:15:13.0245 - INFO - graphrag.logger.progress - extract graph progress: 338/527
2025-10-12 18:15:13.0247 - INFO - graphrag.logger.progress - extract graph progress: 339/527
2025-10-12 18:15:13.0250 - INFO - graphrag.logger.progress - extract graph progress: 340/527
2025-10-12 18:15:35.0548 - INFO - graphrag.logger.progress - extract graph progress: 341/527
2025-10-12 18:15:35.0550 - INFO - graphrag.logger.progress - extract graph progress: 342/527
2025-10-12 18:15:35.0553 - INFO - graphrag.logger.progress - extract graph progress: 343/527
2025-10-12 18:15:35.0555 - INFO - graphrag.logger.progress - extract graph progress: 344/527
2025-10-12 18:15:35.0557 - INFO - graphrag.logger.progress - extract graph progress: 345/527
2025-10-12 18:15:35.0559 - INFO - graphrag.logger.progress - extract graph progress: 346/527
2025-10-12 18:15:35.0561 - INFO - graphrag.logger.progress - extract graph progress: 347/527
2025-10-12 18:15:35.0563 - INFO - graphrag.logger.progress - extract graph progress: 348/527
2025-10-12 18:15:35.0565 - INFO - graphrag.logger.progress - extract graph progress: 349/527
2025-10-12 18:15:35.0567 - INFO - graphrag.logger.progress - extract graph progress: 350/527
2025-10-12 18:15:35.0570 - INFO - graphrag.logger.progress - extract graph progress: 351/527
2025-10-12 18:15:35.0572 - INFO - graphrag.logger.progress - extract graph progress: 352/527
2025-10-12 18:15:35.0574 - INFO - graphrag.logger.progress - extract graph progress: 353/527
2025-10-12 18:15:35.0576 - INFO - graphrag.logger.progress - extract graph progress: 354/527
2025-10-12 18:15:35.0578 - INFO - graphrag.logger.progress - extract graph progress: 355/527
2025-10-12 18:15:35.0580 - INFO - graphrag.logger.progress - extract graph progress: 356/527
2025-10-12 18:15:35.0582 - INFO - graphrag.logger.progress - extract graph progress: 357/527
2025-10-12 18:15:35.0585 - INFO - graphrag.logger.progress - extract graph progress: 358/527
2025-10-12 18:15:35.0587 - INFO - graphrag.logger.progress - extract graph progress: 359/527
2025-10-12 18:15:35.0590 - INFO - graphrag.logger.progress - extract graph progress: 360/527
2025-10-12 18:15:35.0592 - INFO - graphrag.logger.progress - extract graph progress: 361/527
2025-10-12 18:15:35.0594 - INFO - graphrag.logger.progress - extract graph progress: 362/527
2025-10-12 18:15:35.0596 - INFO - graphrag.logger.progress - extract graph progress: 363/527
2025-10-12 18:15:35.0598 - INFO - graphrag.logger.progress - extract graph progress: 364/527
2025-10-12 18:15:35.0601 - INFO - graphrag.logger.progress - extract graph progress: 365/527
2025-10-12 18:15:35.0603 - INFO - graphrag.logger.progress - extract graph progress: 366/527
2025-10-12 18:15:35.0605 - INFO - graphrag.logger.progress - extract graph progress: 367/527
2025-10-12 18:15:35.0607 - INFO - graphrag.logger.progress - extract graph progress: 368/527
2025-10-12 18:15:35.0609 - INFO - graphrag.logger.progress - extract graph progress: 369/527
2025-10-12 18:15:35.0611 - INFO - graphrag.logger.progress - extract graph progress: 370/527
2025-10-12 18:15:35.0613 - INFO - graphrag.logger.progress - extract graph progress: 371/527
2025-10-12 18:15:35.0616 - INFO - graphrag.logger.progress - extract graph progress: 372/527
2025-10-12 18:15:35.0618 - INFO - graphrag.logger.progress - extract graph progress: 373/527
2025-10-12 18:15:35.0621 - INFO - graphrag.logger.progress - extract graph progress: 374/527
2025-10-12 18:15:35.0623 - INFO - graphrag.logger.progress - extract graph progress: 375/527
2025-10-12 18:15:35.0625 - INFO - graphrag.logger.progress - extract graph progress: 376/527
2025-10-12 18:15:35.0628 - INFO - graphrag.logger.progress - extract graph progress: 377/527
2025-10-12 18:15:35.0630 - INFO - graphrag.logger.progress - extract graph progress: 378/527
2025-10-12 18:15:35.0632 - INFO - graphrag.logger.progress - extract graph progress: 379/527
2025-10-12 18:15:35.0634 - INFO - graphrag.logger.progress - extract graph progress: 380/527
2025-10-12 18:15:35.0636 - INFO - graphrag.logger.progress - extract graph progress: 381/527
2025-10-12 18:15:35.0639 - INFO - graphrag.logger.progress - extract graph progress: 382/527
2025-10-12 18:15:35.0641 - INFO - graphrag.logger.progress - extract graph progress: 383/527
2025-10-12 18:15:35.0643 - INFO - graphrag.logger.progress - extract graph progress: 384/527
2025-10-12 18:16:06.0307 - INFO - graphrag.logger.progress - extract graph progress: 385/527
2025-10-12 18:16:06.0312 - INFO - graphrag.logger.progress - extract graph progress: 386/527
2025-10-12 18:16:06.0315 - INFO - graphrag.logger.progress - extract graph progress: 387/527
2025-10-12 18:16:06.0318 - INFO - graphrag.logger.progress - extract graph progress: 388/527
2025-10-12 18:16:06.0321 - INFO - graphrag.logger.progress - extract graph progress: 389/527
2025-10-12 18:16:06.0325 - INFO - graphrag.logger.progress - extract graph progress: 390/527
2025-10-12 18:16:24.0449 - INFO - graphrag.logger.progress - extract graph progress: 391/527
2025-10-12 18:16:24.0454 - INFO - graphrag.logger.progress - extract graph progress: 392/527
2025-10-12 18:16:24.0458 - INFO - graphrag.logger.progress - extract graph progress: 393/527
2025-10-12 18:16:24.0463 - INFO - graphrag.logger.progress - extract graph progress: 394/527
2025-10-12 18:16:24.0467 - INFO - graphrag.logger.progress - extract graph progress: 395/527
2025-10-12 18:16:24.0471 - INFO - graphrag.logger.progress - extract graph progress: 396/527
2025-10-12 18:16:24.0475 - INFO - graphrag.logger.progress - extract graph progress: 397/527
2025-10-12 18:16:24.0479 - INFO - graphrag.logger.progress - extract graph progress: 398/527
2025-10-12 18:16:24.0482 - INFO - graphrag.logger.progress - extract graph progress: 399/527
2025-10-12 18:16:24.0486 - INFO - graphrag.logger.progress - extract graph progress: 400/527
2025-10-12 18:16:24.0490 - INFO - graphrag.logger.progress - extract graph progress: 401/527
2025-10-12 18:16:24.0494 - INFO - graphrag.logger.progress - extract graph progress: 402/527
2025-10-12 18:16:24.0497 - INFO - graphrag.logger.progress - extract graph progress: 403/527
2025-10-12 18:16:24.0501 - INFO - graphrag.logger.progress - extract graph progress: 404/527
2025-10-12 18:16:24.0504 - INFO - graphrag.logger.progress - extract graph progress: 405/527
2025-10-12 18:16:24.0507 - INFO - graphrag.logger.progress - extract graph progress: 406/527
2025-10-12 18:16:24.0513 - INFO - graphrag.logger.progress - extract graph progress: 407/527
2025-10-12 18:16:24.0515 - INFO - graphrag.logger.progress - extract graph progress: 408/527
2025-10-12 18:16:24.0518 - INFO - graphrag.logger.progress - extract graph progress: 409/527
2025-10-12 18:16:24.0521 - INFO - graphrag.logger.progress - extract graph progress: 410/527
2025-10-12 18:16:24.0524 - INFO - graphrag.logger.progress - extract graph progress: 411/527
2025-10-12 18:16:24.0527 - INFO - graphrag.logger.progress - extract graph progress: 412/527
2025-10-12 18:16:24.0531 - INFO - graphrag.logger.progress - extract graph progress: 413/527
2025-10-12 18:16:24.0535 - INFO - graphrag.logger.progress - extract graph progress: 414/527
2025-10-12 18:16:24.0538 - INFO - graphrag.logger.progress - extract graph progress: 415/527
2025-10-12 18:16:24.0540 - INFO - graphrag.logger.progress - extract graph progress: 416/527
2025-10-12 18:16:24.0545 - INFO - graphrag.logger.progress - extract graph progress: 417/527
2025-10-12 18:16:24.0547 - INFO - graphrag.logger.progress - extract graph progress: 418/527
2025-10-12 18:16:24.0550 - INFO - graphrag.logger.progress - extract graph progress: 419/527
2025-10-12 18:16:24.0555 - INFO - graphrag.logger.progress - extract graph progress: 420/527
2025-10-12 18:16:24.0559 - INFO - graphrag.logger.progress - extract graph progress: 421/527
2025-10-12 18:16:24.0563 - INFO - graphrag.logger.progress - extract graph progress: 422/527
2025-10-12 18:16:24.0567 - INFO - graphrag.logger.progress - extract graph progress: 423/527
2025-10-12 18:16:24.0570 - INFO - graphrag.logger.progress - extract graph progress: 424/527
2025-10-12 18:16:24.0573 - INFO - graphrag.logger.progress - extract graph progress: 425/527
2025-10-12 18:16:24.0577 - INFO - graphrag.logger.progress - extract graph progress: 426/527
2025-10-12 18:16:24.0582 - INFO - graphrag.logger.progress - extract graph progress: 427/527
2025-10-12 18:16:24.0586 - INFO - graphrag.logger.progress - extract graph progress: 428/527
2025-10-12 18:16:24.0589 - INFO - graphrag.logger.progress - extract graph progress: 429/527
2025-10-12 18:16:24.0593 - INFO - graphrag.logger.progress - extract graph progress: 430/527
2025-10-12 18:16:24.0596 - INFO - graphrag.logger.progress - extract graph progress: 431/527
2025-10-12 18:16:24.0599 - INFO - graphrag.logger.progress - extract graph progress: 432/527
2025-10-12 18:16:24.0603 - INFO - graphrag.logger.progress - extract graph progress: 433/527
2025-10-12 18:16:55.0555 - INFO - graphrag.logger.progress - extract graph progress: 434/527
2025-10-12 18:16:55.0560 - INFO - graphrag.logger.progress - extract graph progress: 435/527
2025-10-12 18:16:55.0564 - INFO - graphrag.logger.progress - extract graph progress: 436/527
2025-10-12 18:16:55.0568 - INFO - graphrag.logger.progress - extract graph progress: 437/527
2025-10-12 18:16:55.0573 - INFO - graphrag.logger.progress - extract graph progress: 438/527
2025-10-12 18:16:55.0576 - INFO - graphrag.logger.progress - extract graph progress: 439/527
2025-10-12 18:16:55.0579 - INFO - graphrag.logger.progress - extract graph progress: 440/527
2025-10-12 18:16:55.0581 - INFO - graphrag.logger.progress - extract graph progress: 441/527
2025-10-12 18:16:55.0583 - INFO - graphrag.logger.progress - extract graph progress: 442/527
2025-10-12 18:16:55.0585 - INFO - graphrag.logger.progress - extract graph progress: 443/527
2025-10-12 18:16:55.0587 - INFO - graphrag.logger.progress - extract graph progress: 444/527
2025-10-12 18:16:55.0589 - INFO - graphrag.logger.progress - extract graph progress: 445/527
2025-10-12 18:16:55.0592 - INFO - graphrag.logger.progress - extract graph progress: 446/527
2025-10-12 18:16:55.0594 - INFO - graphrag.logger.progress - extract graph progress: 447/527
2025-10-12 18:16:55.0596 - INFO - graphrag.logger.progress - extract graph progress: 448/527
2025-10-12 18:16:55.0598 - INFO - graphrag.logger.progress - extract graph progress: 449/527
2025-10-12 18:16:55.0600 - INFO - graphrag.logger.progress - extract graph progress: 450/527
2025-10-12 18:16:55.0603 - INFO - graphrag.logger.progress - extract graph progress: 451/527
2025-10-12 18:16:55.0605 - INFO - graphrag.logger.progress - extract graph progress: 452/527
2025-10-12 18:16:55.0607 - INFO - graphrag.logger.progress - extract graph progress: 453/527
2025-10-12 18:16:55.0609 - INFO - graphrag.logger.progress - extract graph progress: 454/527
2025-10-12 18:16:55.0611 - INFO - graphrag.logger.progress - extract graph progress: 455/527
2025-10-12 18:16:55.0614 - INFO - graphrag.logger.progress - extract graph progress: 456/527
2025-10-12 18:16:55.0616 - INFO - graphrag.logger.progress - extract graph progress: 457/527
2025-10-12 18:16:55.0618 - INFO - graphrag.logger.progress - extract graph progress: 458/527
2025-10-12 18:16:55.0620 - INFO - graphrag.logger.progress - extract graph progress: 459/527
2025-10-12 18:16:55.0623 - INFO - graphrag.logger.progress - extract graph progress: 460/527
2025-10-12 18:16:55.0625 - INFO - graphrag.logger.progress - extract graph progress: 461/527
2025-10-12 18:16:55.0627 - INFO - graphrag.logger.progress - extract graph progress: 462/527
2025-10-12 18:16:55.0629 - INFO - graphrag.logger.progress - extract graph progress: 463/527
2025-10-12 18:16:55.0631 - INFO - graphrag.logger.progress - extract graph progress: 464/527
2025-10-12 18:16:55.0634 - INFO - graphrag.logger.progress - extract graph progress: 465/527
2025-10-12 18:16:55.0636 - INFO - graphrag.logger.progress - extract graph progress: 466/527
2025-10-12 18:16:55.0638 - INFO - graphrag.logger.progress - extract graph progress: 467/527
2025-10-12 18:16:55.0640 - INFO - graphrag.logger.progress - extract graph progress: 468/527
2025-10-12 18:16:55.0643 - INFO - graphrag.logger.progress - extract graph progress: 469/527
2025-10-12 18:16:55.0645 - INFO - graphrag.logger.progress - extract graph progress: 470/527
2025-10-12 18:16:55.0647 - INFO - graphrag.logger.progress - extract graph progress: 471/527
2025-10-12 18:16:55.0649 - INFO - graphrag.logger.progress - extract graph progress: 472/527
2025-10-12 18:16:55.0651 - INFO - graphrag.logger.progress - extract graph progress: 473/527
2025-10-12 18:16:55.0653 - INFO - graphrag.logger.progress - extract graph progress: 474/527
2025-10-12 18:16:55.0656 - INFO - graphrag.logger.progress - extract graph progress: 475/527
2025-10-12 18:16:55.0658 - INFO - graphrag.logger.progress - extract graph progress: 476/527
2025-10-12 18:16:55.0660 - INFO - graphrag.logger.progress - extract graph progress: 477/527
2025-10-12 18:16:55.0662 - INFO - graphrag.logger.progress - extract graph progress: 478/527
2025-10-12 18:16:55.0665 - INFO - graphrag.logger.progress - extract graph progress: 479/527
2025-10-12 18:16:55.0667 - INFO - graphrag.logger.progress - extract graph progress: 480/527
2025-10-12 18:16:55.0669 - INFO - graphrag.logger.progress - extract graph progress: 481/527
2025-10-12 18:16:55.0671 - INFO - graphrag.logger.progress - extract graph progress: 482/527
2025-10-12 18:16:55.0673 - INFO - graphrag.logger.progress - extract graph progress: 483/527
2025-10-12 18:16:55.0676 - INFO - graphrag.logger.progress - extract graph progress: 484/527
2025-10-12 18:16:55.0678 - INFO - graphrag.logger.progress - extract graph progress: 485/527
2025-10-12 18:16:55.0680 - INFO - graphrag.logger.progress - extract graph progress: 486/527
2025-10-12 18:16:55.0682 - INFO - graphrag.logger.progress - extract graph progress: 487/527
2025-10-12 18:16:55.0685 - INFO - graphrag.logger.progress - extract graph progress: 488/527
2025-10-12 18:16:55.0687 - INFO - graphrag.logger.progress - extract graph progress: 489/527
2025-10-12 18:16:55.0689 - INFO - graphrag.logger.progress - extract graph progress: 490/527
2025-10-12 18:16:55.0691 - INFO - graphrag.logger.progress - extract graph progress: 491/527
2025-10-12 18:16:55.0693 - INFO - graphrag.logger.progress - extract graph progress: 492/527
2025-10-12 18:16:55.0695 - INFO - graphrag.logger.progress - extract graph progress: 493/527
2025-10-12 18:16:55.0698 - INFO - graphrag.logger.progress - extract graph progress: 494/527
2025-10-12 18:16:55.0700 - INFO - graphrag.logger.progress - extract graph progress: 495/527
2025-10-12 18:16:55.0702 - INFO - graphrag.logger.progress - extract graph progress: 496/527
2025-10-12 18:16:55.0704 - INFO - graphrag.logger.progress - extract graph progress: 497/527
2025-10-12 18:16:55.0706 - INFO - graphrag.logger.progress - extract graph progress: 498/527
2025-10-12 18:16:55.0709 - INFO - graphrag.logger.progress - extract graph progress: 499/527
2025-10-12 18:16:55.0711 - INFO - graphrag.logger.progress - extract graph progress: 500/527
2025-10-12 18:16:55.0713 - INFO - graphrag.logger.progress - extract graph progress: 501/527
2025-10-12 18:16:55.0715 - INFO - graphrag.logger.progress - extract graph progress: 502/527
2025-10-12 18:16:55.0717 - INFO - graphrag.logger.progress - extract graph progress: 503/527
2025-10-12 18:16:55.0720 - INFO - graphrag.logger.progress - extract graph progress: 504/527
2025-10-12 18:17:01.0199 - INFO - graphrag.logger.progress - extract graph progress: 505/527
2025-10-12 18:17:01.0203 - INFO - graphrag.logger.progress - extract graph progress: 506/527
2025-10-12 18:17:01.0208 - INFO - graphrag.logger.progress - extract graph progress: 507/527
2025-10-12 18:17:01.0210 - INFO - graphrag.logger.progress - extract graph progress: 508/527
2025-10-12 18:17:01.0213 - INFO - graphrag.logger.progress - extract graph progress: 509/527
2025-10-12 18:17:01.0217 - INFO - graphrag.logger.progress - extract graph progress: 510/527
2025-10-12 18:17:01.0220 - INFO - graphrag.logger.progress - extract graph progress: 511/527
2025-10-12 18:17:01.0223 - INFO - graphrag.logger.progress - extract graph progress: 512/527
2025-10-12 18:17:01.0228 - INFO - graphrag.logger.progress - extract graph progress: 513/527
2025-10-12 18:17:01.0231 - INFO - graphrag.logger.progress - extract graph progress: 514/527
2025-10-12 18:17:01.0234 - INFO - graphrag.logger.progress - extract graph progress: 515/527
2025-10-12 18:17:01.0238 - INFO - graphrag.logger.progress - extract graph progress: 516/527
2025-10-12 18:17:01.0241 - INFO - graphrag.logger.progress - extract graph progress: 517/527
2025-10-12 18:17:01.0244 - INFO - graphrag.logger.progress - extract graph progress: 518/527
2025-10-12 18:17:01.0248 - INFO - graphrag.logger.progress - extract graph progress: 519/527
2025-10-12 18:17:01.0251 - INFO - graphrag.logger.progress - extract graph progress: 520/527
2025-10-12 18:17:01.0254 - INFO - graphrag.logger.progress - extract graph progress: 521/527
2025-10-12 18:17:01.0258 - INFO - graphrag.logger.progress - extract graph progress: 522/527
2025-10-12 18:17:01.0262 - INFO - graphrag.logger.progress - extract graph progress: 523/527
2025-10-12 18:17:01.0267 - INFO - graphrag.logger.progress - extract graph progress: 524/527
2025-10-12 18:17:01.0270 - INFO - graphrag.logger.progress - extract graph progress: 525/527
2025-10-12 18:17:01.0274 - INFO - graphrag.logger.progress - extract graph progress: 526/527
2025-10-12 18:17:01.0278 - INFO - graphrag.logger.progress - extract graph progress: 527/527
2025-10-12 18:17:01.0376 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/summarize_descriptions
2025-10-12 18:17:01.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/198
2025-10-12 18:17:01.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/198
2025-10-12 18:17:01.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/198
2025-10-12 18:17:02.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/198
2025-10-12 18:17:02.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/198
2025-10-12 18:17:03.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/198
2025-10-12 18:17:04.0535 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/198
2025-10-12 18:17:06.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/198
2025-10-12 18:17:07.0539 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/198
2025-10-12 18:17:08.0293 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/198
2025-10-12 18:17:09.0238 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/198
2025-10-12 18:17:09.0238 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/198
2025-10-12 18:17:09.0716 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/198
2025-10-12 18:17:09.0717 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 123/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 124/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 125/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 126/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 127/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 128/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 129/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 130/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 131/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 132/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 133/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 134/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 135/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 136/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 137/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 138/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 139/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 140/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 141/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 142/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 143/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 144/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 145/198
2025-10-12 18:17:10.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 146/198
2025-10-12 18:17:11.0646 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 147/198
2025-10-12 18:17:12.0534 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 148/198
2025-10-12 18:17:12.0534 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 149/198
2025-10-12 18:17:12.0534 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 150/198
2025-10-12 18:17:13.0275 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 151/198
2025-10-12 18:17:14.0785 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 152/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 153/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 154/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 155/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 156/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 157/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 158/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 159/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 160/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 161/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 162/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 163/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 164/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 165/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 166/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 167/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 168/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 169/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 170/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 171/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 172/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 173/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 174/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 175/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 176/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 177/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 178/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 179/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 180/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 181/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 182/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 183/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 184/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 185/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 186/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 187/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 188/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 189/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 190/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 191/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 192/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 193/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 194/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 195/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 196/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 197/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 198/198
2025-10-12 18:17:16.0950 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-10-12 18:17:16.0950 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-10-12 18:17:16.0958 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-10-12 18:17:16.0958 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:16.0964 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:16.0992 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-10-12 18:17:16.0992 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-10-12 18:17:17.0000 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-10-12 18:17:17.0000 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-10-12 18:17:17.0000 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-10-12 18:17:17.0000 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-10-12 18:17:17.0000 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:17.0005 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:17.0038 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-10-12 18:17:17.0038 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-10-12 18:17:17.0044 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-10-12 18:17:17.0044 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:17:17.0048 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:17.0052 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:17.0090 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-10-12 18:17:17.0090 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-10-12 18:17:17.0096 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-10-12 18:17:17.0097 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:17.0101 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:17.0104 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-10-12 18:17:17.0117 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 23
2025-10-12 18:17:17.0148 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 31
2025-10-12 18:17:17.0190 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/community_reporting
2025-10-12 18:17:22.0814 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/4
2025-10-12 18:17:28.0647 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/4
2025-10-12 18:17:34.0335 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/4
2025-10-12 18:17:38.0880 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/4
2025-10-12 18:17:44.0902 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/4
2025-10-12 18:17:51.0405 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/4
2025-10-12 18:17:57.0506 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/4
2025-10-12 18:18:02.0924 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/4
2025-10-12 18:18:02.0932 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-10-12 18:18:02.0932 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-10-12 18:18:02.0940 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-10-12 18:18:02.0940 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-10-12 18:18:02.0941 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:18:02.0950 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:18:02.0954 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-10-12 18:18:02.0960 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-10-12 18:18:02.0960 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-10-12 18:18:03.0003 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 18:18:03.0004 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/text_embedding
2025-10-12 18:18:03.0008 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 102 inputs via 102 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:18:17.0080 - INFO - graphrag.logger.progress - generate embeddings progress: 1/7
2025-10-12 18:18:35.0515 - INFO - graphrag.logger.progress - generate embeddings progress: 2/7
2025-10-12 18:18:53.0001 - INFO - graphrag.logger.progress - generate embeddings progress: 3/7
2025-10-12 18:19:05.0231 - INFO - graphrag.logger.progress - generate embeddings progress: 4/7
2025-10-12 18:19:21.0092 - INFO - graphrag.logger.progress - generate embeddings progress: 5/7
2025-10-12 18:19:35.0962 - INFO - graphrag.logger.progress - generate embeddings progress: 6/7
2025-10-12 18:19:40.0750 - INFO - graphrag.logger.progress - generate embeddings progress: 7/7
2025-10-12 18:19:40.0880 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-10-12 18:19:40.0884 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 18:19:40.0886 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:19:41.0020 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-10-12 18:19:41.0082 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-10-12 18:19:41.0085 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/2 of size 500 to vector store
2025-10-12 18:19:41.0088 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:19:57.0588 - INFO - graphrag.logger.progress - generate embeddings progress: 1/32
2025-10-12 18:20:16.0986 - INFO - graphrag.logger.progress - generate embeddings progress: 2/32
2025-10-12 18:20:16.0989 - INFO - graphrag.logger.progress - generate embeddings progress: 3/32
2025-10-12 18:20:36.0978 - INFO - graphrag.logger.progress - generate embeddings progress: 4/32
2025-10-12 18:20:36.0984 - INFO - graphrag.logger.progress - generate embeddings progress: 5/32
2025-10-12 18:20:57.0063 - INFO - graphrag.logger.progress - generate embeddings progress: 6/32
2025-10-12 18:21:15.0820 - INFO - graphrag.logger.progress - generate embeddings progress: 7/32
2025-10-12 18:21:35.0454 - INFO - graphrag.logger.progress - generate embeddings progress: 8/32
2025-10-12 18:21:35.0456 - INFO - graphrag.logger.progress - generate embeddings progress: 9/32
2025-10-12 18:21:55.0066 - INFO - graphrag.logger.progress - generate embeddings progress: 10/32
2025-10-12 18:22:14.0397 - INFO - graphrag.logger.progress - generate embeddings progress: 11/32
2025-10-12 18:22:33.0341 - INFO - graphrag.logger.progress - generate embeddings progress: 12/32
2025-10-12 18:22:53.0800 - INFO - graphrag.logger.progress - generate embeddings progress: 13/32
2025-10-12 18:22:53.0803 - INFO - graphrag.logger.progress - generate embeddings progress: 14/32
2025-10-12 18:23:11.0649 - INFO - graphrag.logger.progress - generate embeddings progress: 15/32
2025-10-12 18:23:28.0338 - INFO - graphrag.logger.progress - generate embeddings progress: 16/32
2025-10-12 18:23:28.0340 - INFO - graphrag.logger.progress - generate embeddings progress: 17/32
2025-10-12 18:23:28.0342 - INFO - graphrag.logger.progress - generate embeddings progress: 18/32
2025-10-12 18:23:48.0297 - INFO - graphrag.logger.progress - generate embeddings progress: 19/32
2025-10-12 18:24:06.0163 - INFO - graphrag.logger.progress - generate embeddings progress: 20/32
2025-10-12 18:24:26.0176 - INFO - graphrag.logger.progress - generate embeddings progress: 21/32
2025-10-12 18:24:45.0885 - INFO - graphrag.logger.progress - generate embeddings progress: 22/32
2025-10-12 18:24:45.0888 - INFO - graphrag.logger.progress - generate embeddings progress: 23/32
2025-10-12 18:25:04.0494 - INFO - graphrag.logger.progress - generate embeddings progress: 24/32
2025-10-12 18:25:25.0000 - INFO - graphrag.logger.progress - generate embeddings progress: 25/32
2025-10-12 18:25:45.0343 - INFO - graphrag.logger.progress - generate embeddings progress: 26/32
2025-10-12 18:26:07.0138 - INFO - graphrag.logger.progress - generate embeddings progress: 27/32
2025-10-12 18:26:25.0301 - INFO - graphrag.logger.progress - generate embeddings progress: 28/32
2025-10-12 18:26:42.0616 - INFO - graphrag.logger.progress - generate embeddings progress: 29/32
2025-10-12 18:26:59.0727 - INFO - graphrag.logger.progress - generate embeddings progress: 30/32
2025-10-12 18:27:18.0115 - INFO - graphrag.logger.progress - generate embeddings progress: 31/32
2025-10-12 18:27:18.0118 - INFO - graphrag.logger.progress - generate embeddings progress: 32/32
2025-10-12 18:27:18.0209 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 2/2 of size 500 to vector store
2025-10-12 18:27:18.0209 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 27 inputs via 27 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:27:35.0472 - INFO - graphrag.logger.progress - generate embeddings progress: 1/2
2025-10-12 18:27:48.0884 - INFO - graphrag.logger.progress - generate embeddings progress: 2/2
2025-10-12 18:27:48.0903 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-10-12 18:27:48.0903 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-10-12 18:27:48.0918 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-10-12 18:27:48.0923 - INFO - graphrag.cli.index - All workflows completed successfully.
2025-10-12 18:58:17.0948 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 18:58:19.0996 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 18:58:19.0996 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 18:58:19.0997 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "llama3:70b",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "EQUIPMENT",
            "LOCATION",
            "ORGANIZATION",
            "DATE"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 18:58:19.0999 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 18:58:19.0999 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 18:58:19.0999 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:58:19.0999 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 18:58:20.0000 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 18:58:20.0000 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 18:58:20.0003 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 18:58:20.0003 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 18:58:20.0006 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 18:58:20.0006 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:58:20.0006 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 18:58:20.0006 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:58:20.0006 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 18:58:20.0140 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 18:58:20.0140 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 718
2025-10-12 18:58:20.0140 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 718
2025-10-12 18:58:20.0193 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 18:58:20.0223 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 18:58:20.0223 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:58:20.0277 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 527 documents
2025-10-12 18:58:20.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/527
2025-10-12 18:58:20.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/527
2025-10-12 18:58:20.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/527
2025-10-12 18:58:20.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/527
2025-10-12 18:58:20.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/527
2025-10-12 18:58:20.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/527
2025-10-12 18:58:20.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/527
2025-10-12 18:58:20.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/527
2025-10-12 18:58:20.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/527
2025-10-12 18:58:20.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/527
2025-10-12 18:58:20.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/527
2025-10-12 18:58:20.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/527
2025-10-12 18:58:20.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/527
2025-10-12 18:58:20.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/527
2025-10-12 18:58:20.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/527
2025-10-12 18:58:20.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/527
2025-10-12 18:58:20.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/527
2025-10-12 18:58:20.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/527
2025-10-12 18:58:20.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/527
2025-10-12 18:58:20.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/527
2025-10-12 18:58:20.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/527
2025-10-12 18:58:20.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/527
2025-10-12 18:58:20.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/527
2025-10-12 18:58:20.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/527
2025-10-12 18:58:20.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/527
2025-10-12 18:58:20.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/527
2025-10-12 18:58:20.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/527
2025-10-12 18:58:20.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/527
2025-10-12 18:58:20.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/527
2025-10-12 18:58:20.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/527
2025-10-12 18:58:20.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/527
2025-10-12 18:58:20.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/527
2025-10-12 18:58:20.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/527
2025-10-12 18:58:20.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/527
2025-10-12 18:58:20.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/527
2025-10-12 18:58:20.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/527
2025-10-12 18:58:20.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/527
2025-10-12 18:58:20.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/527
2025-10-12 18:58:20.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/527
2025-10-12 18:58:20.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/527
2025-10-12 18:58:20.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/527
2025-10-12 18:58:20.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/527
2025-10-12 18:58:20.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/527
2025-10-12 18:58:20.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/527
2025-10-12 18:58:20.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/527
2025-10-12 18:58:20.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/527
2025-10-12 18:58:20.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/527
2025-10-12 18:58:20.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/527
2025-10-12 18:58:20.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/527
2025-10-12 18:58:20.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/527
2025-10-12 18:58:20.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/527
2025-10-12 18:58:20.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/527
2025-10-12 18:58:20.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/527
2025-10-12 18:58:20.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/527
2025-10-12 18:58:20.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/527
2025-10-12 18:58:20.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/527
2025-10-12 18:58:20.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/527
2025-10-12 18:58:20.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/527
2025-10-12 18:58:20.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/527
2025-10-12 18:58:20.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/527
2025-10-12 18:58:20.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/527
2025-10-12 18:58:20.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/527
2025-10-12 18:58:20.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/527
2025-10-12 18:58:20.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/527
2025-10-12 18:58:20.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/527
2025-10-12 18:58:20.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/527
2025-10-12 18:58:20.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/527
2025-10-12 18:58:20.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/527
2025-10-12 18:58:20.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  69/527
2025-10-12 18:58:20.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  70/527
2025-10-12 18:58:20.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  71/527
2025-10-12 18:58:20.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  72/527
2025-10-12 18:58:20.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  73/527
2025-10-12 18:58:20.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  74/527
2025-10-12 18:58:20.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  75/527
2025-10-12 18:58:20.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  76/527
2025-10-12 18:58:20.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  77/527
2025-10-12 18:58:20.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  78/527
2025-10-12 18:58:20.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  79/527
2025-10-12 18:58:20.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  80/527
2025-10-12 18:58:20.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  81/527
2025-10-12 18:58:20.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  82/527
2025-10-12 18:58:20.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  83/527
2025-10-12 18:58:20.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  84/527
2025-10-12 18:58:20.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  85/527
2025-10-12 18:58:20.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  86/527
2025-10-12 18:58:20.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  87/527
2025-10-12 18:58:20.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  88/527
2025-10-12 18:58:20.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  89/527
2025-10-12 18:58:20.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  90/527
2025-10-12 18:58:20.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  91/527
2025-10-12 18:58:20.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  92/527
2025-10-12 18:58:20.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  93/527
2025-10-12 18:58:20.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  94/527
2025-10-12 18:58:20.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  95/527
2025-10-12 18:58:20.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  96/527
2025-10-12 18:58:20.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  97/527
2025-10-12 18:58:20.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  98/527
2025-10-12 18:58:20.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  99/527
2025-10-12 18:58:20.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  100/527
2025-10-12 18:58:20.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  101/527
2025-10-12 18:58:20.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  102/527
2025-10-12 18:58:20.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  103/527
2025-10-12 18:58:20.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  104/527
2025-10-12 18:58:20.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  105/527
2025-10-12 18:58:20.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  106/527
2025-10-12 18:58:20.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  107/527
2025-10-12 18:58:20.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  108/527
2025-10-12 18:58:20.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  109/527
2025-10-12 18:58:20.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  110/527
2025-10-12 18:58:20.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  111/527
2025-10-12 18:58:20.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  112/527
2025-10-12 18:58:20.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  113/527
2025-10-12 18:58:20.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  114/527
2025-10-12 18:58:20.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  115/527
2025-10-12 18:58:20.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  116/527
2025-10-12 18:58:20.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  117/527
2025-10-12 18:58:20.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  118/527
2025-10-12 18:58:20.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  119/527
2025-10-12 18:58:20.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  120/527
2025-10-12 18:58:20.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  121/527
2025-10-12 18:58:20.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  122/527
2025-10-12 18:58:20.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  123/527
2025-10-12 18:58:20.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  124/527
2025-10-12 18:58:20.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  125/527
2025-10-12 18:58:20.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  126/527
2025-10-12 18:58:20.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  127/527
2025-10-12 18:58:20.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  128/527
2025-10-12 18:58:20.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  129/527
2025-10-12 18:58:20.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  130/527
2025-10-12 18:58:20.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  131/527
2025-10-12 18:58:20.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  132/527
2025-10-12 18:58:20.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  133/527
2025-10-12 18:58:20.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  134/527
2025-10-12 18:58:20.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  135/527
2025-10-12 18:58:20.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  136/527
2025-10-12 18:58:20.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  137/527
2025-10-12 18:58:20.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  138/527
2025-10-12 18:58:20.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  139/527
2025-10-12 18:58:20.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  140/527
2025-10-12 18:58:20.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  141/527
2025-10-12 18:58:20.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  142/527
2025-10-12 18:58:20.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  143/527
2025-10-12 18:58:20.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  144/527
2025-10-12 18:58:20.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  145/527
2025-10-12 18:58:20.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  146/527
2025-10-12 18:58:20.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  147/527
2025-10-12 18:58:20.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  148/527
2025-10-12 18:58:20.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  149/527
2025-10-12 18:58:20.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  150/527
2025-10-12 18:58:20.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  151/527
2025-10-12 18:58:20.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  152/527
2025-10-12 18:58:20.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  153/527
2025-10-12 18:58:20.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  154/527
2025-10-12 18:58:20.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  155/527
2025-10-12 18:58:20.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  156/527
2025-10-12 18:58:20.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  157/527
2025-10-12 18:58:20.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  158/527
2025-10-12 18:58:20.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  159/527
2025-10-12 18:58:20.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  160/527
2025-10-12 18:58:20.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  161/527
2025-10-12 18:58:20.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  162/527
2025-10-12 18:58:20.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  163/527
2025-10-12 18:58:20.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  164/527
2025-10-12 18:58:20.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  165/527
2025-10-12 18:58:20.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  166/527
2025-10-12 18:58:20.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  167/527
2025-10-12 18:58:20.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  168/527
2025-10-12 18:58:20.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  169/527
2025-10-12 18:58:20.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  170/527
2025-10-12 18:58:20.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  171/527
2025-10-12 18:58:20.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  172/527
2025-10-12 18:58:20.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  173/527
2025-10-12 18:58:20.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  174/527
2025-10-12 18:58:20.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  175/527
2025-10-12 18:58:20.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  176/527
2025-10-12 18:58:20.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  177/527
2025-10-12 18:58:20.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  178/527
2025-10-12 18:58:20.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  179/527
2025-10-12 18:58:20.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  180/527
2025-10-12 18:58:20.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  181/527
2025-10-12 18:58:20.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  182/527
2025-10-12 18:58:20.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  183/527
2025-10-12 18:58:20.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  184/527
2025-10-12 18:58:20.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  185/527
2025-10-12 18:58:20.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  186/527
2025-10-12 18:58:20.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  187/527
2025-10-12 18:58:20.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  188/527
2025-10-12 18:58:20.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  189/527
2025-10-12 18:58:20.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  190/527
2025-10-12 18:58:20.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  191/527
2025-10-12 18:58:20.0377 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  192/527
2025-10-12 18:58:20.0377 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  193/527
2025-10-12 18:58:20.0378 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  194/527
2025-10-12 18:58:20.0378 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  195/527
2025-10-12 18:58:20.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  196/527
2025-10-12 18:58:20.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  197/527
2025-10-12 18:58:20.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  198/527
2025-10-12 18:58:20.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  199/527
2025-10-12 18:58:20.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  200/527
2025-10-12 18:58:20.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  201/527
2025-10-12 18:58:20.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  202/527
2025-10-12 18:58:20.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  203/527
2025-10-12 18:58:20.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  204/527
2025-10-12 18:58:20.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  205/527
2025-10-12 18:58:20.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  206/527
2025-10-12 18:58:20.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  207/527
2025-10-12 18:58:20.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  208/527
2025-10-12 18:58:20.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  209/527
2025-10-12 18:58:20.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  210/527
2025-10-12 18:58:20.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  211/527
2025-10-12 18:58:20.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  212/527
2025-10-12 18:58:20.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  213/527
2025-10-12 18:58:20.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  214/527
2025-10-12 18:58:20.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  215/527
2025-10-12 18:58:20.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  216/527
2025-10-12 18:58:20.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  217/527
2025-10-12 18:58:20.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  218/527
2025-10-12 18:58:20.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  219/527
2025-10-12 18:58:20.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  220/527
2025-10-12 18:58:20.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  221/527
2025-10-12 18:58:20.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  222/527
2025-10-12 18:58:20.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  223/527
2025-10-12 18:58:20.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  224/527
2025-10-12 18:58:20.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  225/527
2025-10-12 18:58:20.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  226/527
2025-10-12 18:58:20.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  227/527
2025-10-12 18:58:20.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  228/527
2025-10-12 18:58:20.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  229/527
2025-10-12 18:58:20.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  230/527
2025-10-12 18:58:20.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  231/527
2025-10-12 18:58:20.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  232/527
2025-10-12 18:58:20.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  233/527
2025-10-12 18:58:20.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  234/527
2025-10-12 18:58:20.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  235/527
2025-10-12 18:58:20.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  236/527
2025-10-12 18:58:20.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  237/527
2025-10-12 18:58:20.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  238/527
2025-10-12 18:58:20.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  239/527
2025-10-12 18:58:20.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  240/527
2025-10-12 18:58:20.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  241/527
2025-10-12 18:58:20.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  242/527
2025-10-12 18:58:20.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  243/527
2025-10-12 18:58:20.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  244/527
2025-10-12 18:58:20.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  245/527
2025-10-12 18:58:20.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  246/527
2025-10-12 18:58:20.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  247/527
2025-10-12 18:58:20.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  248/527
2025-10-12 18:58:20.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  249/527
2025-10-12 18:58:20.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  250/527
2025-10-12 18:58:20.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  251/527
2025-10-12 18:58:20.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  252/527
2025-10-12 18:58:20.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  253/527
2025-10-12 18:58:20.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  254/527
2025-10-12 18:58:20.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  255/527
2025-10-12 18:58:20.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  256/527
2025-10-12 18:58:20.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  257/527
2025-10-12 18:58:20.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  258/527
2025-10-12 18:58:20.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  259/527
2025-10-12 18:58:20.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  260/527
2025-10-12 18:58:20.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  261/527
2025-10-12 18:58:20.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  262/527
2025-10-12 18:58:20.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  263/527
2025-10-12 18:58:20.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  264/527
2025-10-12 18:58:20.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  265/527
2025-10-12 18:58:20.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  266/527
2025-10-12 18:58:20.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  267/527
2025-10-12 18:58:20.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  268/527
2025-10-12 18:58:20.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  269/527
2025-10-12 18:58:20.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  270/527
2025-10-12 18:58:20.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  271/527
2025-10-12 18:58:20.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  272/527
2025-10-12 18:58:20.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  273/527
2025-10-12 18:58:20.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  274/527
2025-10-12 18:58:20.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  275/527
2025-10-12 18:58:20.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  276/527
2025-10-12 18:58:20.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  277/527
2025-10-12 18:58:20.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  278/527
2025-10-12 18:58:20.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  279/527
2025-10-12 18:58:20.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  280/527
2025-10-12 18:58:20.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  281/527
2025-10-12 18:58:20.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  282/527
2025-10-12 18:58:20.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  283/527
2025-10-12 18:58:20.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  284/527
2025-10-12 18:58:20.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  285/527
2025-10-12 18:58:20.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  286/527
2025-10-12 18:58:20.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  287/527
2025-10-12 18:58:20.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  288/527
2025-10-12 18:58:20.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  289/527
2025-10-12 18:58:20.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  290/527
2025-10-12 18:58:20.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  291/527
2025-10-12 18:58:20.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  292/527
2025-10-12 18:58:20.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  293/527
2025-10-12 18:58:20.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  294/527
2025-10-12 18:58:20.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  295/527
2025-10-12 18:58:20.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  296/527
2025-10-12 18:58:20.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  297/527
2025-10-12 18:58:20.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  298/527
2025-10-12 18:58:20.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  299/527
2025-10-12 18:58:20.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  300/527
2025-10-12 18:58:20.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  301/527
2025-10-12 18:58:20.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  302/527
2025-10-12 18:58:20.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  303/527
2025-10-12 18:58:20.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  304/527
2025-10-12 18:58:20.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  305/527
2025-10-12 18:58:20.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  306/527
2025-10-12 18:58:20.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  307/527
2025-10-12 18:58:20.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  308/527
2025-10-12 18:58:20.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  309/527
2025-10-12 18:58:20.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  310/527
2025-10-12 18:58:20.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  311/527
2025-10-12 18:58:20.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  312/527
2025-10-12 18:58:20.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  313/527
2025-10-12 18:58:20.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  314/527
2025-10-12 18:58:20.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  315/527
2025-10-12 18:58:20.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  316/527
2025-10-12 18:58:20.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  317/527
2025-10-12 18:58:20.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  318/527
2025-10-12 18:58:20.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  319/527
2025-10-12 18:58:20.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  320/527
2025-10-12 18:58:20.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  321/527
2025-10-12 18:58:20.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  322/527
2025-10-12 18:58:20.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  323/527
2025-10-12 18:58:20.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  324/527
2025-10-12 18:58:20.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  325/527
2025-10-12 18:58:20.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  326/527
2025-10-12 18:58:20.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  327/527
2025-10-12 18:58:20.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  328/527
2025-10-12 18:58:20.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  329/527
2025-10-12 18:58:20.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  330/527
2025-10-12 18:58:20.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  331/527
2025-10-12 18:58:20.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  332/527
2025-10-12 18:58:20.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  333/527
2025-10-12 18:58:20.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  334/527
2025-10-12 18:58:20.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  335/527
2025-10-12 18:58:20.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  336/527
2025-10-12 18:58:20.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  337/527
2025-10-12 18:58:20.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  338/527
2025-10-12 18:58:20.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  339/527
2025-10-12 18:58:20.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  340/527
2025-10-12 18:58:20.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  341/527
2025-10-12 18:58:20.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  342/527
2025-10-12 18:58:20.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  343/527
2025-10-12 18:58:20.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  344/527
2025-10-12 18:58:20.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  345/527
2025-10-12 18:58:20.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  346/527
2025-10-12 18:58:20.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  347/527
2025-10-12 18:58:20.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  348/527
2025-10-12 18:58:20.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  349/527
2025-10-12 18:58:20.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  350/527
2025-10-12 18:58:20.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  351/527
2025-10-12 18:58:20.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  352/527
2025-10-12 18:58:20.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  353/527
2025-10-12 18:58:20.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  354/527
2025-10-12 18:58:20.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  355/527
2025-10-12 18:58:20.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  356/527
2025-10-12 18:58:20.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  357/527
2025-10-12 18:58:20.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  358/527
2025-10-12 18:58:20.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  359/527
2025-10-12 18:58:20.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  360/527
2025-10-12 18:58:20.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  361/527
2025-10-12 18:58:20.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  362/527
2025-10-12 18:58:20.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  363/527
2025-10-12 18:58:20.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  364/527
2025-10-12 18:58:20.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  365/527
2025-10-12 18:58:20.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  366/527
2025-10-12 18:58:20.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  367/527
2025-10-12 18:58:20.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  368/527
2025-10-12 18:58:20.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  369/527
2025-10-12 18:58:20.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  370/527
2025-10-12 18:58:20.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  371/527
2025-10-12 18:58:20.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  372/527
2025-10-12 18:58:20.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  373/527
2025-10-12 18:58:20.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  374/527
2025-10-12 18:58:20.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  375/527
2025-10-12 18:58:20.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  376/527
2025-10-12 18:58:20.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  377/527
2025-10-12 18:58:20.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  378/527
2025-10-12 18:58:20.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  379/527
2025-10-12 18:58:20.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  380/527
2025-10-12 18:58:20.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  381/527
2025-10-12 18:58:20.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  382/527
2025-10-12 18:58:20.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  383/527
2025-10-12 18:58:20.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  384/527
2025-10-12 18:58:20.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  385/527
2025-10-12 18:58:20.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  386/527
2025-10-12 18:58:20.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  387/527
2025-10-12 18:58:20.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  388/527
2025-10-12 18:58:20.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  389/527
2025-10-12 18:58:20.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  390/527
2025-10-12 18:58:20.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  391/527
2025-10-12 18:58:20.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  392/527
2025-10-12 18:58:20.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  393/527
2025-10-12 18:58:20.0479 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  394/527
2025-10-12 18:58:20.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  395/527
2025-10-12 18:58:20.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  396/527
2025-10-12 18:58:20.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  397/527
2025-10-12 18:58:20.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  398/527
2025-10-12 18:58:20.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  399/527
2025-10-12 18:58:20.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  400/527
2025-10-12 18:58:20.0483 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  401/527
2025-10-12 18:58:20.0483 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  402/527
2025-10-12 18:58:20.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  403/527
2025-10-12 18:58:20.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  404/527
2025-10-12 18:58:20.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  405/527
2025-10-12 18:58:20.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  406/527
2025-10-12 18:58:20.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  407/527
2025-10-12 18:58:20.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  408/527
2025-10-12 18:58:20.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  409/527
2025-10-12 18:58:20.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  410/527
2025-10-12 18:58:20.0488 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  411/527
2025-10-12 18:58:20.0488 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  412/527
2025-10-12 18:58:20.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  413/527
2025-10-12 18:58:20.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  414/527
2025-10-12 18:58:20.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  415/527
2025-10-12 18:58:20.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  416/527
2025-10-12 18:58:20.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  417/527
2025-10-12 18:58:20.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  418/527
2025-10-12 18:58:20.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  419/527
2025-10-12 18:58:20.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  420/527
2025-10-12 18:58:20.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  421/527
2025-10-12 18:58:20.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  422/527
2025-10-12 18:58:20.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  423/527
2025-10-12 18:58:20.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  424/527
2025-10-12 18:58:20.0495 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  425/527
2025-10-12 18:58:20.0495 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  426/527
2025-10-12 18:58:20.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  427/527
2025-10-12 18:58:20.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  428/527
2025-10-12 18:58:20.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  429/527
2025-10-12 18:58:20.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  430/527
2025-10-12 18:58:20.0498 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  431/527
2025-10-12 18:58:20.0498 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  432/527
2025-10-12 18:58:20.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  433/527
2025-10-12 18:58:20.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  434/527
2025-10-12 18:58:20.0500 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  435/527
2025-10-12 18:58:20.0500 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  436/527
2025-10-12 18:58:20.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  437/527
2025-10-12 18:58:20.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  438/527
2025-10-12 18:58:20.0502 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  439/527
2025-10-12 18:58:20.0502 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  440/527
2025-10-12 18:58:20.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  441/527
2025-10-12 18:58:20.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  442/527
2025-10-12 18:58:20.0504 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  443/527
2025-10-12 18:58:20.0504 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  444/527
2025-10-12 18:58:20.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  445/527
2025-10-12 18:58:20.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  446/527
2025-10-12 18:58:20.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  447/527
2025-10-12 18:58:20.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  448/527
2025-10-12 18:58:20.0507 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  449/527
2025-10-12 18:58:20.0507 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  450/527
2025-10-12 18:58:20.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  451/527
2025-10-12 18:58:20.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  452/527
2025-10-12 18:58:20.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  453/527
2025-10-12 18:58:20.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  454/527
2025-10-12 18:58:20.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  455/527
2025-10-12 18:58:20.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  456/527
2025-10-12 18:58:20.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  457/527
2025-10-12 18:58:20.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  458/527
2025-10-12 18:58:20.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  459/527
2025-10-12 18:58:20.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  460/527
2025-10-12 18:58:20.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  461/527
2025-10-12 18:58:20.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  462/527
2025-10-12 18:58:20.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  463/527
2025-10-12 18:58:20.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  464/527
2025-10-12 18:58:20.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  465/527
2025-10-12 18:58:20.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  466/527
2025-10-12 18:58:20.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  467/527
2025-10-12 18:58:20.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  468/527
2025-10-12 18:58:20.0517 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  469/527
2025-10-12 18:58:20.0518 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  470/527
2025-10-12 18:58:20.0518 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  471/527
2025-10-12 18:58:20.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  472/527
2025-10-12 18:58:20.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  473/527
2025-10-12 18:58:20.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  474/527
2025-10-12 18:58:20.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  475/527
2025-10-12 18:58:20.0521 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  476/527
2025-10-12 18:58:20.0521 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  477/527
2025-10-12 18:58:20.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  478/527
2025-10-12 18:58:20.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  479/527
2025-10-12 18:58:20.0523 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  480/527
2025-10-12 18:58:20.0523 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  481/527
2025-10-12 18:58:20.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  482/527
2025-10-12 18:58:20.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  483/527
2025-10-12 18:58:20.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  484/527
2025-10-12 18:58:20.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  485/527
2025-10-12 18:58:20.0526 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  486/527
2025-10-12 18:58:20.0526 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  487/527
2025-10-12 18:58:20.0527 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  488/527
2025-10-12 18:58:20.0527 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  489/527
2025-10-12 18:58:20.0528 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  490/527
2025-10-12 18:58:20.0528 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  491/527
2025-10-12 18:58:20.0529 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  492/527
2025-10-12 18:58:20.0529 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  493/527
2025-10-12 18:58:20.0719 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  494/527
2025-10-12 18:58:20.0720 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  495/527
2025-10-12 18:58:20.0721 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  496/527
2025-10-12 18:58:20.0722 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  497/527
2025-10-12 18:58:20.0722 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  498/527
2025-10-12 18:58:20.0723 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  499/527
2025-10-12 18:58:20.0723 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  500/527
2025-10-12 18:58:20.0724 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  501/527
2025-10-12 18:58:20.0724 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  502/527
2025-10-12 18:58:20.0725 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  503/527
2025-10-12 18:58:20.0725 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  504/527
2025-10-12 18:58:20.0726 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  505/527
2025-10-12 18:58:20.0726 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  506/527
2025-10-12 18:58:20.0727 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  507/527
2025-10-12 18:58:20.0727 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  508/527
2025-10-12 18:58:20.0728 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  509/527
2025-10-12 18:58:20.0729 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  510/527
2025-10-12 18:58:20.0729 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  511/527
2025-10-12 18:58:20.0730 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  512/527
2025-10-12 18:58:20.0730 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  513/527
2025-10-12 18:58:20.0731 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  514/527
2025-10-12 18:58:20.0731 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  515/527
2025-10-12 18:58:20.0732 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  516/527
2025-10-12 18:58:20.0732 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  517/527
2025-10-12 18:58:20.0733 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  518/527
2025-10-12 18:58:20.0733 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  519/527
2025-10-12 18:58:20.0734 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  520/527
2025-10-12 18:58:20.0734 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  521/527
2025-10-12 18:58:20.0735 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  522/527
2025-10-12 18:58:20.0735 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  523/527
2025-10-12 18:58:20.0736 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  524/527
2025-10-12 18:58:20.0736 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  525/527
2025-10-12 18:58:20.0737 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  526/527
2025-10-12 18:58:20.0737 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  527/527
2025-10-12 18:58:20.0759 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-12 18:58:20.0760 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-12 18:58:20.0763 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-12 18:58:20.0763 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:58:20.0780 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:58:20.0818 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-12 18:58:20.0818 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-12 18:58:20.0822 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-12 18:58:20.0822 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:58:20.0856 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/extract_graph
2025-10-12 18:58:34.0685 - INFO - graphrag.logger.progress - extract graph progress: 1/527
2025-10-12 18:58:34.0689 - INFO - graphrag.logger.progress - extract graph progress: 2/527
2025-10-12 18:58:34.0691 - INFO - graphrag.logger.progress - extract graph progress: 3/527
2025-10-12 18:58:34.0693 - INFO - graphrag.logger.progress - extract graph progress: 4/527
2025-10-12 18:58:34.0695 - INFO - graphrag.logger.progress - extract graph progress: 5/527
2025-10-12 18:58:34.0697 - INFO - graphrag.logger.progress - extract graph progress: 6/527
2025-10-12 18:58:34.0701 - INFO - graphrag.logger.progress - extract graph progress: 7/527
2025-10-12 18:58:34.0705 - INFO - graphrag.logger.progress - extract graph progress: 8/527
2025-10-12 18:58:34.0709 - INFO - graphrag.logger.progress - extract graph progress: 9/527
2025-10-12 18:58:34.0713 - INFO - graphrag.logger.progress - extract graph progress: 10/527
2025-10-12 18:58:34.0716 - INFO - graphrag.logger.progress - extract graph progress: 11/527
2025-10-12 18:58:34.0719 - INFO - graphrag.logger.progress - extract graph progress: 12/527
2025-10-12 18:58:34.0721 - INFO - graphrag.logger.progress - extract graph progress: 13/527
2025-10-12 18:58:34.0723 - INFO - graphrag.logger.progress - extract graph progress: 14/527
2025-10-12 18:58:34.0725 - INFO - graphrag.logger.progress - extract graph progress: 15/527
2025-10-12 18:58:34.0728 - INFO - graphrag.logger.progress - extract graph progress: 16/527
2025-10-12 18:58:34.0731 - INFO - graphrag.logger.progress - extract graph progress: 17/527
2025-10-12 18:58:34.0734 - INFO - graphrag.logger.progress - extract graph progress: 18/527
2025-10-12 18:58:34.0736 - INFO - graphrag.logger.progress - extract graph progress: 19/527
2025-10-12 18:58:34.0737 - INFO - graphrag.logger.progress - extract graph progress: 20/527
2025-10-12 18:58:34.0739 - INFO - graphrag.logger.progress - extract graph progress: 21/527
2025-10-12 18:58:34.0741 - INFO - graphrag.logger.progress - extract graph progress: 22/527
2025-10-12 18:58:34.0743 - INFO - graphrag.logger.progress - extract graph progress: 23/527
2025-10-12 18:58:34.0746 - INFO - graphrag.logger.progress - extract graph progress: 24/527
2025-10-12 18:58:34.0749 - INFO - graphrag.logger.progress - extract graph progress: 25/527
2025-10-12 18:58:34.0753 - INFO - graphrag.logger.progress - extract graph progress: 26/527
2025-10-12 18:58:34.0757 - INFO - graphrag.logger.progress - extract graph progress: 27/527
2025-10-12 18:58:34.0760 - INFO - graphrag.logger.progress - extract graph progress: 28/527
2025-10-12 18:58:34.0763 - INFO - graphrag.logger.progress - extract graph progress: 29/527
2025-10-12 18:58:34.0765 - INFO - graphrag.logger.progress - extract graph progress: 30/527
2025-10-12 18:58:44.0642 - INFO - graphrag.logger.progress - extract graph progress: 31/527
2025-10-12 18:58:44.0645 - INFO - graphrag.logger.progress - extract graph progress: 32/527
2025-10-12 18:58:44.0647 - INFO - graphrag.logger.progress - extract graph progress: 33/527
2025-10-12 18:58:44.0649 - INFO - graphrag.logger.progress - extract graph progress: 34/527
2025-10-12 18:58:44.0651 - INFO - graphrag.logger.progress - extract graph progress: 35/527
2025-10-12 18:58:44.0652 - INFO - graphrag.logger.progress - extract graph progress: 36/527
2025-10-12 18:58:44.0654 - INFO - graphrag.logger.progress - extract graph progress: 37/527
2025-10-12 18:58:44.0656 - INFO - graphrag.logger.progress - extract graph progress: 38/527
2025-10-12 18:58:44.0658 - INFO - graphrag.logger.progress - extract graph progress: 39/527
2025-10-12 18:58:44.0660 - INFO - graphrag.logger.progress - extract graph progress: 40/527
2025-10-12 18:58:44.0662 - INFO - graphrag.logger.progress - extract graph progress: 41/527
2025-10-12 18:58:44.0663 - INFO - graphrag.logger.progress - extract graph progress: 42/527
2025-10-12 18:58:44.0665 - INFO - graphrag.logger.progress - extract graph progress: 43/527
2025-10-12 18:58:44.0667 - INFO - graphrag.logger.progress - extract graph progress: 44/527
2025-10-12 18:58:44.0669 - INFO - graphrag.logger.progress - extract graph progress: 45/527
2025-10-12 18:58:44.0671 - INFO - graphrag.logger.progress - extract graph progress: 46/527
2025-10-12 18:58:44.0673 - INFO - graphrag.logger.progress - extract graph progress: 47/527
2025-10-12 18:58:44.0675 - INFO - graphrag.logger.progress - extract graph progress: 48/527
2025-10-12 18:58:44.0676 - INFO - graphrag.logger.progress - extract graph progress: 49/527
2025-10-12 18:58:44.0678 - INFO - graphrag.logger.progress - extract graph progress: 50/527
2025-10-12 18:58:44.0680 - INFO - graphrag.logger.progress - extract graph progress: 51/527
2025-10-12 18:58:44.0682 - INFO - graphrag.logger.progress - extract graph progress: 52/527
2025-10-12 18:58:44.0684 - INFO - graphrag.logger.progress - extract graph progress: 53/527
2025-10-12 18:58:44.0686 - INFO - graphrag.logger.progress - extract graph progress: 54/527
2025-10-12 18:58:44.0687 - INFO - graphrag.logger.progress - extract graph progress: 55/527
2025-10-12 18:58:53.0673 - INFO - graphrag.logger.progress - extract graph progress: 56/527
2025-10-12 18:58:53.0678 - INFO - graphrag.logger.progress - extract graph progress: 57/527
2025-10-12 18:58:53.0682 - INFO - graphrag.logger.progress - extract graph progress: 58/527
2025-10-12 18:58:53.0685 - INFO - graphrag.logger.progress - extract graph progress: 59/527
2025-10-12 18:58:53.0687 - INFO - graphrag.logger.progress - extract graph progress: 60/527
2025-10-12 18:58:53.0688 - INFO - graphrag.logger.progress - extract graph progress: 61/527
2025-10-12 18:58:53.0690 - INFO - graphrag.logger.progress - extract graph progress: 62/527
2025-10-12 18:58:53.0693 - INFO - graphrag.logger.progress - extract graph progress: 63/527
2025-10-12 18:58:53.0696 - INFO - graphrag.logger.progress - extract graph progress: 64/527
2025-10-12 18:58:53.0698 - INFO - graphrag.logger.progress - extract graph progress: 65/527
2025-10-12 18:58:53.0700 - INFO - graphrag.logger.progress - extract graph progress: 66/527
2025-10-12 18:58:53.0702 - INFO - graphrag.logger.progress - extract graph progress: 67/527
2025-10-12 18:58:53.0707 - INFO - graphrag.logger.progress - extract graph progress: 68/527
2025-10-12 18:58:53.0710 - INFO - graphrag.logger.progress - extract graph progress: 69/527
2025-10-12 18:58:53.0713 - INFO - graphrag.logger.progress - extract graph progress: 70/527
2025-10-12 18:58:53.0714 - INFO - graphrag.logger.progress - extract graph progress: 71/527
2025-10-12 18:58:53.0716 - INFO - graphrag.logger.progress - extract graph progress: 72/527
2025-10-12 18:58:53.0719 - INFO - graphrag.logger.progress - extract graph progress: 73/527
2025-10-12 18:58:53.0722 - INFO - graphrag.logger.progress - extract graph progress: 74/527
2025-10-12 18:58:53.0726 - INFO - graphrag.logger.progress - extract graph progress: 75/527
2025-10-12 18:58:53.0727 - INFO - graphrag.logger.progress - extract graph progress: 76/527
2025-10-12 18:58:53.0729 - INFO - graphrag.logger.progress - extract graph progress: 77/527
2025-10-12 18:58:53.0732 - INFO - graphrag.logger.progress - extract graph progress: 78/527
2025-10-12 18:58:53.0736 - INFO - graphrag.logger.progress - extract graph progress: 79/527
2025-10-12 18:58:53.0739 - INFO - graphrag.logger.progress - extract graph progress: 80/527
2025-10-12 18:58:53.0743 - INFO - graphrag.logger.progress - extract graph progress: 81/527
2025-10-12 18:58:53.0748 - INFO - graphrag.logger.progress - extract graph progress: 82/527
2025-10-12 18:58:53.0752 - INFO - graphrag.logger.progress - extract graph progress: 83/527
2025-10-12 18:58:53.0755 - INFO - graphrag.logger.progress - extract graph progress: 84/527
2025-10-12 18:58:53.0759 - INFO - graphrag.logger.progress - extract graph progress: 85/527
2025-10-12 18:58:53.0763 - INFO - graphrag.logger.progress - extract graph progress: 86/527
2025-10-12 18:58:53.0766 - INFO - graphrag.logger.progress - extract graph progress: 87/527
2025-10-12 18:58:53.0769 - INFO - graphrag.logger.progress - extract graph progress: 88/527
2025-10-12 18:58:53.0773 - INFO - graphrag.logger.progress - extract graph progress: 89/527
2025-10-12 18:58:53.0777 - INFO - graphrag.logger.progress - extract graph progress: 90/527
2025-10-12 18:58:53.0781 - INFO - graphrag.logger.progress - extract graph progress: 91/527
2025-10-12 18:58:53.0784 - INFO - graphrag.logger.progress - extract graph progress: 92/527
2025-10-12 18:58:53.0788 - INFO - graphrag.logger.progress - extract graph progress: 93/527
2025-10-12 18:58:53.0792 - INFO - graphrag.logger.progress - extract graph progress: 94/527
2025-10-12 18:58:53.0796 - INFO - graphrag.logger.progress - extract graph progress: 95/527
2025-10-12 18:58:53.0799 - INFO - graphrag.logger.progress - extract graph progress: 96/527
2025-10-12 18:58:53.0803 - INFO - graphrag.logger.progress - extract graph progress: 97/527
2025-10-12 18:58:53.0805 - INFO - graphrag.logger.progress - extract graph progress: 98/527
2025-10-12 18:58:53.0809 - INFO - graphrag.logger.progress - extract graph progress: 99/527
2025-10-12 18:58:53.0813 - INFO - graphrag.logger.progress - extract graph progress: 100/527
2025-10-12 18:58:53.0817 - INFO - graphrag.logger.progress - extract graph progress: 101/527
2025-10-12 18:58:53.0819 - INFO - graphrag.logger.progress - extract graph progress: 102/527
2025-10-12 18:58:53.0820 - INFO - graphrag.logger.progress - extract graph progress: 103/527
2025-10-12 18:58:53.0822 - INFO - graphrag.logger.progress - extract graph progress: 104/527
2025-10-12 18:58:53.0825 - INFO - graphrag.logger.progress - extract graph progress: 105/527
2025-10-12 18:58:53.0829 - INFO - graphrag.logger.progress - extract graph progress: 106/527
2025-10-12 18:58:53.0831 - INFO - graphrag.logger.progress - extract graph progress: 107/527
2025-10-12 18:58:53.0833 - INFO - graphrag.logger.progress - extract graph progress: 108/527
2025-10-12 18:58:53.0835 - INFO - graphrag.logger.progress - extract graph progress: 109/527
2025-10-12 18:58:53.0836 - INFO - graphrag.logger.progress - extract graph progress: 110/527
2025-10-12 18:58:53.0838 - INFO - graphrag.logger.progress - extract graph progress: 111/527
2025-10-12 18:58:53.0840 - INFO - graphrag.logger.progress - extract graph progress: 112/527
2025-10-12 18:58:53.0842 - INFO - graphrag.logger.progress - extract graph progress: 113/527
2025-10-12 18:58:53.0844 - INFO - graphrag.logger.progress - extract graph progress: 114/527
2025-10-12 18:58:53.0846 - INFO - graphrag.logger.progress - extract graph progress: 115/527
2025-10-12 18:58:53.0848 - INFO - graphrag.logger.progress - extract graph progress: 116/527
2025-10-12 18:58:53.0849 - INFO - graphrag.logger.progress - extract graph progress: 117/527
2025-10-12 18:58:53.0851 - INFO - graphrag.logger.progress - extract graph progress: 118/527
2025-10-12 18:58:53.0853 - INFO - graphrag.logger.progress - extract graph progress: 119/527
2025-10-12 18:58:53.0855 - INFO - graphrag.logger.progress - extract graph progress: 120/527
2025-10-12 18:58:53.0857 - INFO - graphrag.logger.progress - extract graph progress: 121/527
2025-10-12 18:59:03.0728 - INFO - graphrag.logger.progress - extract graph progress: 122/527
2025-10-12 18:59:03.0730 - INFO - graphrag.logger.progress - extract graph progress: 123/527
2025-10-12 18:59:03.0732 - INFO - graphrag.logger.progress - extract graph progress: 124/527
2025-10-12 18:59:03.0734 - INFO - graphrag.logger.progress - extract graph progress: 125/527
2025-10-12 18:59:14.0433 - INFO - graphrag.logger.progress - extract graph progress: 126/527
2025-10-12 18:59:14.0436 - INFO - graphrag.logger.progress - extract graph progress: 127/527
2025-10-12 18:59:14.0438 - INFO - graphrag.logger.progress - extract graph progress: 128/527
2025-10-12 18:59:14.0440 - INFO - graphrag.logger.progress - extract graph progress: 129/527
2025-10-12 18:59:14.0442 - INFO - graphrag.logger.progress - extract graph progress: 130/527
2025-10-12 18:59:14.0444 - INFO - graphrag.logger.progress - extract graph progress: 131/527
2025-10-12 18:59:14.0446 - INFO - graphrag.logger.progress - extract graph progress: 132/527
2025-10-12 18:59:14.0448 - INFO - graphrag.logger.progress - extract graph progress: 133/527
2025-10-12 18:59:14.0450 - INFO - graphrag.logger.progress - extract graph progress: 134/527
2025-10-12 18:59:14.0451 - INFO - graphrag.logger.progress - extract graph progress: 135/527
2025-10-12 18:59:14.0454 - INFO - graphrag.logger.progress - extract graph progress: 136/527
2025-10-12 18:59:14.0457 - INFO - graphrag.logger.progress - extract graph progress: 137/527
2025-10-12 18:59:14.0461 - INFO - graphrag.logger.progress - extract graph progress: 138/527
2025-10-12 18:59:14.0463 - INFO - graphrag.logger.progress - extract graph progress: 139/527
2025-10-12 18:59:14.0465 - INFO - graphrag.logger.progress - extract graph progress: 140/527
2025-10-12 18:59:14.0468 - INFO - graphrag.logger.progress - extract graph progress: 141/527
2025-10-12 18:59:14.0472 - INFO - graphrag.logger.progress - extract graph progress: 142/527
2025-10-12 18:59:14.0475 - INFO - graphrag.logger.progress - extract graph progress: 143/527
2025-10-12 18:59:14.0478 - INFO - graphrag.logger.progress - extract graph progress: 144/527
2025-10-12 18:59:14.0480 - INFO - graphrag.logger.progress - extract graph progress: 145/527
2025-10-12 18:59:14.0481 - INFO - graphrag.logger.progress - extract graph progress: 146/527
2025-10-12 18:59:14.0483 - INFO - graphrag.logger.progress - extract graph progress: 147/527
2025-10-12 18:59:14.0486 - INFO - graphrag.logger.progress - extract graph progress: 148/527
2025-10-12 18:59:14.0489 - INFO - graphrag.logger.progress - extract graph progress: 149/527
2025-10-12 18:59:20.0728 - INFO - graphrag.logger.progress - extract graph progress: 150/527
2025-10-12 18:59:20.0730 - INFO - graphrag.logger.progress - extract graph progress: 151/527
2025-10-12 18:59:20.0732 - INFO - graphrag.logger.progress - extract graph progress: 152/527
2025-10-12 18:59:20.0734 - INFO - graphrag.logger.progress - extract graph progress: 153/527
2025-10-12 18:59:32.0587 - INFO - graphrag.logger.progress - extract graph progress: 154/527
2025-10-12 18:59:32.0591 - INFO - graphrag.logger.progress - extract graph progress: 155/527
2025-10-12 18:59:32.0595 - INFO - graphrag.logger.progress - extract graph progress: 156/527
2025-10-12 18:59:32.0598 - INFO - graphrag.logger.progress - extract graph progress: 157/527
2025-10-12 18:59:32.0602 - INFO - graphrag.logger.progress - extract graph progress: 158/527
2025-10-12 18:59:32.0605 - INFO - graphrag.logger.progress - extract graph progress: 159/527
2025-10-12 18:59:32.0608 - INFO - graphrag.logger.progress - extract graph progress: 160/527
2025-10-12 18:59:32.0609 - INFO - graphrag.logger.progress - extract graph progress: 161/527
2025-10-12 18:59:32.0611 - INFO - graphrag.logger.progress - extract graph progress: 162/527
2025-10-12 18:59:32.0614 - INFO - graphrag.logger.progress - extract graph progress: 163/527
2025-10-12 18:59:32.0617 - INFO - graphrag.logger.progress - extract graph progress: 164/527
2025-10-12 18:59:32.0620 - INFO - graphrag.logger.progress - extract graph progress: 165/527
2025-10-12 18:59:32.0621 - INFO - graphrag.logger.progress - extract graph progress: 166/527
2025-10-12 18:59:32.0623 - INFO - graphrag.logger.progress - extract graph progress: 167/527
2025-10-12 18:59:32.0625 - INFO - graphrag.logger.progress - extract graph progress: 168/527
2025-10-12 18:59:32.0629 - INFO - graphrag.logger.progress - extract graph progress: 169/527
2025-10-12 18:59:32.0632 - INFO - graphrag.logger.progress - extract graph progress: 170/527
2025-10-12 18:59:43.0889 - INFO - graphrag.logger.progress - extract graph progress: 171/527
2025-10-12 18:59:43.0892 - INFO - graphrag.logger.progress - extract graph progress: 172/527
2025-10-12 18:59:43.0896 - INFO - graphrag.logger.progress - extract graph progress: 173/527
2025-10-12 18:59:43.0899 - INFO - graphrag.logger.progress - extract graph progress: 174/527
2025-10-12 18:59:43.0902 - INFO - graphrag.logger.progress - extract graph progress: 175/527
2025-10-12 18:59:43.0905 - INFO - graphrag.logger.progress - extract graph progress: 176/527
2025-10-12 18:59:43.0909 - INFO - graphrag.logger.progress - extract graph progress: 177/527
2025-10-12 18:59:43.0912 - INFO - graphrag.logger.progress - extract graph progress: 178/527
2025-10-12 18:59:43.0916 - INFO - graphrag.logger.progress - extract graph progress: 179/527
2025-10-12 18:59:43.0920 - INFO - graphrag.logger.progress - extract graph progress: 180/527
2025-10-12 18:59:43.0923 - INFO - graphrag.logger.progress - extract graph progress: 181/527
2025-10-12 18:59:43.0928 - INFO - graphrag.logger.progress - extract graph progress: 182/527
2025-10-12 18:59:43.0930 - INFO - graphrag.logger.progress - extract graph progress: 183/527
2025-10-12 18:59:43.0932 - INFO - graphrag.logger.progress - extract graph progress: 184/527
2025-10-12 18:59:43.0935 - INFO - graphrag.logger.progress - extract graph progress: 185/527
2025-10-12 18:59:43.0938 - INFO - graphrag.logger.progress - extract graph progress: 186/527
2025-10-12 18:59:43.0941 - INFO - graphrag.logger.progress - extract graph progress: 187/527
2025-10-12 18:59:43.0942 - INFO - graphrag.logger.progress - extract graph progress: 188/527
2025-10-12 18:59:43.0947 - INFO - graphrag.logger.progress - extract graph progress: 189/527
2025-10-12 18:59:43.0951 - INFO - graphrag.logger.progress - extract graph progress: 190/527
2025-10-12 18:59:43.0954 - INFO - graphrag.logger.progress - extract graph progress: 191/527
2025-10-12 18:59:43.0957 - INFO - graphrag.logger.progress - extract graph progress: 192/527
2025-10-12 18:59:43.0960 - INFO - graphrag.logger.progress - extract graph progress: 193/527
2025-10-12 18:59:43.0961 - INFO - graphrag.logger.progress - extract graph progress: 194/527
2025-10-12 18:59:43.0963 - INFO - graphrag.logger.progress - extract graph progress: 195/527
2025-10-12 18:59:43.0966 - INFO - graphrag.logger.progress - extract graph progress: 196/527
2025-10-12 18:59:43.0970 - INFO - graphrag.logger.progress - extract graph progress: 197/527
2025-10-12 18:59:43.0973 - INFO - graphrag.logger.progress - extract graph progress: 198/527
2025-10-12 18:59:43.0977 - INFO - graphrag.logger.progress - extract graph progress: 199/527
2025-10-12 18:59:43.0981 - INFO - graphrag.logger.progress - extract graph progress: 200/527
2025-10-12 18:59:43.0984 - INFO - graphrag.logger.progress - extract graph progress: 201/527
2025-10-12 18:59:43.0987 - INFO - graphrag.logger.progress - extract graph progress: 202/527
2025-10-12 18:59:43.0988 - INFO - graphrag.logger.progress - extract graph progress: 203/527
2025-10-12 18:59:43.0990 - INFO - graphrag.logger.progress - extract graph progress: 204/527
2025-10-12 18:59:43.0993 - INFO - graphrag.logger.progress - extract graph progress: 205/527
2025-10-12 18:59:43.0996 - INFO - graphrag.logger.progress - extract graph progress: 206/527
2025-10-12 18:59:43.0999 - INFO - graphrag.logger.progress - extract graph progress: 207/527
2025-10-12 18:59:44.0000 - INFO - graphrag.logger.progress - extract graph progress: 208/527
2025-10-12 18:59:44.0002 - INFO - graphrag.logger.progress - extract graph progress: 209/527
2025-10-12 18:59:44.0005 - INFO - graphrag.logger.progress - extract graph progress: 210/527
2025-10-12 18:59:44.0008 - INFO - graphrag.logger.progress - extract graph progress: 211/527
2025-10-12 18:59:44.0011 - INFO - graphrag.logger.progress - extract graph progress: 212/527
2025-10-12 18:59:44.0013 - INFO - graphrag.logger.progress - extract graph progress: 213/527
2025-10-12 18:59:44.0015 - INFO - graphrag.logger.progress - extract graph progress: 214/527
2025-10-12 18:59:44.0018 - INFO - graphrag.logger.progress - extract graph progress: 215/527
2025-10-12 18:59:44.0022 - INFO - graphrag.logger.progress - extract graph progress: 216/527
2025-10-12 18:59:44.0025 - INFO - graphrag.logger.progress - extract graph progress: 217/527
2025-10-12 18:59:44.0028 - INFO - graphrag.logger.progress - extract graph progress: 218/527
2025-10-12 18:59:44.0030 - INFO - graphrag.logger.progress - extract graph progress: 219/527
2025-10-12 18:59:44.0031 - INFO - graphrag.logger.progress - extract graph progress: 220/527
2025-10-12 18:59:44.0033 - INFO - graphrag.logger.progress - extract graph progress: 221/527
2025-10-12 18:59:44.0035 - INFO - graphrag.logger.progress - extract graph progress: 222/527
2025-10-12 18:59:44.0040 - INFO - graphrag.logger.progress - extract graph progress: 223/527
2025-10-12 18:59:44.0042 - INFO - graphrag.logger.progress - extract graph progress: 224/527
2025-10-12 18:59:44.0045 - INFO - graphrag.logger.progress - extract graph progress: 225/527
2025-10-12 18:59:44.0048 - INFO - graphrag.logger.progress - extract graph progress: 226/527
2025-10-12 18:59:44.0051 - INFO - graphrag.logger.progress - extract graph progress: 227/527
2025-10-12 18:59:44.0052 - INFO - graphrag.logger.progress - extract graph progress: 228/527
2025-10-12 18:59:44.0054 - INFO - graphrag.logger.progress - extract graph progress: 229/527
2025-10-12 18:59:44.0056 - INFO - graphrag.logger.progress - extract graph progress: 230/527
2025-10-12 18:59:44.0060 - INFO - graphrag.logger.progress - extract graph progress: 231/527
2025-10-12 18:59:44.0062 - INFO - graphrag.logger.progress - extract graph progress: 232/527
2025-10-12 18:59:44.0064 - INFO - graphrag.logger.progress - extract graph progress: 233/527
2025-10-12 18:59:44.0067 - INFO - graphrag.logger.progress - extract graph progress: 234/527
2025-10-12 18:59:44.0070 - INFO - graphrag.logger.progress - extract graph progress: 235/527
2025-10-12 18:59:44.0073 - INFO - graphrag.logger.progress - extract graph progress: 236/527
2025-10-12 18:59:44.0074 - INFO - graphrag.logger.progress - extract graph progress: 237/527
2025-10-12 18:59:44.0076 - INFO - graphrag.logger.progress - extract graph progress: 238/527
2025-10-12 18:59:44.0079 - INFO - graphrag.logger.progress - extract graph progress: 239/527
2025-10-12 18:59:44.0082 - INFO - graphrag.logger.progress - extract graph progress: 240/527
2025-10-12 18:59:44.0085 - INFO - graphrag.logger.progress - extract graph progress: 241/527
2025-10-12 18:59:44.0086 - INFO - graphrag.logger.progress - extract graph progress: 242/527
2025-10-12 18:59:44.0089 - INFO - graphrag.logger.progress - extract graph progress: 243/527
2025-10-12 18:59:44.0092 - INFO - graphrag.logger.progress - extract graph progress: 244/527
2025-10-12 18:59:44.0095 - INFO - graphrag.logger.progress - extract graph progress: 245/527
2025-10-12 18:59:44.0096 - INFO - graphrag.logger.progress - extract graph progress: 246/527
2025-10-12 18:59:44.0099 - INFO - graphrag.logger.progress - extract graph progress: 247/527
2025-10-12 18:59:44.0102 - INFO - graphrag.logger.progress - extract graph progress: 248/527
2025-10-12 18:59:44.0104 - INFO - graphrag.logger.progress - extract graph progress: 249/527
2025-10-12 18:59:44.0107 - INFO - graphrag.logger.progress - extract graph progress: 250/527
2025-10-12 18:59:44.0110 - INFO - graphrag.logger.progress - extract graph progress: 251/527
2025-10-12 18:59:44.0114 - INFO - graphrag.logger.progress - extract graph progress: 252/527
2025-10-12 18:59:44.0117 - INFO - graphrag.logger.progress - extract graph progress: 253/527
2025-10-12 18:59:44.0119 - INFO - graphrag.logger.progress - extract graph progress: 254/527
2025-10-12 18:59:44.0123 - INFO - graphrag.logger.progress - extract graph progress: 255/527
2025-10-12 18:59:44.0126 - INFO - graphrag.logger.progress - extract graph progress: 256/527
2025-10-12 18:59:44.0128 - INFO - graphrag.logger.progress - extract graph progress: 257/527
2025-10-12 18:59:44.0129 - INFO - graphrag.logger.progress - extract graph progress: 258/527
2025-10-12 18:59:44.0131 - INFO - graphrag.logger.progress - extract graph progress: 259/527
2025-10-12 18:59:44.0133 - INFO - graphrag.logger.progress - extract graph progress: 260/527
2025-10-12 18:59:44.0136 - INFO - graphrag.logger.progress - extract graph progress: 261/527
2025-10-12 18:59:44.0140 - INFO - graphrag.logger.progress - extract graph progress: 262/527
2025-10-12 18:59:44.0142 - INFO - graphrag.logger.progress - extract graph progress: 263/527
2025-10-12 18:59:44.0143 - INFO - graphrag.logger.progress - extract graph progress: 264/527
2025-10-12 18:59:44.0145 - INFO - graphrag.logger.progress - extract graph progress: 265/527
2025-10-12 18:59:44.0147 - INFO - graphrag.logger.progress - extract graph progress: 266/527
2025-10-12 18:59:44.0151 - INFO - graphrag.logger.progress - extract graph progress: 267/527
2025-10-12 18:59:44.0154 - INFO - graphrag.logger.progress - extract graph progress: 268/527
2025-10-12 18:59:44.0158 - INFO - graphrag.logger.progress - extract graph progress: 269/527
2025-10-12 18:59:44.0161 - INFO - graphrag.logger.progress - extract graph progress: 270/527
2025-10-12 18:59:44.0164 - INFO - graphrag.logger.progress - extract graph progress: 271/527
2025-10-12 18:59:44.0168 - INFO - graphrag.logger.progress - extract graph progress: 272/527
2025-10-12 18:59:44.0171 - INFO - graphrag.logger.progress - extract graph progress: 273/527
2025-10-12 18:59:44.0173 - INFO - graphrag.logger.progress - extract graph progress: 274/527
2025-10-12 18:59:44.0177 - INFO - graphrag.logger.progress - extract graph progress: 275/527
2025-10-12 18:59:44.0180 - INFO - graphrag.logger.progress - extract graph progress: 276/527
2025-10-12 18:59:44.0184 - INFO - graphrag.logger.progress - extract graph progress: 277/527
2025-10-12 18:59:44.0187 - INFO - graphrag.logger.progress - extract graph progress: 278/527
2025-10-12 18:59:44.0191 - INFO - graphrag.logger.progress - extract graph progress: 279/527
2025-10-12 18:59:44.0194 - INFO - graphrag.logger.progress - extract graph progress: 280/527
2025-10-12 18:59:44.0196 - INFO - graphrag.logger.progress - extract graph progress: 281/527
2025-10-12 18:59:44.0197 - INFO - graphrag.logger.progress - extract graph progress: 282/527
2025-10-12 18:59:44.0199 - INFO - graphrag.logger.progress - extract graph progress: 283/527
2025-10-12 18:59:44.0202 - INFO - graphrag.logger.progress - extract graph progress: 284/527
2025-10-12 18:59:44.0205 - INFO - graphrag.logger.progress - extract graph progress: 285/527
2025-10-12 18:59:44.0207 - INFO - graphrag.logger.progress - extract graph progress: 286/527
2025-10-12 18:59:44.0210 - INFO - graphrag.logger.progress - extract graph progress: 287/527
2025-10-12 18:59:44.0213 - INFO - graphrag.logger.progress - extract graph progress: 288/527
2025-10-12 18:59:44.0215 - INFO - graphrag.logger.progress - extract graph progress: 289/527
2025-10-12 18:59:44.0216 - INFO - graphrag.logger.progress - extract graph progress: 290/527
2025-10-12 18:59:44.0218 - INFO - graphrag.logger.progress - extract graph progress: 291/527
2025-10-12 18:59:44.0221 - INFO - graphrag.logger.progress - extract graph progress: 292/527
2025-10-12 18:59:44.0225 - INFO - graphrag.logger.progress - extract graph progress: 293/527
2025-10-12 18:59:44.0227 - INFO - graphrag.logger.progress - extract graph progress: 294/527
2025-10-12 18:59:44.0228 - INFO - graphrag.logger.progress - extract graph progress: 295/527
2025-10-12 18:59:44.0230 - INFO - graphrag.logger.progress - extract graph progress: 296/527
2025-10-12 18:59:44.0234 - INFO - graphrag.logger.progress - extract graph progress: 297/527
2025-10-12 18:59:44.0238 - INFO - graphrag.logger.progress - extract graph progress: 298/527
2025-10-12 18:59:44.0241 - INFO - graphrag.logger.progress - extract graph progress: 299/527
2025-10-12 18:59:44.0244 - INFO - graphrag.logger.progress - extract graph progress: 300/527
2025-10-12 18:59:44.0247 - INFO - graphrag.logger.progress - extract graph progress: 301/527
2025-10-12 18:59:44.0250 - INFO - graphrag.logger.progress - extract graph progress: 302/527
2025-10-12 18:59:44.0251 - INFO - graphrag.logger.progress - extract graph progress: 303/527
2025-10-12 18:59:44.0253 - INFO - graphrag.logger.progress - extract graph progress: 304/527
2025-10-12 18:59:44.0255 - INFO - graphrag.logger.progress - extract graph progress: 305/527
2025-10-12 18:59:44.0259 - INFO - graphrag.logger.progress - extract graph progress: 306/527
2025-10-12 18:59:44.0262 - INFO - graphrag.logger.progress - extract graph progress: 307/527
2025-10-12 18:59:44.0264 - INFO - graphrag.logger.progress - extract graph progress: 308/527
2025-10-12 18:59:44.0265 - INFO - graphrag.logger.progress - extract graph progress: 309/527
2025-10-12 18:59:44.0268 - INFO - graphrag.logger.progress - extract graph progress: 310/527
2025-10-12 18:59:44.0272 - INFO - graphrag.logger.progress - extract graph progress: 311/527
2025-10-12 18:59:44.0276 - INFO - graphrag.logger.progress - extract graph progress: 312/527
2025-10-12 18:59:44.0279 - INFO - graphrag.logger.progress - extract graph progress: 313/527
2025-10-12 18:59:44.0283 - INFO - graphrag.logger.progress - extract graph progress: 314/527
2025-10-12 18:59:44.0285 - INFO - graphrag.logger.progress - extract graph progress: 315/527
2025-10-12 18:59:44.0286 - INFO - graphrag.logger.progress - extract graph progress: 316/527
2025-10-12 18:59:44.0288 - INFO - graphrag.logger.progress - extract graph progress: 317/527
2025-10-12 18:59:44.0292 - INFO - graphrag.logger.progress - extract graph progress: 318/527
2025-10-12 18:59:44.0295 - INFO - graphrag.logger.progress - extract graph progress: 319/527
2025-10-12 18:59:44.0297 - INFO - graphrag.logger.progress - extract graph progress: 320/527
2025-10-12 18:59:44.0299 - INFO - graphrag.logger.progress - extract graph progress: 321/527
2025-10-12 18:59:44.0302 - INFO - graphrag.logger.progress - extract graph progress: 322/527
2025-10-12 18:59:44.0305 - INFO - graphrag.logger.progress - extract graph progress: 323/527
2025-10-12 18:59:44.0306 - INFO - graphrag.logger.progress - extract graph progress: 324/527
2025-10-12 18:59:44.0309 - INFO - graphrag.logger.progress - extract graph progress: 325/527
2025-10-12 18:59:44.0314 - INFO - graphrag.logger.progress - extract graph progress: 326/527
2025-10-12 18:59:44.0317 - INFO - graphrag.logger.progress - extract graph progress: 327/527
2025-10-12 18:59:44.0321 - INFO - graphrag.logger.progress - extract graph progress: 328/527
2025-10-12 18:59:44.0323 - INFO - graphrag.logger.progress - extract graph progress: 329/527
2025-10-12 18:59:44.0325 - INFO - graphrag.logger.progress - extract graph progress: 330/527
2025-10-12 18:59:44.0326 - INFO - graphrag.logger.progress - extract graph progress: 331/527
2025-10-12 18:59:44.0329 - INFO - graphrag.logger.progress - extract graph progress: 332/527
2025-10-12 18:59:44.0332 - INFO - graphrag.logger.progress - extract graph progress: 333/527
2025-10-12 18:59:44.0335 - INFO - graphrag.logger.progress - extract graph progress: 334/527
2025-10-12 18:59:44.0337 - INFO - graphrag.logger.progress - extract graph progress: 335/527
2025-10-12 18:59:44.0338 - INFO - graphrag.logger.progress - extract graph progress: 336/527
2025-10-12 18:59:44.0340 - INFO - graphrag.logger.progress - extract graph progress: 337/527
2025-10-12 18:59:44.0344 - INFO - graphrag.logger.progress - extract graph progress: 338/527
2025-10-12 18:59:44.0346 - INFO - graphrag.logger.progress - extract graph progress: 339/527
2025-10-12 18:59:44.0348 - INFO - graphrag.logger.progress - extract graph progress: 340/527
2025-10-12 18:59:53.0553 - INFO - graphrag.logger.progress - extract graph progress: 341/527
2025-10-12 18:59:53.0558 - INFO - graphrag.logger.progress - extract graph progress: 342/527
2025-10-12 18:59:53.0561 - INFO - graphrag.logger.progress - extract graph progress: 343/527
2025-10-12 18:59:53.0565 - INFO - graphrag.logger.progress - extract graph progress: 344/527
2025-10-12 18:59:53.0569 - INFO - graphrag.logger.progress - extract graph progress: 345/527
2025-10-12 18:59:53.0572 - INFO - graphrag.logger.progress - extract graph progress: 346/527
2025-10-12 18:59:53.0576 - INFO - graphrag.logger.progress - extract graph progress: 347/527
2025-10-12 18:59:53.0580 - INFO - graphrag.logger.progress - extract graph progress: 348/527
2025-10-12 18:59:53.0583 - INFO - graphrag.logger.progress - extract graph progress: 349/527
2025-10-12 18:59:53.0587 - INFO - graphrag.logger.progress - extract graph progress: 350/527
2025-10-12 18:59:53.0590 - INFO - graphrag.logger.progress - extract graph progress: 351/527
2025-10-12 18:59:53.0594 - INFO - graphrag.logger.progress - extract graph progress: 352/527
2025-10-12 18:59:53.0598 - INFO - graphrag.logger.progress - extract graph progress: 353/527
2025-10-12 18:59:53.0601 - INFO - graphrag.logger.progress - extract graph progress: 354/527
2025-10-12 18:59:53.0605 - INFO - graphrag.logger.progress - extract graph progress: 355/527
2025-10-12 18:59:53.0609 - INFO - graphrag.logger.progress - extract graph progress: 356/527
2025-10-12 18:59:53.0612 - INFO - graphrag.logger.progress - extract graph progress: 357/527
2025-10-12 18:59:53.0617 - INFO - graphrag.logger.progress - extract graph progress: 358/527
2025-10-12 18:59:53.0620 - INFO - graphrag.logger.progress - extract graph progress: 359/527
2025-10-12 18:59:53.0624 - INFO - graphrag.logger.progress - extract graph progress: 360/527
2025-10-12 18:59:53.0628 - INFO - graphrag.logger.progress - extract graph progress: 361/527
2025-10-12 18:59:53.0631 - INFO - graphrag.logger.progress - extract graph progress: 362/527
2025-10-12 18:59:53.0635 - INFO - graphrag.logger.progress - extract graph progress: 363/527
2025-10-12 18:59:53.0639 - INFO - graphrag.logger.progress - extract graph progress: 364/527
2025-10-12 18:59:53.0642 - INFO - graphrag.logger.progress - extract graph progress: 365/527
2025-10-12 18:59:53.0646 - INFO - graphrag.logger.progress - extract graph progress: 366/527
2025-10-12 18:59:53.0650 - INFO - graphrag.logger.progress - extract graph progress: 367/527
2025-10-12 18:59:53.0653 - INFO - graphrag.logger.progress - extract graph progress: 368/527
2025-10-12 18:59:53.0657 - INFO - graphrag.logger.progress - extract graph progress: 369/527
2025-10-12 18:59:53.0661 - INFO - graphrag.logger.progress - extract graph progress: 370/527
2025-10-12 18:59:53.0664 - INFO - graphrag.logger.progress - extract graph progress: 371/527
2025-10-12 18:59:53.0668 - INFO - graphrag.logger.progress - extract graph progress: 372/527
2025-10-12 18:59:53.0671 - INFO - graphrag.logger.progress - extract graph progress: 373/527
2025-10-12 18:59:53.0675 - INFO - graphrag.logger.progress - extract graph progress: 374/527
2025-10-12 18:59:53.0679 - INFO - graphrag.logger.progress - extract graph progress: 375/527
2025-10-12 18:59:53.0682 - INFO - graphrag.logger.progress - extract graph progress: 376/527
2025-10-12 18:59:53.0686 - INFO - graphrag.logger.progress - extract graph progress: 377/527
2025-10-12 18:59:53.0690 - INFO - graphrag.logger.progress - extract graph progress: 378/527
2025-10-12 18:59:53.0693 - INFO - graphrag.logger.progress - extract graph progress: 379/527
2025-10-12 18:59:53.0697 - INFO - graphrag.logger.progress - extract graph progress: 380/527
2025-10-12 18:59:53.0701 - INFO - graphrag.logger.progress - extract graph progress: 381/527
2025-10-12 18:59:53.0704 - INFO - graphrag.logger.progress - extract graph progress: 382/527
2025-10-12 18:59:53.0708 - INFO - graphrag.logger.progress - extract graph progress: 383/527
2025-10-12 18:59:53.0712 - INFO - graphrag.logger.progress - extract graph progress: 384/527
2025-10-12 18:59:58.0970 - INFO - graphrag.logger.progress - extract graph progress: 385/527
2025-10-12 18:59:58.0975 - INFO - graphrag.logger.progress - extract graph progress: 386/527
2025-10-12 18:59:58.0980 - INFO - graphrag.logger.progress - extract graph progress: 387/527
2025-10-12 18:59:58.0982 - INFO - graphrag.logger.progress - extract graph progress: 388/527
2025-10-12 18:59:58.0983 - INFO - graphrag.logger.progress - extract graph progress: 389/527
2025-10-12 18:59:58.0985 - INFO - graphrag.logger.progress - extract graph progress: 390/527
2025-10-12 19:00:08.0668 - INFO - graphrag.logger.progress - extract graph progress: 391/527
2025-10-12 19:00:08.0670 - INFO - graphrag.logger.progress - extract graph progress: 392/527
2025-10-12 19:00:08.0672 - INFO - graphrag.logger.progress - extract graph progress: 393/527
2025-10-12 19:00:08.0675 - INFO - graphrag.logger.progress - extract graph progress: 394/527
2025-10-12 19:00:08.0676 - INFO - graphrag.logger.progress - extract graph progress: 395/527
2025-10-12 19:00:08.0678 - INFO - graphrag.logger.progress - extract graph progress: 396/527
2025-10-12 19:00:08.0680 - INFO - graphrag.logger.progress - extract graph progress: 397/527
2025-10-12 19:00:08.0682 - INFO - graphrag.logger.progress - extract graph progress: 398/527
2025-10-12 19:00:08.0684 - INFO - graphrag.logger.progress - extract graph progress: 399/527
2025-10-12 19:00:08.0686 - INFO - graphrag.logger.progress - extract graph progress: 400/527
2025-10-12 19:00:08.0688 - INFO - graphrag.logger.progress - extract graph progress: 401/527
2025-10-12 19:00:08.0690 - INFO - graphrag.logger.progress - extract graph progress: 402/527
2025-10-12 19:00:08.0691 - INFO - graphrag.logger.progress - extract graph progress: 403/527
2025-10-12 19:00:08.0693 - INFO - graphrag.logger.progress - extract graph progress: 404/527
2025-10-12 19:00:08.0695 - INFO - graphrag.logger.progress - extract graph progress: 405/527
2025-10-12 19:00:08.0697 - INFO - graphrag.logger.progress - extract graph progress: 406/527
2025-10-12 19:00:08.0700 - INFO - graphrag.logger.progress - extract graph progress: 407/527
2025-10-12 19:00:08.0701 - INFO - graphrag.logger.progress - extract graph progress: 408/527
2025-10-12 19:00:08.0703 - INFO - graphrag.logger.progress - extract graph progress: 409/527
2025-10-12 19:00:08.0705 - INFO - graphrag.logger.progress - extract graph progress: 410/527
2025-10-12 19:00:08.0707 - INFO - graphrag.logger.progress - extract graph progress: 411/527
2025-10-12 19:00:08.0709 - INFO - graphrag.logger.progress - extract graph progress: 412/527
2025-10-12 19:00:08.0711 - INFO - graphrag.logger.progress - extract graph progress: 413/527
2025-10-12 19:00:08.0712 - INFO - graphrag.logger.progress - extract graph progress: 414/527
2025-10-12 19:00:08.0714 - INFO - graphrag.logger.progress - extract graph progress: 415/527
2025-10-12 19:00:08.0716 - INFO - graphrag.logger.progress - extract graph progress: 416/527
2025-10-12 19:00:08.0718 - INFO - graphrag.logger.progress - extract graph progress: 417/527
2025-10-12 19:00:08.0720 - INFO - graphrag.logger.progress - extract graph progress: 418/527
2025-10-12 19:00:08.0722 - INFO - graphrag.logger.progress - extract graph progress: 419/527
2025-10-12 19:00:08.0724 - INFO - graphrag.logger.progress - extract graph progress: 420/527
2025-10-12 19:00:08.0725 - INFO - graphrag.logger.progress - extract graph progress: 421/527
2025-10-12 19:00:08.0727 - INFO - graphrag.logger.progress - extract graph progress: 422/527
2025-10-12 19:00:08.0729 - INFO - graphrag.logger.progress - extract graph progress: 423/527
2025-10-12 19:00:08.0731 - INFO - graphrag.logger.progress - extract graph progress: 424/527
2025-10-12 19:00:08.0733 - INFO - graphrag.logger.progress - extract graph progress: 425/527
2025-10-12 19:00:08.0735 - INFO - graphrag.logger.progress - extract graph progress: 426/527
2025-10-12 19:00:08.0738 - INFO - graphrag.logger.progress - extract graph progress: 427/527
2025-10-12 19:00:08.0739 - INFO - graphrag.logger.progress - extract graph progress: 428/527
2025-10-12 19:00:08.0741 - INFO - graphrag.logger.progress - extract graph progress: 429/527
2025-10-12 19:00:08.0743 - INFO - graphrag.logger.progress - extract graph progress: 430/527
2025-10-12 19:00:08.0745 - INFO - graphrag.logger.progress - extract graph progress: 431/527
2025-10-12 19:00:08.0747 - INFO - graphrag.logger.progress - extract graph progress: 432/527
2025-10-12 19:00:08.0749 - INFO - graphrag.logger.progress - extract graph progress: 433/527
2025-10-12 19:00:18.0670 - INFO - graphrag.logger.progress - extract graph progress: 434/527
2025-10-12 19:00:18.0672 - INFO - graphrag.logger.progress - extract graph progress: 435/527
2025-10-12 19:00:18.0673 - INFO - graphrag.logger.progress - extract graph progress: 436/527
2025-10-12 19:00:18.0675 - INFO - graphrag.logger.progress - extract graph progress: 437/527
2025-10-12 19:00:18.0677 - INFO - graphrag.logger.progress - extract graph progress: 438/527
2025-10-12 19:00:18.0679 - INFO - graphrag.logger.progress - extract graph progress: 439/527
2025-10-12 19:00:18.0681 - INFO - graphrag.logger.progress - extract graph progress: 440/527
2025-10-12 19:00:18.0683 - INFO - graphrag.logger.progress - extract graph progress: 441/527
2025-10-12 19:00:18.0685 - INFO - graphrag.logger.progress - extract graph progress: 442/527
2025-10-12 19:00:18.0686 - INFO - graphrag.logger.progress - extract graph progress: 443/527
2025-10-12 19:00:18.0689 - INFO - graphrag.logger.progress - extract graph progress: 444/527
2025-10-12 19:00:18.0690 - INFO - graphrag.logger.progress - extract graph progress: 445/527
2025-10-12 19:00:18.0692 - INFO - graphrag.logger.progress - extract graph progress: 446/527
2025-10-12 19:00:18.0694 - INFO - graphrag.logger.progress - extract graph progress: 447/527
2025-10-12 19:00:18.0696 - INFO - graphrag.logger.progress - extract graph progress: 448/527
2025-10-12 19:00:18.0698 - INFO - graphrag.logger.progress - extract graph progress: 449/527
2025-10-12 19:00:18.0700 - INFO - graphrag.logger.progress - extract graph progress: 450/527
2025-10-12 19:00:18.0702 - INFO - graphrag.logger.progress - extract graph progress: 451/527
2025-10-12 19:00:18.0704 - INFO - graphrag.logger.progress - extract graph progress: 452/527
2025-10-12 19:00:18.0705 - INFO - graphrag.logger.progress - extract graph progress: 453/527
2025-10-12 19:00:18.0707 - INFO - graphrag.logger.progress - extract graph progress: 454/527
2025-10-12 19:00:18.0709 - INFO - graphrag.logger.progress - extract graph progress: 455/527
2025-10-12 19:00:18.0711 - INFO - graphrag.logger.progress - extract graph progress: 456/527
2025-10-12 19:00:18.0713 - INFO - graphrag.logger.progress - extract graph progress: 457/527
2025-10-12 19:00:18.0714 - INFO - graphrag.logger.progress - extract graph progress: 458/527
2025-10-12 19:00:18.0716 - INFO - graphrag.logger.progress - extract graph progress: 459/527
2025-10-12 19:00:18.0718 - INFO - graphrag.logger.progress - extract graph progress: 460/527
2025-10-12 19:00:18.0719 - INFO - graphrag.logger.progress - extract graph progress: 461/527
2025-10-12 19:00:18.0721 - INFO - graphrag.logger.progress - extract graph progress: 462/527
2025-10-12 19:00:18.0723 - INFO - graphrag.logger.progress - extract graph progress: 463/527
2025-10-12 19:00:18.0725 - INFO - graphrag.logger.progress - extract graph progress: 464/527
2025-10-12 19:00:18.0726 - INFO - graphrag.logger.progress - extract graph progress: 465/527
2025-10-12 19:00:18.0728 - INFO - graphrag.logger.progress - extract graph progress: 466/527
2025-10-12 19:00:18.0730 - INFO - graphrag.logger.progress - extract graph progress: 467/527
2025-10-12 19:00:18.0731 - INFO - graphrag.logger.progress - extract graph progress: 468/527
2025-10-12 19:00:18.0733 - INFO - graphrag.logger.progress - extract graph progress: 469/527
2025-10-12 19:00:18.0735 - INFO - graphrag.logger.progress - extract graph progress: 470/527
2025-10-12 19:00:18.0736 - INFO - graphrag.logger.progress - extract graph progress: 471/527
2025-10-12 19:00:18.0738 - INFO - graphrag.logger.progress - extract graph progress: 472/527
2025-10-12 19:00:18.0740 - INFO - graphrag.logger.progress - extract graph progress: 473/527
2025-10-12 19:00:18.0742 - INFO - graphrag.logger.progress - extract graph progress: 474/527
2025-10-12 19:00:18.0744 - INFO - graphrag.logger.progress - extract graph progress: 475/527
2025-10-12 19:00:18.0746 - INFO - graphrag.logger.progress - extract graph progress: 476/527
2025-10-12 19:00:18.0747 - INFO - graphrag.logger.progress - extract graph progress: 477/527
2025-10-12 19:00:18.0749 - INFO - graphrag.logger.progress - extract graph progress: 478/527
2025-10-12 19:00:18.0751 - INFO - graphrag.logger.progress - extract graph progress: 479/527
2025-10-12 19:00:18.0753 - INFO - graphrag.logger.progress - extract graph progress: 480/527
2025-10-12 19:00:18.0754 - INFO - graphrag.logger.progress - extract graph progress: 481/527
2025-10-12 19:00:18.0756 - INFO - graphrag.logger.progress - extract graph progress: 482/527
2025-10-12 19:00:18.0758 - INFO - graphrag.logger.progress - extract graph progress: 483/527
2025-10-12 19:00:18.0760 - INFO - graphrag.logger.progress - extract graph progress: 484/527
2025-10-12 19:00:18.0762 - INFO - graphrag.logger.progress - extract graph progress: 485/527
2025-10-12 19:00:18.0764 - INFO - graphrag.logger.progress - extract graph progress: 486/527
2025-10-12 19:00:18.0766 - INFO - graphrag.logger.progress - extract graph progress: 487/527
2025-10-12 19:00:18.0767 - INFO - graphrag.logger.progress - extract graph progress: 488/527
2025-10-12 19:00:18.0769 - INFO - graphrag.logger.progress - extract graph progress: 489/527
2025-10-12 19:00:18.0771 - INFO - graphrag.logger.progress - extract graph progress: 490/527
2025-10-12 19:00:18.0773 - INFO - graphrag.logger.progress - extract graph progress: 491/527
2025-10-12 19:00:18.0775 - INFO - graphrag.logger.progress - extract graph progress: 492/527
2025-10-12 19:00:18.0777 - INFO - graphrag.logger.progress - extract graph progress: 493/527
2025-10-12 19:00:18.0779 - INFO - graphrag.logger.progress - extract graph progress: 494/527
2025-10-12 19:00:18.0781 - INFO - graphrag.logger.progress - extract graph progress: 495/527
2025-10-12 19:00:18.0782 - INFO - graphrag.logger.progress - extract graph progress: 496/527
2025-10-12 19:00:18.0784 - INFO - graphrag.logger.progress - extract graph progress: 497/527
2025-10-12 19:00:18.0786 - INFO - graphrag.logger.progress - extract graph progress: 498/527
2025-10-12 19:00:18.0788 - INFO - graphrag.logger.progress - extract graph progress: 499/527
2025-10-12 19:00:18.0789 - INFO - graphrag.logger.progress - extract graph progress: 500/527
2025-10-12 19:00:18.0791 - INFO - graphrag.logger.progress - extract graph progress: 501/527
2025-10-12 19:00:18.0793 - INFO - graphrag.logger.progress - extract graph progress: 502/527
2025-10-12 19:00:18.0795 - INFO - graphrag.logger.progress - extract graph progress: 503/527
2025-10-12 19:00:18.0797 - INFO - graphrag.logger.progress - extract graph progress: 504/527
2025-10-12 19:00:31.0276 - INFO - graphrag.logger.progress - extract graph progress: 505/527
2025-10-12 19:00:31.0278 - INFO - graphrag.logger.progress - extract graph progress: 506/527
2025-10-12 19:00:31.0280 - INFO - graphrag.logger.progress - extract graph progress: 507/527
2025-10-12 19:00:31.0282 - INFO - graphrag.logger.progress - extract graph progress: 508/527
2025-10-12 19:00:31.0284 - INFO - graphrag.logger.progress - extract graph progress: 509/527
2025-10-12 19:00:31.0286 - INFO - graphrag.logger.progress - extract graph progress: 510/527
2025-10-12 19:00:31.0288 - INFO - graphrag.logger.progress - extract graph progress: 511/527
2025-10-12 19:00:31.0290 - INFO - graphrag.logger.progress - extract graph progress: 512/527
2025-10-12 19:00:31.0292 - INFO - graphrag.logger.progress - extract graph progress: 513/527
2025-10-12 19:00:31.0294 - INFO - graphrag.logger.progress - extract graph progress: 514/527
2025-10-12 19:00:31.0296 - INFO - graphrag.logger.progress - extract graph progress: 515/527
2025-10-12 19:00:31.0297 - INFO - graphrag.logger.progress - extract graph progress: 516/527
2025-10-12 19:00:31.0299 - INFO - graphrag.logger.progress - extract graph progress: 517/527
2025-10-12 19:00:31.0301 - INFO - graphrag.logger.progress - extract graph progress: 518/527
2025-10-12 19:00:31.0303 - INFO - graphrag.logger.progress - extract graph progress: 519/527
2025-10-12 19:00:31.0305 - INFO - graphrag.logger.progress - extract graph progress: 520/527
2025-10-12 19:00:31.0307 - INFO - graphrag.logger.progress - extract graph progress: 521/527
2025-10-12 19:00:31.0309 - INFO - graphrag.logger.progress - extract graph progress: 522/527
2025-10-12 19:00:31.0310 - INFO - graphrag.logger.progress - extract graph progress: 523/527
2025-10-12 19:00:31.0312 - INFO - graphrag.logger.progress - extract graph progress: 524/527
2025-10-12 19:00:31.0314 - INFO - graphrag.logger.progress - extract graph progress: 525/527
2025-10-12 19:00:31.0316 - INFO - graphrag.logger.progress - extract graph progress: 526/527
2025-10-12 19:00:31.0318 - INFO - graphrag.logger.progress - extract graph progress: 527/527
2025-10-12 19:00:31.0382 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
                                                               ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
                                                  ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
           ^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
                               ^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-10-12 19:00:31.0440 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-10-12 19:00:31.0441 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-23 21:10:03.0956 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:06.0810 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:11.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:20.0728 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:37.0809 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:11:10.0160 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:12:14.0655 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:14:23.0042 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:18:39.0942 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:27:12.0725 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:34:55.0953 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:34:58.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:35:03.0309 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:35:11.0852 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:35:28.0206 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:36:00.0308 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:37:05.0263 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:39:14.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:43:30.0878 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:17.0594 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:17.0596 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:17.0601 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:40.0100 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:43.0125 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:48.0090 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:56.0499 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:45:12.0857 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:45:45.0775 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:46:50.0752 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:48:59.0030 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:52:03.0151 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:53:16.0106 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:59:50.0305 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:59:52.0600 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:59:57.0546 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:00:05.0613 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:00:22.0074 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:00:54.0936 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:01:59.0489 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
  2025-10-23 22:04:07.0729 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:33.0757 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:35.0872 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:40.0150 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:48.0471 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:08:04.0994 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/grapphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:09:08.0154 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-pacon3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:09:41.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                2025-10-23 22:11:50.0251 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:16:07.0240 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:16:56.0875 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:18:53.0817 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:18:53.0821 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:18:53.0828 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:24:40.0042 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:34:01.0839 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:34:01.0845 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:34:01.0851 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:41:44.0232 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:41:44.0237 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:41:44.0243 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:22.0783 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:25.0212 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:30.0001 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:38.0785 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:54.0893 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:48:27.0355 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:40.0794 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:43.0615 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:48.0438 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:57.0187 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:50:13.0948 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:50:46.0408 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:51:51.0447 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:52:48.0084 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:52:50.0455 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:52:54.0665 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:53:03.0603 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:53:20.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:53:53.0014 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:15:59.0589 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:02.0291 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:06.0967 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:15.0254 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:31.0526 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:41.0504 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:44.0557 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:49.0452 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:58.0137 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:25:15.0064 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
