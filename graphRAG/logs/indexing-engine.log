2025-10-06 13:40:00.0708 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0845 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0907 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:00.0968 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0029 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0090 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0151 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0214 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0277 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0339 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0342 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 2525, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 344, in completion
    data = provider_config.transform_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/chat/transformation.py", line 151, in transform_request
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: Model google/gemma-2b-it is not supported for provider huggingface

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 570, in acompletion
    init_response = await loop.run_in_executor(None, func_with_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1084, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3733, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:40:01.0348 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Model google/gemma-2b-it is not supported for provider huggingface
2025-10-06 13:50:20.0918 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0036 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0163 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0394 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0541 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0653 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0769 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:21.0965 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0077 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0195 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0197 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://router.huggingface.co/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.huggingface.common_utils.HuggingFaceError: {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 13:50:22.0201 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.BadRequestError: HuggingfaceException - {"error":{"message":"The requested model 'huggingface/DeepSeek-R1-Distill Qwen' does not exist.","type":"invalid_request_error","param":"model","code":"model_not_found"}}
2025-10-06 14:14:03.0354 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0443 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0545 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0637 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0726 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0823 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0825 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:14:03.0830 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.BadRequestError: GroqException - {"error":{"message":"The model `llama3-8b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:16:08.0881 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:15.0000 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:21.0317 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:27.0579 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:33.0720 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Server error '503 Service Unavailable' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 511, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: ServiceUnavailableError: GroqException - {"error":{"message":"llama-3.1-8b-instant is currently over capacity. Please try again and back off exponentially. Visit https://groqstatus.com to see if there is an active incident.","type":"internal_server_error"}}

2025-10-06 14:16:45.0257 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:16:45.0484 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:45.0695 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:45.0900 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0111 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0334 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0570 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0786 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:46.0996 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0217 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0429 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0642 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0644 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/None/huggingface/DeepSeek-R1-Distill%20Qwen'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:16:47.0648 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:28:57.0838 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:57.0925 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0012 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0104 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0188 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0277 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0279 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 392, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:28:58.0283 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.BadRequestError: GroqException - {"error":{"message":"The model `gemma-7b-it` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.","type":"invalid_request_error","code":"model_decommissioned"}}

2025-10-06 14:29:56.0688 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:56.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:56.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:56.0944 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0027 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0106 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0108 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 108, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 350, in exception_type
    raise NotFoundError(
litellm.exceptions.NotFoundError: litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:29:57.0111 - ERROR - graphrag.index.validate_config - LLM configuration error detected. Exiting...
litellm.NotFoundError: GroqException - {"error":{"message":"The model `llama2-70b-chat` does not exist or you do not have access to it.","type":"invalid_request_error","code":"model_not_found"}}

2025-10-06 14:38:56.0458 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:38:58.0336 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:38:59.0491 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:01.0940 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:03.0885 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:04.0799 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:05.0748 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:07.0016 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:09.0331 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:11.0469 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:12.0576 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:14.0331 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:14.0423 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:39:14.0628 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 14:45:49.0342 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:45:50.0062 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:50.0465 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:50.0938 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:51.0521 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:52.0344 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:52.0642 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:53.0235 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:53.0810 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:54.0713 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0189 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0644 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0692 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/sentence-similarity/sentence-transformers/all-MiniLM-L6-v2'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:45:55.0755 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Not Found

2025-10-06 14:57:55.0057 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 14:57:55.0844 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:56.0539 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:58.0376 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:59.0030 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:57:59.0874 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:00.0546 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:01.0185 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:04.0887 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:05.0884 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:06.0457 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:07.0765 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:07.0798 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIError: HuggingfaceException - Not Found
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 328, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 284, in post
    response.raise_for_status()
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '404 Not Found' for url 'https://router.huggingface.co/hf-inference/pipeline/feature-extraction/BAAI/bge-small-en-v1.5'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1571, in exception_type
    raise APIError(
litellm.exceptions.APIError: litellm.APIError: HuggingfaceException - Not Found
2025-10-06 14:58:09.0629 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIError: HuggingfaceException - Not Found

2025-10-06 15:10:03.0475 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:10:03.0660 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:03.0821 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0081 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0237 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0649 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0836 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:04.0992 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0155 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0423 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0584 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0781 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0783 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 272, in aembedding
    data = self._transform_input(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 180, in _transform_input
    data = self._transform_input_on_pipeline_tag(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 91, in _transform_input_on_pipeline_tag
    raise HuggingFaceError(
litellm.llms.huggingface.common_utils.HuggingFaceError: sentence-similarity requires 2+ sentences

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1540, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences
2025-10-06 15:10:05.0787 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.BadRequestError: HuggingfaceException - sentence-similarity requires 2+ sentences


2025-10-06 15:19:45.0612 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:19:45.0835 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0064 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0245 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0457 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0671 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:46.0877 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0084 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0284 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0503 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:47.0711 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:48.0298 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:48.0302 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:19:48.0309 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:09.0948 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:24:10.0164 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0374 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0577 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0781 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:10.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0417 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0603 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0788 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:11.0958 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0143 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0347 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0351 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:24:12.0357 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:35.0880 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:26:36.0061 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0259 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0471 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0642 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:36.0819 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0027 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0202 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0411 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0588 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:37.0797 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:38.0055 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:38.0060 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:26:38.0065 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0154 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:28:23.0351 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0552 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0735 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:23.0938 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0105 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0269 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0446 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0648 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:24.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0132 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0330 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0334 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:28:25.0339 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0098 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:30:48.0293 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0499 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0756 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:48.0928 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0115 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0282 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0453 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0625 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0797 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:49.0982 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:50.0180 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:50.0184 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:30:50.0190 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:50.0951 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:31:51.0289 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:51.0467 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:51.0670 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:51.0841 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0061 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0266 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0467 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0667 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:52.0918 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0155 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0367 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0371 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:31:53.0377 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:18.0656 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:32:18.0985 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0194 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0408 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0580 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0789 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:19.0990 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0220 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0436 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0727 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:20.0963 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:21.0160 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:21.0164 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:32:21.0170 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0162 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:33:02.0385 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0596 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0783 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:02.0983 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0192 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0394 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0574 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0747 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:03.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0171 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0341 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0345 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2249, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local

2025-10-06 15:33:04.0351 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: /local
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 637, in _request
    raise err_exc_cls(url)
aiohttp.client_exceptions.InvalidUrlClientError: /local

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 330, in post
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.InvalidURL: /local



2025-10-06 15:36:11.0146 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:36:11.0373 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:11.0556 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:11.0919 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0140 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0382 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0595 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0789 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:12.0986 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0198 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0402 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0656 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0661 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:13.0668 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:41.0230 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:36:41.0486 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:41.0698 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:41.0879 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0100 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0451 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0680 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:42.0862 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0041 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0269 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 8000), [Errno 111] Connect call failed ('::1', 8000, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0515 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0521 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/huggingface/embedding/handler.py", line 296, in aembedding
    response = await client.post(api_base, headers=headers, data=json.dumps(data))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:36:43.0528 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: HuggingfaceException - Cannot connect to host localhost:8000 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 8000, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 8000)]
2025-10-06 15:39:39.0094 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:39:39.0125 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0152 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0177 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0202 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0227 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0255 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0280 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0305 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0329 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0354 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0379 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0384 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:39:39.0391 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0218 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-06 15:40:51.0248 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0300 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0326 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0351 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0379 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=6, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0404 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=7, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0429 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=8, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0453 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=9, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0478 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('127.0.0.1', 11434), [Errno 111] Connect call failed ('::1', 11434, 0, 0)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0503 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0508 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 283, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1268, in _wrap_create_connection
    sock = await aiohappyeyeballs.start_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohappyeyeballs/impl.py", line 141, in start_connection
    raise OSError(first_errno, msg)
ConnectionRefusedError: [Errno 111] Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 219, in handle_async_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/client.py", line 725, in _connect_and_send_request
    conn = await self._connector.connect(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 642, in connect
    proto = await self._create_connection(req, traces, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1209, in _create_connection
    _, proto = await self._create_direct_connection(req, traces, timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1581, in _create_direct_connection
    raise last_exc
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1550, in _create_direct_connection
    transp, proto = await self._wrap_create_connection(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/aiohttp/connector.py", line 1291, in _wrap_create_connection
    raise client_error(req.connection_key, exc) from exc
aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3845, in aembedding
    response = await init_response  # type: ignore
               ^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/ollama/completion/handler.py", line 87, in ollama_aembeddings
    response = await litellm.module_level_aclient.post(url=api_base, json=data)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    return await self.single_connection_post_request(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 517, in single_connection_post_request
    response = await client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 212, in handle_async_request
    with map_aiohttp_exceptions():
  File "/opt/apps/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/contextlib.py", line 155, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/embedding_model.py", line 94, in _base_aembedding
    return await aembedding(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1612, in wrapper_async
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/main.py", line 3860, in aembedding
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/cz82/.local/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-06 15:40:51.0516 - ERROR - graphrag.index.validate_config - Embedding LLM configuration error detected. Exiting...
litellm.APIConnectionError: OllamaException - Cannot connect to host localhost:11434 ssl:default [Multiple exceptions: [Errno 111] Connect call failed ('::1', 11434, 0, 0), [Errno 111] Connect call failed ('127.0.0.1', 11434)]
2025-10-09 19:49:43.0592 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.563s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.563s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.563s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:43.0725 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.413999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.413999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.413999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:43.0831 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.306999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.306999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.306999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:43.0952 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.196s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0073 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0209 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0213 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:49:44.0221 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201395, Requested 18. Please try again in 24h20m20.937s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0096 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=1, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m54.058s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m54.058s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m54.058s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0249 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=2, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.889s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0426 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=3, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.722s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=4, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201294, Requested 18. Please try again in 24h18m53.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0707 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Request failed, immediately retrying, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.435s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.435s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.435s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0898 - ERROR - graphrag.language_model.providers.litellm.services.retry.native_wait_retry - NativeRetry: Max retries exceeded, retries=5, max_retries=5, exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0903 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 328, in post
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\http_handler.py", line 284, in post
    response.raise_for_status()
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 578, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 148, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 3025, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\services\retry\native_wait_retry.py", line 56, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1612, in wrapper_async
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\utils.py", line 1462, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\main.py", line 597, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "C:\Users\zhour\AppData\Roaming\Python\Python311\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 330, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-09 19:51:11.0912 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k6xev7m5ecfbxh4s88mqkfap` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 201293, Requested 18. Please try again in 24h18m53.299s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2025-10-12 14:55:52.0998 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
2025-10-12 14:58:55.0909 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.004 seconds
2025-10-12 15:02:00.0263 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
2025-10-12 15:05:09.0062 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=180.0, time taken=180.003 seconds
2025-10-12 15:19:26.0722 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=600.0, time taken=600.005 seconds
2025-10-12 15:53:55.0563 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 59, in map_aiohttp_exceptions
    yield
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 272, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 239, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 1488, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 770, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client.py", line 748, in _connect_and_send_request
    await resp.start(conn)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/client_reqrep.py", line 541, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/aiohttp/streams.py", line 680, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 292, in post
    response = await self.client.send(req, stream=stream)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 271, in handle_async_request
    with map_aiohttp_exceptions():
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/aiohttp_transport.py", line 73, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 123, in _make_common_async_call
    response = await async_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py", line 321, in post
    raise litellm.Timeout(
litellm.exceptions.Timeout: litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 584, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 255, in async_completion
    response = await self._make_common_async_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 150, in _make_common_async_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/custom_httpx/llm_http_handler.py", line 3026, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.ollama.common_utils.OllamaError: litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1626, in wrapper_async
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1472, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 603, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2242, in exception_type
    raise APIConnectionError(
litellm.exceptions.APIConnectionError: litellm.APIConnectionError: OllamaException - litellm.Timeout: Connection timed out. Timeout passed=1800.0, time taken=1800.002 seconds
2025-10-12 16:08:52.0894 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 16:08:55.0354 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 16:08:55.0354 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 16:08:55.0355 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "DESCRIPTION",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 512,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "SEVERITY_LEVEL",
            "ORGANIZATION",
            "WORKPLACE",
            "WORK_PROCESS",
            "DESCRIPTION_SUMMARY"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": null,
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": null,
        "text_prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": null,
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 16:08:55.0356 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 16:08:55.0356 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 16:08:55.0356 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:08:55.0356 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 16:08:55.0357 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 16:08:55.0357 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 16:08:55.0369 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 16:08:55.0369 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 16:08:55.0372 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 16:08:55.0372 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:08:55.0372 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-10-12 16:08:55.0372 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.txt$
2025-10-12 16:08:55.0373 - ERROR - graphrag.index.run.run_pipeline - error running workflow load_input_documents
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 26, in run_workflow
    output = await load_input_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 43, in load_input_documents
    return await create_input(config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/factory.py", line 37, in create_input
    result = await loader(config, storage)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/text.py", line 35, in load_text
    return await load_files(load_file, config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/util.py", line 34, in load_files
    raise ValueError(msg)
ValueError: No InputFileType.text files found in /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:08:55.0375 - ERROR - graphrag.api.index - Workflow load_input_documents completed with errors
2025-10-12 16:08:55.0376 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 16:23:25.0727 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 16:23:27.0435 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 16:23:27.0435 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 16:23:27.0436 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "DESCRIPTION",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 512,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "SEVERITY_LEVEL",
            "ORGANIZATION",
            "WORKPLACE",
            "WORK_PROCESS",
            "DESCRIPTION_SUMMARY"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": null,
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": null,
        "text_prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": null,
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 16:23:27.0437 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 16:23:27.0437 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 16:23:27.0437 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 16:23:27.0439 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 16:23:27.0439 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 16:23:27.0441 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 16:23:27.0441 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:23:27.0441 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-10-12 16:23:27.0442 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.txt$
2025-10-12 16:23:27.0442 - ERROR - graphrag.index.run.run_pipeline - error running workflow load_input_documents
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 26, in run_workflow
    output = await load_input_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 43, in load_input_documents
    return await create_input(config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/factory.py", line 37, in create_input
    result = await loader(config, storage)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/text.py", line 35, in load_text
    return await load_files(load_file, config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/util.py", line 34, in load_files
    raise ValueError(msg)
ValueError: No InputFileType.text files found in /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:23:27.0445 - ERROR - graphrag.api.index - Workflow load_input_documents completed with errors
2025-10-12 16:23:27.0445 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 16:44:56.0670 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 16:44:58.0328 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 16:44:58.0328 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 16:44:58.0329 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 1800.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "DESCRIPTION",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 512,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "SEVERITY_LEVEL",
            "ORGANIZATION",
            "WORKPLACE",
            "WORK_PROCESS",
            "DESCRIPTION_SUMMARY"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": null,
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": null,
        "text_prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": null,
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": null,
        "reduce_prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": null,
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 16:44:58.0330 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 16:44:58.0330 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 16:44:58.0330 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:44:58.0331 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 16:44:58.0331 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 16:44:58.0331 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 16:44:58.0333 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 16:44:58.0333 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 16:44:58.0335 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 16:44:58.0335 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:44:58.0335 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2025-10-12 16:44:58.0336 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.txt$
2025-10-12 16:44:58.0337 - ERROR - graphrag.index.run.run_pipeline - error running workflow load_input_documents
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 26, in run_workflow
    output = await load_input_documents(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/load_input_documents.py", line 43, in load_input_documents
    return await create_input(config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/factory.py", line 37, in create_input
    result = await loader(config, storage)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/text.py", line 35, in load_text
    return await load_files(load_file, config, storage)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/input/util.py", line 34, in load_files
    raise ValueError(msg)
ValueError: No InputFileType.text files found in /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 16:44:58.0339 - ERROR - graphrag.api.index - Workflow load_input_documents completed with errors
2025-10-12 16:44:58.0339 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 17:07:27.0193 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 17:07:29.0138 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 17:07:29.0138 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 17:07:29.0139 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 17:07:29.0140 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 17:07:29.0140 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 17:07:29.0140 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:07:29.0140 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 17:07:29.0141 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 17:07:29.0141 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 17:07:29.0143 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 17:07:29.0143 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 17:07:29.0145 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 17:07:29.0145 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:07:29.0145 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 17:07:29.0145 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:07:29.0146 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 17:07:29.0167 - WARNING - graphrag.index.input.util - text_column text not found in csv file dev_sample.csv
2025-10-12 17:07:29.0168 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 17:07:29.0169 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 80
2025-10-12 17:07:29.0169 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 80
2025-10-12 17:07:29.0204 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 17:07:29.0235 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 17:07:29.0236 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 17:07:29.0270 - ERROR - graphrag.index.run.run_pipeline - error running workflow create_base_text_units
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pandas/_libs/index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'text'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/create_base_text_units.py", line 35, in run_workflow
    output = create_base_text_units(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/create_base_text_units.py", line 68, in create_base_text_units
    zip(*[sort[col] for col in ["id", "text"]], strict=True)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/create_base_text_units.py", line 68, in <listcomp>
    zip(*[sort[col] for col in ["id", "text"]], strict=True)
          ~~~~^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/frame.py", line 4113, in __getitem__
    indexer = self.columns.get_loc(key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/indexes/base.py", line 3819, in get_loc
    raise KeyError(key) from err
KeyError: 'text'
2025-10-12 17:07:29.0275 - ERROR - graphrag.api.index - Workflow create_base_text_units completed with errors
2025-10-12 17:07:29.0275 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-12 17:20:48.0277 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 17:20:50.0037 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 17:20:50.0037 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 17:20:50.0037 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 17:20:50.0039 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 17:20:50.0039 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 17:20:50.0039 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:20:50.0039 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 17:20:50.0040 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 17:20:50.0040 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 17:20:50.0043 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 17:20:50.0043 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 17:20:50.0045 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 17:20:50.0045 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:20:50.0045 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 17:20:50.0046 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 17:20:50.0046 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 17:20:50.0066 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 17:20:50.0067 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 80
2025-10-12 17:20:50.0067 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 80
2025-10-12 17:20:50.0082 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 17:20:50.0110 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 17:20:50.0110 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 17:20:50.0153 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 68 documents
2025-10-12 17:20:50.0155 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/68
2025-10-12 17:20:50.0155 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/68
2025-10-12 17:20:50.0156 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/68
2025-10-12 17:20:50.0157 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/68
2025-10-12 17:20:50.0157 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/68
2025-10-12 17:20:50.0158 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/68
2025-10-12 17:20:50.0158 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/68
2025-10-12 17:20:50.0159 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/68
2025-10-12 17:20:50.0159 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/68
2025-10-12 17:20:50.0160 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/68
2025-10-12 17:20:50.0160 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/68
2025-10-12 17:20:50.0161 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/68
2025-10-12 17:20:50.0162 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/68
2025-10-12 17:20:50.0162 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/68
2025-10-12 17:20:50.0163 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/68
2025-10-12 17:20:50.0163 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/68
2025-10-12 17:20:50.0164 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/68
2025-10-12 17:20:50.0164 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/68
2025-10-12 17:20:50.0165 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/68
2025-10-12 17:20:50.0165 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/68
2025-10-12 17:20:50.0166 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/68
2025-10-12 17:20:50.0166 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/68
2025-10-12 17:20:50.0167 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/68
2025-10-12 17:20:50.0167 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/68
2025-10-12 17:20:50.0168 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/68
2025-10-12 17:20:50.0168 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/68
2025-10-12 17:20:50.0169 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/68
2025-10-12 17:20:50.0169 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/68
2025-10-12 17:20:50.0170 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/68
2025-10-12 17:20:50.0170 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/68
2025-10-12 17:20:50.0171 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/68
2025-10-12 17:20:50.0171 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/68
2025-10-12 17:20:50.0172 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/68
2025-10-12 17:20:50.0172 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/68
2025-10-12 17:20:50.0173 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/68
2025-10-12 17:20:50.0173 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/68
2025-10-12 17:20:50.0174 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/68
2025-10-12 17:20:50.0174 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/68
2025-10-12 17:20:50.0175 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/68
2025-10-12 17:20:50.0175 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/68
2025-10-12 17:20:50.0176 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/68
2025-10-12 17:20:50.0176 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/68
2025-10-12 17:20:50.0177 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/68
2025-10-12 17:20:50.0177 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/68
2025-10-12 17:20:50.0178 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/68
2025-10-12 17:20:50.0178 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/68
2025-10-12 17:20:50.0179 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/68
2025-10-12 17:20:50.0179 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/68
2025-10-12 17:20:50.0180 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/68
2025-10-12 17:20:50.0181 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/68
2025-10-12 17:20:50.0181 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/68
2025-10-12 17:20:50.0182 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/68
2025-10-12 17:20:50.0182 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/68
2025-10-12 17:20:50.0183 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/68
2025-10-12 17:20:50.0183 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/68
2025-10-12 17:20:50.0184 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/68
2025-10-12 17:20:50.0184 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/68
2025-10-12 17:20:50.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/68
2025-10-12 17:20:50.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/68
2025-10-12 17:20:50.0186 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/68
2025-10-12 17:20:50.0186 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/68
2025-10-12 17:20:50.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/68
2025-10-12 17:20:50.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/68
2025-10-12 17:20:50.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/68
2025-10-12 17:20:50.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/68
2025-10-12 17:20:50.0189 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/68
2025-10-12 17:20:50.0189 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/68
2025-10-12 17:20:50.0190 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/68
2025-10-12 17:20:50.0199 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-12 17:20:50.0199 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-12 17:20:50.0203 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-12 17:20:50.0203 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 17:20:50.0214 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:20:50.0227 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-12 17:20:50.0227 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-12 17:20:50.0231 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-12 17:20:50.0232 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:20:50.0241 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/extract_graph
2025-10-12 17:20:53.0297 - INFO - graphrag.logger.progress - extract graph progress: 1/68
2025-10-12 17:20:53.0300 - INFO - graphrag.logger.progress - extract graph progress: 2/68
2025-10-12 17:20:53.0301 - INFO - graphrag.logger.progress - extract graph progress: 3/68
2025-10-12 17:20:53.0303 - INFO - graphrag.logger.progress - extract graph progress: 4/68
2025-10-12 17:20:53.0306 - INFO - graphrag.logger.progress - extract graph progress: 5/68
2025-10-12 17:20:53.0307 - INFO - graphrag.logger.progress - extract graph progress: 6/68
2025-10-12 17:20:53.0309 - INFO - graphrag.logger.progress - extract graph progress: 7/68
2025-10-12 17:20:53.0311 - INFO - graphrag.logger.progress - extract graph progress: 8/68
2025-10-12 17:20:53.0313 - INFO - graphrag.logger.progress - extract graph progress: 9/68
2025-10-12 17:20:53.0315 - INFO - graphrag.logger.progress - extract graph progress: 10/68
2025-10-12 17:20:53.0317 - INFO - graphrag.logger.progress - extract graph progress: 11/68
2025-10-12 17:20:53.0319 - INFO - graphrag.logger.progress - extract graph progress: 12/68
2025-10-12 17:20:53.0321 - INFO - graphrag.logger.progress - extract graph progress: 13/68
2025-10-12 17:20:56.0195 - INFO - graphrag.logger.progress - extract graph progress: 14/68
2025-10-12 17:20:56.0197 - INFO - graphrag.logger.progress - extract graph progress: 15/68
2025-10-12 17:20:56.0199 - INFO - graphrag.logger.progress - extract graph progress: 16/68
2025-10-12 17:20:56.0201 - INFO - graphrag.logger.progress - extract graph progress: 17/68
2025-10-12 17:20:56.0203 - INFO - graphrag.logger.progress - extract graph progress: 18/68
2025-10-12 17:20:56.0205 - INFO - graphrag.logger.progress - extract graph progress: 19/68
2025-10-12 17:20:56.0207 - INFO - graphrag.logger.progress - extract graph progress: 20/68
2025-10-12 17:20:56.0209 - INFO - graphrag.logger.progress - extract graph progress: 21/68
2025-10-12 17:20:56.0211 - INFO - graphrag.logger.progress - extract graph progress: 22/68
2025-10-12 17:20:59.0282 - INFO - graphrag.logger.progress - extract graph progress: 23/68
2025-10-12 17:20:59.0287 - INFO - graphrag.logger.progress - extract graph progress: 24/68
2025-10-12 17:20:59.0291 - INFO - graphrag.logger.progress - extract graph progress: 25/68
2025-10-12 17:20:59.0294 - INFO - graphrag.logger.progress - extract graph progress: 26/68
2025-10-12 17:20:59.0298 - INFO - graphrag.logger.progress - extract graph progress: 27/68
2025-10-12 17:20:59.0301 - INFO - graphrag.logger.progress - extract graph progress: 28/68
2025-10-12 17:20:59.0304 - INFO - graphrag.logger.progress - extract graph progress: 29/68
2025-10-12 17:20:59.0307 - INFO - graphrag.logger.progress - extract graph progress: 30/68
2025-10-12 17:20:59.0310 - INFO - graphrag.logger.progress - extract graph progress: 31/68
2025-10-12 17:20:59.0312 - INFO - graphrag.logger.progress - extract graph progress: 32/68
2025-10-12 17:20:59.0313 - INFO - graphrag.logger.progress - extract graph progress: 33/68
2025-10-12 17:20:59.0316 - INFO - graphrag.logger.progress - extract graph progress: 34/68
2025-10-12 17:20:59.0319 - INFO - graphrag.logger.progress - extract graph progress: 35/68
2025-10-12 17:20:59.0322 - INFO - graphrag.logger.progress - extract graph progress: 36/68
2025-10-12 17:20:59.0324 - INFO - graphrag.logger.progress - extract graph progress: 37/68
2025-10-12 17:20:59.0328 - INFO - graphrag.logger.progress - extract graph progress: 38/68
2025-10-12 17:20:59.0330 - INFO - graphrag.logger.progress - extract graph progress: 39/68
2025-10-12 17:20:59.0332 - INFO - graphrag.logger.progress - extract graph progress: 40/68
2025-10-12 17:20:59.0333 - INFO - graphrag.logger.progress - extract graph progress: 41/68
2025-10-12 17:20:59.0336 - INFO - graphrag.logger.progress - extract graph progress: 42/68
2025-10-12 17:20:59.0339 - INFO - graphrag.logger.progress - extract graph progress: 43/68
2025-10-12 17:20:59.0342 - INFO - graphrag.logger.progress - extract graph progress: 44/68
2025-10-12 17:20:59.0345 - INFO - graphrag.logger.progress - extract graph progress: 45/68
2025-10-12 17:21:03.0591 - INFO - graphrag.logger.progress - extract graph progress: 46/68
2025-10-12 17:21:03.0593 - INFO - graphrag.logger.progress - extract graph progress: 47/68
2025-10-12 17:21:03.0595 - INFO - graphrag.logger.progress - extract graph progress: 48/68
2025-10-12 17:21:03.0597 - INFO - graphrag.logger.progress - extract graph progress: 49/68
2025-10-12 17:21:03.0598 - INFO - graphrag.logger.progress - extract graph progress: 50/68
2025-10-12 17:21:03.0600 - INFO - graphrag.logger.progress - extract graph progress: 51/68
2025-10-12 17:21:03.0602 - INFO - graphrag.logger.progress - extract graph progress: 52/68
2025-10-12 17:21:03.0604 - INFO - graphrag.logger.progress - extract graph progress: 53/68
2025-10-12 17:21:03.0606 - INFO - graphrag.logger.progress - extract graph progress: 54/68
2025-10-12 17:21:03.0608 - INFO - graphrag.logger.progress - extract graph progress: 55/68
2025-10-12 17:21:03.0610 - INFO - graphrag.logger.progress - extract graph progress: 56/68
2025-10-12 17:21:03.0612 - INFO - graphrag.logger.progress - extract graph progress: 57/68
2025-10-12 17:21:03.0614 - INFO - graphrag.logger.progress - extract graph progress: 58/68
2025-10-12 17:21:03.0618 - INFO - graphrag.logger.progress - extract graph progress: 59/68
2025-10-12 17:21:03.0622 - INFO - graphrag.logger.progress - extract graph progress: 60/68
2025-10-12 17:21:03.0625 - INFO - graphrag.logger.progress - extract graph progress: 61/68
2025-10-12 17:21:03.0629 - INFO - graphrag.logger.progress - extract graph progress: 62/68
2025-10-12 17:21:03.0634 - INFO - graphrag.logger.progress - extract graph progress: 63/68
2025-10-12 17:21:03.0638 - INFO - graphrag.logger.progress - extract graph progress: 64/68
2025-10-12 17:21:03.0642 - INFO - graphrag.logger.progress - extract graph progress: 65/68
2025-10-12 17:21:03.0646 - INFO - graphrag.logger.progress - extract graph progress: 66/68
2025-10-12 17:21:03.0650 - INFO - graphrag.logger.progress - extract graph progress: 67/68
2025-10-12 17:21:03.0653 - INFO - graphrag.logger.progress - extract graph progress: 68/68
2025-10-12 17:21:03.0674 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/summarize_descriptions
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/23
2025-10-12 17:21:03.0677 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/23
2025-10-12 17:21:04.0499 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/23
2025-10-12 17:21:04.0500 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/23
2025-10-12 17:21:04.0512 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-10-12 17:21:04.0512 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-10-12 17:21:04.0519 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-10-12 17:21:04.0519 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0524 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0540 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-10-12 17:21:04.0540 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-10-12 17:21:04.0547 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-10-12 17:21:04.0547 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-10-12 17:21:04.0547 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-10-12 17:21:04.0547 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-10-12 17:21:04.0547 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0551 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0574 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-10-12 17:21:04.0574 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-10-12 17:21:04.0579 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-10-12 17:21:04.0579 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:21:04.0583 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0586 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0604 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-10-12 17:21:04.0604 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-10-12 17:21:04.0609 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-10-12 17:21:04.0609 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 17:21:04.0613 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:04.0616 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-10-12 17:21:04.0625 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 5
2025-10-12 17:21:04.0646 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/community_reporting
2025-10-12 17:21:10.0323 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/1
2025-10-12 17:21:10.0331 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-10-12 17:21:10.0331 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-10-12 17:21:10.0337 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-10-12 17:21:10.0337 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-10-12 17:21:10.0337 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 17:21:10.0341 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 17:21:10.0345 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-10-12 17:21:10.0350 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-10-12 17:21:10.0350 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-10-12 17:21:10.0372 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 17:21:10.0372 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/text_embedding
2025-10-12 17:21:10.0376 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 14 inputs via 14 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 17:21:23.0050 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-10-12 17:21:23.0177 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-10-12 17:21:23.0179 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 17:21:23.0180 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 17:21:23.0247 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-10-12 17:21:23.0308 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-10-12 17:21:23.0310 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 17:21:23.0311 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 68 inputs via 68 snippets using 5 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 17:21:38.0615 - INFO - graphrag.logger.progress - generate embeddings progress: 1/5
2025-10-12 17:21:54.0730 - INFO - graphrag.logger.progress - generate embeddings progress: 2/5
2025-10-12 17:22:11.0917 - INFO - graphrag.logger.progress - generate embeddings progress: 3/5
2025-10-12 17:22:30.0282 - INFO - graphrag.logger.progress - generate embeddings progress: 4/5
2025-10-12 17:22:33.0887 - INFO - graphrag.logger.progress - generate embeddings progress: 5/5
2025-10-12 17:22:33.0935 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-10-12 17:22:33.0935 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-10-12 17:22:33.0948 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-10-12 17:22:33.0953 - INFO - graphrag.cli.index - All workflows completed successfully.
2025-10-12 18:13:32.0877 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 18:13:34.0933 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 18:13:34.0933 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 18:13:34.0934 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "mistral",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "EQUIPMENT",
            "LOCATION",
            "ORGANIZATION",
            "DATE"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 18:13:34.0935 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 18:13:34.0935 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 18:13:34.0935 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:13:34.0935 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 18:13:34.0936 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 18:13:34.0936 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 18:13:34.0938 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 18:13:34.0938 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 18:13:34.0940 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 18:13:34.0940 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:13:34.0940 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 18:13:34.0940 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:13:34.0941 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 18:13:35.0084 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 18:13:35.0084 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 718
2025-10-12 18:13:35.0084 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 718
2025-10-12 18:13:35.0117 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 18:13:35.0151 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 18:13:35.0151 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:13:35.0212 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 527 documents
2025-10-12 18:13:35.0213 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/527
2025-10-12 18:13:35.0214 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/527
2025-10-12 18:13:35.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/527
2025-10-12 18:13:35.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/527
2025-10-12 18:13:35.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/527
2025-10-12 18:13:35.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/527
2025-10-12 18:13:35.0217 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/527
2025-10-12 18:13:35.0218 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/527
2025-10-12 18:13:35.0218 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/527
2025-10-12 18:13:35.0219 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/527
2025-10-12 18:13:35.0219 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/527
2025-10-12 18:13:35.0220 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/527
2025-10-12 18:13:35.0220 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/527
2025-10-12 18:13:35.0221 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/527
2025-10-12 18:13:35.0221 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/527
2025-10-12 18:13:35.0222 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/527
2025-10-12 18:13:35.0222 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/527
2025-10-12 18:13:35.0223 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/527
2025-10-12 18:13:35.0223 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/527
2025-10-12 18:13:35.0224 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/527
2025-10-12 18:13:35.0224 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/527
2025-10-12 18:13:35.0225 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/527
2025-10-12 18:13:35.0225 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/527
2025-10-12 18:13:35.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/527
2025-10-12 18:13:35.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/527
2025-10-12 18:13:35.0227 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/527
2025-10-12 18:13:35.0227 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/527
2025-10-12 18:13:35.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/527
2025-10-12 18:13:35.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/527
2025-10-12 18:13:35.0229 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/527
2025-10-12 18:13:35.0229 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/527
2025-10-12 18:13:35.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/527
2025-10-12 18:13:35.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/527
2025-10-12 18:13:35.0231 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/527
2025-10-12 18:13:35.0231 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/527
2025-10-12 18:13:35.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/527
2025-10-12 18:13:35.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/527
2025-10-12 18:13:35.0233 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/527
2025-10-12 18:13:35.0233 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/527
2025-10-12 18:13:35.0234 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/527
2025-10-12 18:13:35.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/527
2025-10-12 18:13:35.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/527
2025-10-12 18:13:35.0236 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/527
2025-10-12 18:13:35.0236 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/527
2025-10-12 18:13:35.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/527
2025-10-12 18:13:35.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/527
2025-10-12 18:13:35.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/527
2025-10-12 18:13:35.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/527
2025-10-12 18:13:35.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/527
2025-10-12 18:13:35.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/527
2025-10-12 18:13:35.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/527
2025-10-12 18:13:35.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/527
2025-10-12 18:13:35.0241 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/527
2025-10-12 18:13:35.0241 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/527
2025-10-12 18:13:35.0242 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/527
2025-10-12 18:13:35.0242 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/527
2025-10-12 18:13:35.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/527
2025-10-12 18:13:35.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/527
2025-10-12 18:13:35.0244 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/527
2025-10-12 18:13:35.0244 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/527
2025-10-12 18:13:35.0245 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/527
2025-10-12 18:13:35.0245 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/527
2025-10-12 18:13:35.0246 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/527
2025-10-12 18:13:35.0246 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/527
2025-10-12 18:13:35.0247 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/527
2025-10-12 18:13:35.0247 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/527
2025-10-12 18:13:35.0248 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/527
2025-10-12 18:13:35.0248 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/527
2025-10-12 18:13:35.0249 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  69/527
2025-10-12 18:13:35.0249 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  70/527
2025-10-12 18:13:35.0250 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  71/527
2025-10-12 18:13:35.0250 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  72/527
2025-10-12 18:13:35.0251 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  73/527
2025-10-12 18:13:35.0251 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  74/527
2025-10-12 18:13:35.0252 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  75/527
2025-10-12 18:13:35.0252 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  76/527
2025-10-12 18:13:35.0253 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  77/527
2025-10-12 18:13:35.0253 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  78/527
2025-10-12 18:13:35.0254 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  79/527
2025-10-12 18:13:35.0254 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  80/527
2025-10-12 18:13:35.0255 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  81/527
2025-10-12 18:13:35.0255 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  82/527
2025-10-12 18:13:35.0256 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  83/527
2025-10-12 18:13:35.0256 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  84/527
2025-10-12 18:13:35.0257 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  85/527
2025-10-12 18:13:35.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  86/527
2025-10-12 18:13:35.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  87/527
2025-10-12 18:13:35.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  88/527
2025-10-12 18:13:35.0259 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  89/527
2025-10-12 18:13:35.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  90/527
2025-10-12 18:13:35.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  91/527
2025-10-12 18:13:35.0261 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  92/527
2025-10-12 18:13:35.0261 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  93/527
2025-10-12 18:13:35.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  94/527
2025-10-12 18:13:35.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  95/527
2025-10-12 18:13:35.0263 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  96/527
2025-10-12 18:13:35.0263 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  97/527
2025-10-12 18:13:35.0264 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  98/527
2025-10-12 18:13:35.0264 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  99/527
2025-10-12 18:13:35.0265 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  100/527
2025-10-12 18:13:35.0265 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  101/527
2025-10-12 18:13:35.0266 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  102/527
2025-10-12 18:13:35.0266 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  103/527
2025-10-12 18:13:35.0267 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  104/527
2025-10-12 18:13:35.0267 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  105/527
2025-10-12 18:13:35.0268 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  106/527
2025-10-12 18:13:35.0268 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  107/527
2025-10-12 18:13:35.0269 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  108/527
2025-10-12 18:13:35.0269 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  109/527
2025-10-12 18:13:35.0270 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  110/527
2025-10-12 18:13:35.0270 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  111/527
2025-10-12 18:13:35.0271 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  112/527
2025-10-12 18:13:35.0271 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  113/527
2025-10-12 18:13:35.0272 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  114/527
2025-10-12 18:13:35.0272 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  115/527
2025-10-12 18:13:35.0273 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  116/527
2025-10-12 18:13:35.0273 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  117/527
2025-10-12 18:13:35.0274 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  118/527
2025-10-12 18:13:35.0274 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  119/527
2025-10-12 18:13:35.0275 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  120/527
2025-10-12 18:13:35.0275 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  121/527
2025-10-12 18:13:35.0276 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  122/527
2025-10-12 18:13:35.0276 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  123/527
2025-10-12 18:13:35.0277 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  124/527
2025-10-12 18:13:35.0277 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  125/527
2025-10-12 18:13:35.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  126/527
2025-10-12 18:13:35.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  127/527
2025-10-12 18:13:35.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  128/527
2025-10-12 18:13:35.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  129/527
2025-10-12 18:13:35.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  130/527
2025-10-12 18:13:35.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  131/527
2025-10-12 18:13:35.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  132/527
2025-10-12 18:13:35.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  133/527
2025-10-12 18:13:35.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  134/527
2025-10-12 18:13:35.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  135/527
2025-10-12 18:13:35.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  136/527
2025-10-12 18:13:35.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  137/527
2025-10-12 18:13:35.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  138/527
2025-10-12 18:13:35.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  139/527
2025-10-12 18:13:35.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  140/527
2025-10-12 18:13:35.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  141/527
2025-10-12 18:13:35.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  142/527
2025-10-12 18:13:35.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  143/527
2025-10-12 18:13:35.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  144/527
2025-10-12 18:13:35.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  145/527
2025-10-12 18:13:35.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  146/527
2025-10-12 18:13:35.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  147/527
2025-10-12 18:13:35.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  148/527
2025-10-12 18:13:35.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  149/527
2025-10-12 18:13:35.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  150/527
2025-10-12 18:13:35.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  151/527
2025-10-12 18:13:35.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  152/527
2025-10-12 18:13:35.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  153/527
2025-10-12 18:13:35.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  154/527
2025-10-12 18:13:35.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  155/527
2025-10-12 18:13:35.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  156/527
2025-10-12 18:13:35.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  157/527
2025-10-12 18:13:35.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  158/527
2025-10-12 18:13:35.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  159/527
2025-10-12 18:13:35.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  160/527
2025-10-12 18:13:35.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  161/527
2025-10-12 18:13:35.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  162/527
2025-10-12 18:13:35.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  163/527
2025-10-12 18:13:35.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  164/527
2025-10-12 18:13:35.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  165/527
2025-10-12 18:13:35.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  166/527
2025-10-12 18:13:35.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  167/527
2025-10-12 18:13:35.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  168/527
2025-10-12 18:13:35.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  169/527
2025-10-12 18:13:35.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  170/527
2025-10-12 18:13:35.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  171/527
2025-10-12 18:13:35.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  172/527
2025-10-12 18:13:35.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  173/527
2025-10-12 18:13:35.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  174/527
2025-10-12 18:13:35.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  175/527
2025-10-12 18:13:35.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  176/527
2025-10-12 18:13:35.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  177/527
2025-10-12 18:13:35.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  178/527
2025-10-12 18:13:35.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  179/527
2025-10-12 18:13:35.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  180/527
2025-10-12 18:13:35.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  181/527
2025-10-12 18:13:35.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  182/527
2025-10-12 18:13:35.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  183/527
2025-10-12 18:13:35.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  184/527
2025-10-12 18:13:35.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  185/527
2025-10-12 18:13:35.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  186/527
2025-10-12 18:13:35.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  187/527
2025-10-12 18:13:35.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  188/527
2025-10-12 18:13:35.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  189/527
2025-10-12 18:13:35.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  190/527
2025-10-12 18:13:35.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  191/527
2025-10-12 18:13:35.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  192/527
2025-10-12 18:13:35.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  193/527
2025-10-12 18:13:35.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  194/527
2025-10-12 18:13:35.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  195/527
2025-10-12 18:13:35.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  196/527
2025-10-12 18:13:35.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  197/527
2025-10-12 18:13:35.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  198/527
2025-10-12 18:13:35.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  199/527
2025-10-12 18:13:35.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  200/527
2025-10-12 18:13:35.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  201/527
2025-10-12 18:13:35.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  202/527
2025-10-12 18:13:35.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  203/527
2025-10-12 18:13:35.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  204/527
2025-10-12 18:13:35.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  205/527
2025-10-12 18:13:35.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  206/527
2025-10-12 18:13:35.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  207/527
2025-10-12 18:13:35.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  208/527
2025-10-12 18:13:35.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  209/527
2025-10-12 18:13:35.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  210/527
2025-10-12 18:13:35.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  211/527
2025-10-12 18:13:35.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  212/527
2025-10-12 18:13:35.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  213/527
2025-10-12 18:13:35.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  214/527
2025-10-12 18:13:35.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  215/527
2025-10-12 18:13:35.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  216/527
2025-10-12 18:13:35.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  217/527
2025-10-12 18:13:35.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  218/527
2025-10-12 18:13:35.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  219/527
2025-10-12 18:13:35.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  220/527
2025-10-12 18:13:35.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  221/527
2025-10-12 18:13:35.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  222/527
2025-10-12 18:13:35.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  223/527
2025-10-12 18:13:35.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  224/527
2025-10-12 18:13:35.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  225/527
2025-10-12 18:13:35.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  226/527
2025-10-12 18:13:35.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  227/527
2025-10-12 18:13:35.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  228/527
2025-10-12 18:13:35.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  229/527
2025-10-12 18:13:35.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  230/527
2025-10-12 18:13:35.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  231/527
2025-10-12 18:13:35.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  232/527
2025-10-12 18:13:35.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  233/527
2025-10-12 18:13:35.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  234/527
2025-10-12 18:13:35.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  235/527
2025-10-12 18:13:35.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  236/527
2025-10-12 18:13:35.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  237/527
2025-10-12 18:13:35.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  238/527
2025-10-12 18:13:35.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  239/527
2025-10-12 18:13:35.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  240/527
2025-10-12 18:13:35.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  241/527
2025-10-12 18:13:35.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  242/527
2025-10-12 18:13:35.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  243/527
2025-10-12 18:13:35.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  244/527
2025-10-12 18:13:35.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  245/527
2025-10-12 18:13:35.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  246/527
2025-10-12 18:13:35.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  247/527
2025-10-12 18:13:35.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  248/527
2025-10-12 18:13:35.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  249/527
2025-10-12 18:13:35.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  250/527
2025-10-12 18:13:35.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  251/527
2025-10-12 18:13:35.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  252/527
2025-10-12 18:13:35.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  253/527
2025-10-12 18:13:35.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  254/527
2025-10-12 18:13:35.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  255/527
2025-10-12 18:13:35.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  256/527
2025-10-12 18:13:35.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  257/527
2025-10-12 18:13:35.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  258/527
2025-10-12 18:13:35.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  259/527
2025-10-12 18:13:35.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  260/527
2025-10-12 18:13:35.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  261/527
2025-10-12 18:13:35.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  262/527
2025-10-12 18:13:35.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  263/527
2025-10-12 18:13:35.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  264/527
2025-10-12 18:13:35.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  265/527
2025-10-12 18:13:35.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  266/527
2025-10-12 18:13:35.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  267/527
2025-10-12 18:13:35.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  268/527
2025-10-12 18:13:35.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  269/527
2025-10-12 18:13:35.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  270/527
2025-10-12 18:13:35.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  271/527
2025-10-12 18:13:35.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  272/527
2025-10-12 18:13:35.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  273/527
2025-10-12 18:13:35.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  274/527
2025-10-12 18:13:35.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  275/527
2025-10-12 18:13:35.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  276/527
2025-10-12 18:13:35.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  277/527
2025-10-12 18:13:35.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  278/527
2025-10-12 18:13:35.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  279/527
2025-10-12 18:13:35.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  280/527
2025-10-12 18:13:35.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  281/527
2025-10-12 18:13:35.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  282/527
2025-10-12 18:13:35.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  283/527
2025-10-12 18:13:35.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  284/527
2025-10-12 18:13:35.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  285/527
2025-10-12 18:13:35.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  286/527
2025-10-12 18:13:35.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  287/527
2025-10-12 18:13:35.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  288/527
2025-10-12 18:13:35.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  289/527
2025-10-12 18:13:35.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  290/527
2025-10-12 18:13:35.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  291/527
2025-10-12 18:13:35.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  292/527
2025-10-12 18:13:35.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  293/527
2025-10-12 18:13:35.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  294/527
2025-10-12 18:13:35.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  295/527
2025-10-12 18:13:35.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  296/527
2025-10-12 18:13:35.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  297/527
2025-10-12 18:13:35.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  298/527
2025-10-12 18:13:35.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  299/527
2025-10-12 18:13:35.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  300/527
2025-10-12 18:13:35.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  301/527
2025-10-12 18:13:35.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  302/527
2025-10-12 18:13:35.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  303/527
2025-10-12 18:13:35.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  304/527
2025-10-12 18:13:35.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  305/527
2025-10-12 18:13:35.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  306/527
2025-10-12 18:13:35.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  307/527
2025-10-12 18:13:35.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  308/527
2025-10-12 18:13:35.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  309/527
2025-10-12 18:13:35.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  310/527
2025-10-12 18:13:35.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  311/527
2025-10-12 18:13:35.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  312/527
2025-10-12 18:13:35.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  313/527
2025-10-12 18:13:35.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  314/527
2025-10-12 18:13:35.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  315/527
2025-10-12 18:13:35.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  316/527
2025-10-12 18:13:35.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  317/527
2025-10-12 18:13:35.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  318/527
2025-10-12 18:13:35.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  319/527
2025-10-12 18:13:35.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  320/527
2025-10-12 18:13:35.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  321/527
2025-10-12 18:13:35.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  322/527
2025-10-12 18:13:35.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  323/527
2025-10-12 18:13:35.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  324/527
2025-10-12 18:13:35.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  325/527
2025-10-12 18:13:35.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  326/527
2025-10-12 18:13:35.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  327/527
2025-10-12 18:13:35.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  328/527
2025-10-12 18:13:35.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  329/527
2025-10-12 18:13:35.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  330/527
2025-10-12 18:13:35.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  331/527
2025-10-12 18:13:35.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  332/527
2025-10-12 18:13:35.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  333/527
2025-10-12 18:13:35.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  334/527
2025-10-12 18:13:35.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  335/527
2025-10-12 18:13:35.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  336/527
2025-10-12 18:13:35.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  337/527
2025-10-12 18:13:35.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  338/527
2025-10-12 18:13:35.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  339/527
2025-10-12 18:13:35.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  340/527
2025-10-12 18:13:35.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  341/527
2025-10-12 18:13:35.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  342/527
2025-10-12 18:13:35.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  343/527
2025-10-12 18:13:35.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  344/527
2025-10-12 18:13:35.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  345/527
2025-10-12 18:13:35.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  346/527
2025-10-12 18:13:35.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  347/527
2025-10-12 18:13:35.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  348/527
2025-10-12 18:13:35.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  349/527
2025-10-12 18:13:35.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  350/527
2025-10-12 18:13:35.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  351/527
2025-10-12 18:13:35.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  352/527
2025-10-12 18:13:35.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  353/527
2025-10-12 18:13:35.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  354/527
2025-10-12 18:13:35.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  355/527
2025-10-12 18:13:35.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  356/527
2025-10-12 18:13:35.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  357/527
2025-10-12 18:13:35.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  358/527
2025-10-12 18:13:35.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  359/527
2025-10-12 18:13:35.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  360/527
2025-10-12 18:13:35.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  361/527
2025-10-12 18:13:35.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  362/527
2025-10-12 18:13:35.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  363/527
2025-10-12 18:13:35.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  364/527
2025-10-12 18:13:35.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  365/527
2025-10-12 18:13:35.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  366/527
2025-10-12 18:13:35.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  367/527
2025-10-12 18:13:35.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  368/527
2025-10-12 18:13:35.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  369/527
2025-10-12 18:13:35.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  370/527
2025-10-12 18:13:35.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  371/527
2025-10-12 18:13:35.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  372/527
2025-10-12 18:13:35.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  373/527
2025-10-12 18:13:35.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  374/527
2025-10-12 18:13:35.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  375/527
2025-10-12 18:13:35.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  376/527
2025-10-12 18:13:35.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  377/527
2025-10-12 18:13:35.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  378/527
2025-10-12 18:13:35.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  379/527
2025-10-12 18:13:35.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  380/527
2025-10-12 18:13:35.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  381/527
2025-10-12 18:13:35.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  382/527
2025-10-12 18:13:35.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  383/527
2025-10-12 18:13:35.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  384/527
2025-10-12 18:13:35.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  385/527
2025-10-12 18:13:35.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  386/527
2025-10-12 18:13:35.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  387/527
2025-10-12 18:13:35.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  388/527
2025-10-12 18:13:35.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  389/527
2025-10-12 18:13:35.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  390/527
2025-10-12 18:13:35.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  391/527
2025-10-12 18:13:35.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  392/527
2025-10-12 18:13:35.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  393/527
2025-10-12 18:13:35.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  394/527
2025-10-12 18:13:35.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  395/527
2025-10-12 18:13:35.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  396/527
2025-10-12 18:13:35.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  397/527
2025-10-12 18:13:35.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  398/527
2025-10-12 18:13:35.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  399/527
2025-10-12 18:13:35.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  400/527
2025-10-12 18:13:35.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  401/527
2025-10-12 18:13:35.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  402/527
2025-10-12 18:13:35.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  403/527
2025-10-12 18:13:35.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  404/527
2025-10-12 18:13:35.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  405/527
2025-10-12 18:13:35.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  406/527
2025-10-12 18:13:35.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  407/527
2025-10-12 18:13:35.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  408/527
2025-10-12 18:13:35.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  409/527
2025-10-12 18:13:35.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  410/527
2025-10-12 18:13:35.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  411/527
2025-10-12 18:13:35.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  412/527
2025-10-12 18:13:35.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  413/527
2025-10-12 18:13:35.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  414/527
2025-10-12 18:13:35.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  415/527
2025-10-12 18:13:35.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  416/527
2025-10-12 18:13:35.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  417/527
2025-10-12 18:13:35.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  418/527
2025-10-12 18:13:35.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  419/527
2025-10-12 18:13:35.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  420/527
2025-10-12 18:13:35.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  421/527
2025-10-12 18:13:35.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  422/527
2025-10-12 18:13:35.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  423/527
2025-10-12 18:13:35.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  424/527
2025-10-12 18:13:35.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  425/527
2025-10-12 18:13:35.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  426/527
2025-10-12 18:13:35.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  427/527
2025-10-12 18:13:35.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  428/527
2025-10-12 18:13:35.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  429/527
2025-10-12 18:13:35.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  430/527
2025-10-12 18:13:35.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  431/527
2025-10-12 18:13:35.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  432/527
2025-10-12 18:13:35.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  433/527
2025-10-12 18:13:35.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  434/527
2025-10-12 18:13:35.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  435/527
2025-10-12 18:13:35.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  436/527
2025-10-12 18:13:35.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  437/527
2025-10-12 18:13:35.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  438/527
2025-10-12 18:13:35.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  439/527
2025-10-12 18:13:35.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  440/527
2025-10-12 18:13:35.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  441/527
2025-10-12 18:13:35.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  442/527
2025-10-12 18:13:35.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  443/527
2025-10-12 18:13:35.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  444/527
2025-10-12 18:13:35.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  445/527
2025-10-12 18:13:35.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  446/527
2025-10-12 18:13:35.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  447/527
2025-10-12 18:13:35.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  448/527
2025-10-12 18:13:35.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  449/527
2025-10-12 18:13:35.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  450/527
2025-10-12 18:13:35.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  451/527
2025-10-12 18:13:35.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  452/527
2025-10-12 18:13:35.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  453/527
2025-10-12 18:13:35.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  454/527
2025-10-12 18:13:35.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  455/527
2025-10-12 18:13:35.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  456/527
2025-10-12 18:13:35.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  457/527
2025-10-12 18:13:35.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  458/527
2025-10-12 18:13:35.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  459/527
2025-10-12 18:13:35.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  460/527
2025-10-12 18:13:35.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  461/527
2025-10-12 18:13:35.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  462/527
2025-10-12 18:13:35.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  463/527
2025-10-12 18:13:35.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  464/527
2025-10-12 18:13:35.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  465/527
2025-10-12 18:13:35.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  466/527
2025-10-12 18:13:35.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  467/527
2025-10-12 18:13:35.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  468/527
2025-10-12 18:13:35.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  469/527
2025-10-12 18:13:35.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  470/527
2025-10-12 18:13:35.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  471/527
2025-10-12 18:13:35.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  472/527
2025-10-12 18:13:35.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  473/527
2025-10-12 18:13:35.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  474/527
2025-10-12 18:13:35.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  475/527
2025-10-12 18:13:35.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  476/527
2025-10-12 18:13:35.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  477/527
2025-10-12 18:13:35.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  478/527
2025-10-12 18:13:35.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  479/527
2025-10-12 18:13:35.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  480/527
2025-10-12 18:13:35.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  481/527
2025-10-12 18:13:35.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  482/527
2025-10-12 18:13:35.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  483/527
2025-10-12 18:13:35.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  484/527
2025-10-12 18:13:35.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  485/527
2025-10-12 18:13:35.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  486/527
2025-10-12 18:13:35.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  487/527
2025-10-12 18:13:35.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  488/527
2025-10-12 18:13:35.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  489/527
2025-10-12 18:13:35.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  490/527
2025-10-12 18:13:35.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  491/527
2025-10-12 18:13:35.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  492/527
2025-10-12 18:13:35.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  493/527
2025-10-12 18:13:35.0672 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  494/527
2025-10-12 18:13:35.0673 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  495/527
2025-10-12 18:13:35.0674 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  496/527
2025-10-12 18:13:35.0674 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  497/527
2025-10-12 18:13:35.0675 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  498/527
2025-10-12 18:13:35.0675 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  499/527
2025-10-12 18:13:35.0676 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  500/527
2025-10-12 18:13:35.0676 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  501/527
2025-10-12 18:13:35.0677 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  502/527
2025-10-12 18:13:35.0677 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  503/527
2025-10-12 18:13:35.0678 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  504/527
2025-10-12 18:13:35.0679 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  505/527
2025-10-12 18:13:35.0679 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  506/527
2025-10-12 18:13:35.0680 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  507/527
2025-10-12 18:13:35.0680 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  508/527
2025-10-12 18:13:35.0681 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  509/527
2025-10-12 18:13:35.0681 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  510/527
2025-10-12 18:13:35.0682 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  511/527
2025-10-12 18:13:35.0682 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  512/527
2025-10-12 18:13:35.0683 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  513/527
2025-10-12 18:13:35.0683 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  514/527
2025-10-12 18:13:35.0684 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  515/527
2025-10-12 18:13:35.0684 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  516/527
2025-10-12 18:13:35.0685 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  517/527
2025-10-12 18:13:35.0685 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  518/527
2025-10-12 18:13:35.0686 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  519/527
2025-10-12 18:13:35.0687 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  520/527
2025-10-12 18:13:35.0687 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  521/527
2025-10-12 18:13:35.0688 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  522/527
2025-10-12 18:13:35.0688 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  523/527
2025-10-12 18:13:35.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  524/527
2025-10-12 18:13:35.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  525/527
2025-10-12 18:13:35.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  526/527
2025-10-12 18:13:35.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  527/527
2025-10-12 18:13:35.0713 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-12 18:13:35.0713 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-12 18:13:35.0717 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-12 18:13:35.0717 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:13:35.0736 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:13:35.0776 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-12 18:13:35.0776 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-12 18:13:35.0780 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-12 18:13:35.0781 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:13:35.0799 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/extract_graph
2025-10-12 18:13:44.0170 - INFO - graphrag.logger.progress - extract graph progress: 1/527
2025-10-12 18:13:44.0175 - INFO - graphrag.logger.progress - extract graph progress: 2/527
2025-10-12 18:13:44.0179 - INFO - graphrag.logger.progress - extract graph progress: 3/527
2025-10-12 18:13:44.0184 - INFO - graphrag.logger.progress - extract graph progress: 4/527
2025-10-12 18:13:44.0188 - INFO - graphrag.logger.progress - extract graph progress: 5/527
2025-10-12 18:13:44.0192 - INFO - graphrag.logger.progress - extract graph progress: 6/527
2025-10-12 18:13:44.0196 - INFO - graphrag.logger.progress - extract graph progress: 7/527
2025-10-12 18:13:44.0200 - INFO - graphrag.logger.progress - extract graph progress: 8/527
2025-10-12 18:13:44.0203 - INFO - graphrag.logger.progress - extract graph progress: 9/527
2025-10-12 18:13:44.0206 - INFO - graphrag.logger.progress - extract graph progress: 10/527
2025-10-12 18:13:44.0210 - INFO - graphrag.logger.progress - extract graph progress: 11/527
2025-10-12 18:13:44.0214 - INFO - graphrag.logger.progress - extract graph progress: 12/527
2025-10-12 18:13:44.0218 - INFO - graphrag.logger.progress - extract graph progress: 13/527
2025-10-12 18:13:44.0222 - INFO - graphrag.logger.progress - extract graph progress: 14/527
2025-10-12 18:13:44.0225 - INFO - graphrag.logger.progress - extract graph progress: 15/527
2025-10-12 18:13:44.0228 - INFO - graphrag.logger.progress - extract graph progress: 16/527
2025-10-12 18:13:44.0231 - INFO - graphrag.logger.progress - extract graph progress: 17/527
2025-10-12 18:13:44.0234 - INFO - graphrag.logger.progress - extract graph progress: 18/527
2025-10-12 18:13:44.0238 - INFO - graphrag.logger.progress - extract graph progress: 19/527
2025-10-12 18:13:44.0242 - INFO - graphrag.logger.progress - extract graph progress: 20/527
2025-10-12 18:13:44.0244 - INFO - graphrag.logger.progress - extract graph progress: 21/527
2025-10-12 18:13:44.0246 - INFO - graphrag.logger.progress - extract graph progress: 22/527
2025-10-12 18:13:44.0249 - INFO - graphrag.logger.progress - extract graph progress: 23/527
2025-10-12 18:13:44.0251 - INFO - graphrag.logger.progress - extract graph progress: 24/527
2025-10-12 18:13:44.0255 - INFO - graphrag.logger.progress - extract graph progress: 25/527
2025-10-12 18:13:44.0258 - INFO - graphrag.logger.progress - extract graph progress: 26/527
2025-10-12 18:13:44.0261 - INFO - graphrag.logger.progress - extract graph progress: 27/527
2025-10-12 18:13:44.0265 - INFO - graphrag.logger.progress - extract graph progress: 28/527
2025-10-12 18:13:44.0269 - INFO - graphrag.logger.progress - extract graph progress: 29/527
2025-10-12 18:13:44.0273 - INFO - graphrag.logger.progress - extract graph progress: 30/527
2025-10-12 18:13:56.0513 - INFO - graphrag.logger.progress - extract graph progress: 31/527
2025-10-12 18:13:56.0518 - INFO - graphrag.logger.progress - extract graph progress: 32/527
2025-10-12 18:13:56.0520 - INFO - graphrag.logger.progress - extract graph progress: 33/527
2025-10-12 18:13:56.0523 - INFO - graphrag.logger.progress - extract graph progress: 34/527
2025-10-12 18:13:56.0527 - INFO - graphrag.logger.progress - extract graph progress: 35/527
2025-10-12 18:13:56.0531 - INFO - graphrag.logger.progress - extract graph progress: 36/527
2025-10-12 18:13:56.0534 - INFO - graphrag.logger.progress - extract graph progress: 37/527
2025-10-12 18:13:56.0538 - INFO - graphrag.logger.progress - extract graph progress: 38/527
2025-10-12 18:13:56.0542 - INFO - graphrag.logger.progress - extract graph progress: 39/527
2025-10-12 18:13:56.0547 - INFO - graphrag.logger.progress - extract graph progress: 40/527
2025-10-12 18:13:56.0550 - INFO - graphrag.logger.progress - extract graph progress: 41/527
2025-10-12 18:13:56.0552 - INFO - graphrag.logger.progress - extract graph progress: 42/527
2025-10-12 18:13:56.0555 - INFO - graphrag.logger.progress - extract graph progress: 43/527
2025-10-12 18:13:56.0559 - INFO - graphrag.logger.progress - extract graph progress: 44/527
2025-10-12 18:13:56.0563 - INFO - graphrag.logger.progress - extract graph progress: 45/527
2025-10-12 18:13:56.0567 - INFO - graphrag.logger.progress - extract graph progress: 46/527
2025-10-12 18:13:56.0572 - INFO - graphrag.logger.progress - extract graph progress: 47/527
2025-10-12 18:13:56.0576 - INFO - graphrag.logger.progress - extract graph progress: 48/527
2025-10-12 18:13:56.0580 - INFO - graphrag.logger.progress - extract graph progress: 49/527
2025-10-12 18:13:56.0584 - INFO - graphrag.logger.progress - extract graph progress: 50/527
2025-10-12 18:13:56.0588 - INFO - graphrag.logger.progress - extract graph progress: 51/527
2025-10-12 18:13:56.0591 - INFO - graphrag.logger.progress - extract graph progress: 52/527
2025-10-12 18:13:56.0594 - INFO - graphrag.logger.progress - extract graph progress: 53/527
2025-10-12 18:13:56.0598 - INFO - graphrag.logger.progress - extract graph progress: 54/527
2025-10-12 18:13:56.0603 - INFO - graphrag.logger.progress - extract graph progress: 55/527
2025-10-12 18:14:16.0973 - INFO - graphrag.logger.progress - extract graph progress: 56/527
2025-10-12 18:14:16.0976 - INFO - graphrag.logger.progress - extract graph progress: 57/527
2025-10-12 18:14:16.0979 - INFO - graphrag.logger.progress - extract graph progress: 58/527
2025-10-12 18:14:16.0981 - INFO - graphrag.logger.progress - extract graph progress: 59/527
2025-10-12 18:14:16.0983 - INFO - graphrag.logger.progress - extract graph progress: 60/527
2025-10-12 18:14:16.0985 - INFO - graphrag.logger.progress - extract graph progress: 61/527
2025-10-12 18:14:16.0987 - INFO - graphrag.logger.progress - extract graph progress: 62/527
2025-10-12 18:14:16.0989 - INFO - graphrag.logger.progress - extract graph progress: 63/527
2025-10-12 18:14:16.0991 - INFO - graphrag.logger.progress - extract graph progress: 64/527
2025-10-12 18:14:16.0994 - INFO - graphrag.logger.progress - extract graph progress: 65/527
2025-10-12 18:14:16.0996 - INFO - graphrag.logger.progress - extract graph progress: 66/527
2025-10-12 18:14:16.0998 - INFO - graphrag.logger.progress - extract graph progress: 67/527
2025-10-12 18:14:17.0002 - INFO - graphrag.logger.progress - extract graph progress: 68/527
2025-10-12 18:14:17.0004 - INFO - graphrag.logger.progress - extract graph progress: 69/527
2025-10-12 18:14:17.0007 - INFO - graphrag.logger.progress - extract graph progress: 70/527
2025-10-12 18:14:17.0009 - INFO - graphrag.logger.progress - extract graph progress: 71/527
2025-10-12 18:14:17.0011 - INFO - graphrag.logger.progress - extract graph progress: 72/527
2025-10-12 18:14:17.0013 - INFO - graphrag.logger.progress - extract graph progress: 73/527
2025-10-12 18:14:17.0015 - INFO - graphrag.logger.progress - extract graph progress: 74/527
2025-10-12 18:14:17.0017 - INFO - graphrag.logger.progress - extract graph progress: 75/527
2025-10-12 18:14:17.0019 - INFO - graphrag.logger.progress - extract graph progress: 76/527
2025-10-12 18:14:17.0021 - INFO - graphrag.logger.progress - extract graph progress: 77/527
2025-10-12 18:14:17.0023 - INFO - graphrag.logger.progress - extract graph progress: 78/527
2025-10-12 18:14:17.0025 - INFO - graphrag.logger.progress - extract graph progress: 79/527
2025-10-12 18:14:17.0026 - INFO - graphrag.logger.progress - extract graph progress: 80/527
2025-10-12 18:14:17.0028 - INFO - graphrag.logger.progress - extract graph progress: 81/527
2025-10-12 18:14:17.0031 - INFO - graphrag.logger.progress - extract graph progress: 82/527
2025-10-12 18:14:17.0032 - INFO - graphrag.logger.progress - extract graph progress: 83/527
2025-10-12 18:14:17.0035 - INFO - graphrag.logger.progress - extract graph progress: 84/527
2025-10-12 18:14:17.0036 - INFO - graphrag.logger.progress - extract graph progress: 85/527
2025-10-12 18:14:17.0039 - INFO - graphrag.logger.progress - extract graph progress: 86/527
2025-10-12 18:14:17.0041 - INFO - graphrag.logger.progress - extract graph progress: 87/527
2025-10-12 18:14:17.0043 - INFO - graphrag.logger.progress - extract graph progress: 88/527
2025-10-12 18:14:17.0045 - INFO - graphrag.logger.progress - extract graph progress: 89/527
2025-10-12 18:14:17.0047 - INFO - graphrag.logger.progress - extract graph progress: 90/527
2025-10-12 18:14:17.0049 - INFO - graphrag.logger.progress - extract graph progress: 91/527
2025-10-12 18:14:17.0051 - INFO - graphrag.logger.progress - extract graph progress: 92/527
2025-10-12 18:14:17.0053 - INFO - graphrag.logger.progress - extract graph progress: 93/527
2025-10-12 18:14:17.0055 - INFO - graphrag.logger.progress - extract graph progress: 94/527
2025-10-12 18:14:17.0057 - INFO - graphrag.logger.progress - extract graph progress: 95/527
2025-10-12 18:14:17.0059 - INFO - graphrag.logger.progress - extract graph progress: 96/527
2025-10-12 18:14:17.0062 - INFO - graphrag.logger.progress - extract graph progress: 97/527
2025-10-12 18:14:17.0064 - INFO - graphrag.logger.progress - extract graph progress: 98/527
2025-10-12 18:14:17.0065 - INFO - graphrag.logger.progress - extract graph progress: 99/527
2025-10-12 18:14:17.0067 - INFO - graphrag.logger.progress - extract graph progress: 100/527
2025-10-12 18:14:17.0069 - INFO - graphrag.logger.progress - extract graph progress: 101/527
2025-10-12 18:14:17.0071 - INFO - graphrag.logger.progress - extract graph progress: 102/527
2025-10-12 18:14:17.0073 - INFO - graphrag.logger.progress - extract graph progress: 103/527
2025-10-12 18:14:17.0075 - INFO - graphrag.logger.progress - extract graph progress: 104/527
2025-10-12 18:14:17.0077 - INFO - graphrag.logger.progress - extract graph progress: 105/527
2025-10-12 18:14:17.0079 - INFO - graphrag.logger.progress - extract graph progress: 106/527
2025-10-12 18:14:17.0081 - INFO - graphrag.logger.progress - extract graph progress: 107/527
2025-10-12 18:14:17.0083 - INFO - graphrag.logger.progress - extract graph progress: 108/527
2025-10-12 18:14:17.0086 - INFO - graphrag.logger.progress - extract graph progress: 109/527
2025-10-12 18:14:17.0088 - INFO - graphrag.logger.progress - extract graph progress: 110/527
2025-10-12 18:14:17.0090 - INFO - graphrag.logger.progress - extract graph progress: 111/527
2025-10-12 18:14:17.0092 - INFO - graphrag.logger.progress - extract graph progress: 112/527
2025-10-12 18:14:17.0094 - INFO - graphrag.logger.progress - extract graph progress: 113/527
2025-10-12 18:14:17.0096 - INFO - graphrag.logger.progress - extract graph progress: 114/527
2025-10-12 18:14:17.0098 - INFO - graphrag.logger.progress - extract graph progress: 115/527
2025-10-12 18:14:17.0100 - INFO - graphrag.logger.progress - extract graph progress: 116/527
2025-10-12 18:14:17.0102 - INFO - graphrag.logger.progress - extract graph progress: 117/527
2025-10-12 18:14:17.0104 - INFO - graphrag.logger.progress - extract graph progress: 118/527
2025-10-12 18:14:17.0106 - INFO - graphrag.logger.progress - extract graph progress: 119/527
2025-10-12 18:14:17.0108 - INFO - graphrag.logger.progress - extract graph progress: 120/527
2025-10-12 18:14:17.0111 - INFO - graphrag.logger.progress - extract graph progress: 121/527
2025-10-12 18:14:29.0571 - INFO - graphrag.logger.progress - extract graph progress: 122/527
2025-10-12 18:14:29.0576 - INFO - graphrag.logger.progress - extract graph progress: 123/527
2025-10-12 18:14:29.0580 - INFO - graphrag.logger.progress - extract graph progress: 124/527
2025-10-12 18:14:29.0583 - INFO - graphrag.logger.progress - extract graph progress: 125/527
2025-10-12 18:14:39.0074 - INFO - graphrag.logger.progress - extract graph progress: 126/527
2025-10-12 18:14:39.0078 - INFO - graphrag.logger.progress - extract graph progress: 127/527
2025-10-12 18:14:39.0083 - INFO - graphrag.logger.progress - extract graph progress: 128/527
2025-10-12 18:14:39.0087 - INFO - graphrag.logger.progress - extract graph progress: 129/527
2025-10-12 18:14:39.0091 - INFO - graphrag.logger.progress - extract graph progress: 130/527
2025-10-12 18:14:39.0095 - INFO - graphrag.logger.progress - extract graph progress: 131/527
2025-10-12 18:14:39.0099 - INFO - graphrag.logger.progress - extract graph progress: 132/527
2025-10-12 18:14:39.0103 - INFO - graphrag.logger.progress - extract graph progress: 133/527
2025-10-12 18:14:39.0107 - INFO - graphrag.logger.progress - extract graph progress: 134/527
2025-10-12 18:14:39.0111 - INFO - graphrag.logger.progress - extract graph progress: 135/527
2025-10-12 18:14:39.0113 - INFO - graphrag.logger.progress - extract graph progress: 136/527
2025-10-12 18:14:39.0116 - INFO - graphrag.logger.progress - extract graph progress: 137/527
2025-10-12 18:14:39.0118 - INFO - graphrag.logger.progress - extract graph progress: 138/527
2025-10-12 18:14:39.0120 - INFO - graphrag.logger.progress - extract graph progress: 139/527
2025-10-12 18:14:39.0122 - INFO - graphrag.logger.progress - extract graph progress: 140/527
2025-10-12 18:14:39.0125 - INFO - graphrag.logger.progress - extract graph progress: 141/527
2025-10-12 18:14:39.0129 - INFO - graphrag.logger.progress - extract graph progress: 142/527
2025-10-12 18:14:39.0133 - INFO - graphrag.logger.progress - extract graph progress: 143/527
2025-10-12 18:14:39.0137 - INFO - graphrag.logger.progress - extract graph progress: 144/527
2025-10-12 18:14:39.0141 - INFO - graphrag.logger.progress - extract graph progress: 145/527
2025-10-12 18:14:39.0145 - INFO - graphrag.logger.progress - extract graph progress: 146/527
2025-10-12 18:14:39.0148 - INFO - graphrag.logger.progress - extract graph progress: 147/527
2025-10-12 18:14:39.0151 - INFO - graphrag.logger.progress - extract graph progress: 148/527
2025-10-12 18:14:39.0155 - INFO - graphrag.logger.progress - extract graph progress: 149/527
2025-10-12 18:14:58.0008 - INFO - graphrag.logger.progress - extract graph progress: 150/527
2025-10-12 18:14:58.0012 - INFO - graphrag.logger.progress - extract graph progress: 151/527
2025-10-12 18:14:58.0017 - INFO - graphrag.logger.progress - extract graph progress: 152/527
2025-10-12 18:14:58.0020 - INFO - graphrag.logger.progress - extract graph progress: 153/527
2025-10-12 18:15:08.0192 - INFO - graphrag.logger.progress - extract graph progress: 154/527
2025-10-12 18:15:08.0196 - INFO - graphrag.logger.progress - extract graph progress: 155/527
2025-10-12 18:15:08.0200 - INFO - graphrag.logger.progress - extract graph progress: 156/527
2025-10-12 18:15:08.0204 - INFO - graphrag.logger.progress - extract graph progress: 157/527
2025-10-12 18:15:08.0206 - INFO - graphrag.logger.progress - extract graph progress: 158/527
2025-10-12 18:15:08.0209 - INFO - graphrag.logger.progress - extract graph progress: 159/527
2025-10-12 18:15:08.0212 - INFO - graphrag.logger.progress - extract graph progress: 160/527
2025-10-12 18:15:08.0216 - INFO - graphrag.logger.progress - extract graph progress: 161/527
2025-10-12 18:15:08.0220 - INFO - graphrag.logger.progress - extract graph progress: 162/527
2025-10-12 18:15:08.0224 - INFO - graphrag.logger.progress - extract graph progress: 163/527
2025-10-12 18:15:08.0227 - INFO - graphrag.logger.progress - extract graph progress: 164/527
2025-10-12 18:15:08.0230 - INFO - graphrag.logger.progress - extract graph progress: 165/527
2025-10-12 18:15:08.0233 - INFO - graphrag.logger.progress - extract graph progress: 166/527
2025-10-12 18:15:08.0236 - INFO - graphrag.logger.progress - extract graph progress: 167/527
2025-10-12 18:15:08.0240 - INFO - graphrag.logger.progress - extract graph progress: 168/527
2025-10-12 18:15:08.0243 - INFO - graphrag.logger.progress - extract graph progress: 169/527
2025-10-12 18:15:08.0245 - INFO - graphrag.logger.progress - extract graph progress: 170/527
2025-10-12 18:15:12.0877 - INFO - graphrag.logger.progress - extract graph progress: 171/527
2025-10-12 18:15:12.0879 - INFO - graphrag.logger.progress - extract graph progress: 172/527
2025-10-12 18:15:12.0882 - INFO - graphrag.logger.progress - extract graph progress: 173/527
2025-10-12 18:15:12.0884 - INFO - graphrag.logger.progress - extract graph progress: 174/527
2025-10-12 18:15:12.0886 - INFO - graphrag.logger.progress - extract graph progress: 175/527
2025-10-12 18:15:12.0888 - INFO - graphrag.logger.progress - extract graph progress: 176/527
2025-10-12 18:15:12.0891 - INFO - graphrag.logger.progress - extract graph progress: 177/527
2025-10-12 18:15:12.0893 - INFO - graphrag.logger.progress - extract graph progress: 178/527
2025-10-12 18:15:12.0895 - INFO - graphrag.logger.progress - extract graph progress: 179/527
2025-10-12 18:15:12.0897 - INFO - graphrag.logger.progress - extract graph progress: 180/527
2025-10-12 18:15:12.0899 - INFO - graphrag.logger.progress - extract graph progress: 181/527
2025-10-12 18:15:12.0903 - INFO - graphrag.logger.progress - extract graph progress: 182/527
2025-10-12 18:15:12.0905 - INFO - graphrag.logger.progress - extract graph progress: 183/527
2025-10-12 18:15:12.0907 - INFO - graphrag.logger.progress - extract graph progress: 184/527
2025-10-12 18:15:12.0909 - INFO - graphrag.logger.progress - extract graph progress: 185/527
2025-10-12 18:15:12.0911 - INFO - graphrag.logger.progress - extract graph progress: 186/527
2025-10-12 18:15:12.0914 - INFO - graphrag.logger.progress - extract graph progress: 187/527
2025-10-12 18:15:12.0916 - INFO - graphrag.logger.progress - extract graph progress: 188/527
2025-10-12 18:15:12.0919 - INFO - graphrag.logger.progress - extract graph progress: 189/527
2025-10-12 18:15:12.0921 - INFO - graphrag.logger.progress - extract graph progress: 190/527
2025-10-12 18:15:12.0923 - INFO - graphrag.logger.progress - extract graph progress: 191/527
2025-10-12 18:15:12.0925 - INFO - graphrag.logger.progress - extract graph progress: 192/527
2025-10-12 18:15:12.0928 - INFO - graphrag.logger.progress - extract graph progress: 193/527
2025-10-12 18:15:12.0930 - INFO - graphrag.logger.progress - extract graph progress: 194/527
2025-10-12 18:15:12.0932 - INFO - graphrag.logger.progress - extract graph progress: 195/527
2025-10-12 18:15:12.0934 - INFO - graphrag.logger.progress - extract graph progress: 196/527
2025-10-12 18:15:12.0936 - INFO - graphrag.logger.progress - extract graph progress: 197/527
2025-10-12 18:15:12.0939 - INFO - graphrag.logger.progress - extract graph progress: 198/527
2025-10-12 18:15:12.0941 - INFO - graphrag.logger.progress - extract graph progress: 199/527
2025-10-12 18:15:12.0943 - INFO - graphrag.logger.progress - extract graph progress: 200/527
2025-10-12 18:15:12.0945 - INFO - graphrag.logger.progress - extract graph progress: 201/527
2025-10-12 18:15:12.0947 - INFO - graphrag.logger.progress - extract graph progress: 202/527
2025-10-12 18:15:12.0950 - INFO - graphrag.logger.progress - extract graph progress: 203/527
2025-10-12 18:15:12.0952 - INFO - graphrag.logger.progress - extract graph progress: 204/527
2025-10-12 18:15:12.0954 - INFO - graphrag.logger.progress - extract graph progress: 205/527
2025-10-12 18:15:12.0956 - INFO - graphrag.logger.progress - extract graph progress: 206/527
2025-10-12 18:15:12.0958 - INFO - graphrag.logger.progress - extract graph progress: 207/527
2025-10-12 18:15:12.0960 - INFO - graphrag.logger.progress - extract graph progress: 208/527
2025-10-12 18:15:12.0962 - INFO - graphrag.logger.progress - extract graph progress: 209/527
2025-10-12 18:15:12.0965 - INFO - graphrag.logger.progress - extract graph progress: 210/527
2025-10-12 18:15:12.0967 - INFO - graphrag.logger.progress - extract graph progress: 211/527
2025-10-12 18:15:12.0969 - INFO - graphrag.logger.progress - extract graph progress: 212/527
2025-10-12 18:15:12.0971 - INFO - graphrag.logger.progress - extract graph progress: 213/527
2025-10-12 18:15:12.0973 - INFO - graphrag.logger.progress - extract graph progress: 214/527
2025-10-12 18:15:12.0976 - INFO - graphrag.logger.progress - extract graph progress: 215/527
2025-10-12 18:15:12.0978 - INFO - graphrag.logger.progress - extract graph progress: 216/527
2025-10-12 18:15:12.0980 - INFO - graphrag.logger.progress - extract graph progress: 217/527
2025-10-12 18:15:12.0982 - INFO - graphrag.logger.progress - extract graph progress: 218/527
2025-10-12 18:15:12.0984 - INFO - graphrag.logger.progress - extract graph progress: 219/527
2025-10-12 18:15:12.0986 - INFO - graphrag.logger.progress - extract graph progress: 220/527
2025-10-12 18:15:12.0988 - INFO - graphrag.logger.progress - extract graph progress: 221/527
2025-10-12 18:15:12.0990 - INFO - graphrag.logger.progress - extract graph progress: 222/527
2025-10-12 18:15:12.0993 - INFO - graphrag.logger.progress - extract graph progress: 223/527
2025-10-12 18:15:12.0996 - INFO - graphrag.logger.progress - extract graph progress: 224/527
2025-10-12 18:15:12.0998 - INFO - graphrag.logger.progress - extract graph progress: 225/527
2025-10-12 18:15:13.0000 - INFO - graphrag.logger.progress - extract graph progress: 226/527
2025-10-12 18:15:13.0002 - INFO - graphrag.logger.progress - extract graph progress: 227/527
2025-10-12 18:15:13.0004 - INFO - graphrag.logger.progress - extract graph progress: 228/527
2025-10-12 18:15:13.0006 - INFO - graphrag.logger.progress - extract graph progress: 229/527
2025-10-12 18:15:13.0008 - INFO - graphrag.logger.progress - extract graph progress: 230/527
2025-10-12 18:15:13.0011 - INFO - graphrag.logger.progress - extract graph progress: 231/527
2025-10-12 18:15:13.0013 - INFO - graphrag.logger.progress - extract graph progress: 232/527
2025-10-12 18:15:13.0015 - INFO - graphrag.logger.progress - extract graph progress: 233/527
2025-10-12 18:15:13.0017 - INFO - graphrag.logger.progress - extract graph progress: 234/527
2025-10-12 18:15:13.0019 - INFO - graphrag.logger.progress - extract graph progress: 235/527
2025-10-12 18:15:13.0021 - INFO - graphrag.logger.progress - extract graph progress: 236/527
2025-10-12 18:15:13.0024 - INFO - graphrag.logger.progress - extract graph progress: 237/527
2025-10-12 18:15:13.0026 - INFO - graphrag.logger.progress - extract graph progress: 238/527
2025-10-12 18:15:13.0028 - INFO - graphrag.logger.progress - extract graph progress: 239/527
2025-10-12 18:15:13.0030 - INFO - graphrag.logger.progress - extract graph progress: 240/527
2025-10-12 18:15:13.0032 - INFO - graphrag.logger.progress - extract graph progress: 241/527
2025-10-12 18:15:13.0034 - INFO - graphrag.logger.progress - extract graph progress: 242/527
2025-10-12 18:15:13.0036 - INFO - graphrag.logger.progress - extract graph progress: 243/527
2025-10-12 18:15:13.0038 - INFO - graphrag.logger.progress - extract graph progress: 244/527
2025-10-12 18:15:13.0041 - INFO - graphrag.logger.progress - extract graph progress: 245/527
2025-10-12 18:15:13.0043 - INFO - graphrag.logger.progress - extract graph progress: 246/527
2025-10-12 18:15:13.0045 - INFO - graphrag.logger.progress - extract graph progress: 247/527
2025-10-12 18:15:13.0047 - INFO - graphrag.logger.progress - extract graph progress: 248/527
2025-10-12 18:15:13.0050 - INFO - graphrag.logger.progress - extract graph progress: 249/527
2025-10-12 18:15:13.0052 - INFO - graphrag.logger.progress - extract graph progress: 250/527
2025-10-12 18:15:13.0054 - INFO - graphrag.logger.progress - extract graph progress: 251/527
2025-10-12 18:15:13.0056 - INFO - graphrag.logger.progress - extract graph progress: 252/527
2025-10-12 18:15:13.0059 - INFO - graphrag.logger.progress - extract graph progress: 253/527
2025-10-12 18:15:13.0060 - INFO - graphrag.logger.progress - extract graph progress: 254/527
2025-10-12 18:15:13.0062 - INFO - graphrag.logger.progress - extract graph progress: 255/527
2025-10-12 18:15:13.0065 - INFO - graphrag.logger.progress - extract graph progress: 256/527
2025-10-12 18:15:13.0067 - INFO - graphrag.logger.progress - extract graph progress: 257/527
2025-10-12 18:15:13.0069 - INFO - graphrag.logger.progress - extract graph progress: 258/527
2025-10-12 18:15:13.0071 - INFO - graphrag.logger.progress - extract graph progress: 259/527
2025-10-12 18:15:13.0073 - INFO - graphrag.logger.progress - extract graph progress: 260/527
2025-10-12 18:15:13.0075 - INFO - graphrag.logger.progress - extract graph progress: 261/527
2025-10-12 18:15:13.0078 - INFO - graphrag.logger.progress - extract graph progress: 262/527
2025-10-12 18:15:13.0080 - INFO - graphrag.logger.progress - extract graph progress: 263/527
2025-10-12 18:15:13.0082 - INFO - graphrag.logger.progress - extract graph progress: 264/527
2025-10-12 18:15:13.0084 - INFO - graphrag.logger.progress - extract graph progress: 265/527
2025-10-12 18:15:13.0086 - INFO - graphrag.logger.progress - extract graph progress: 266/527
2025-10-12 18:15:13.0088 - INFO - graphrag.logger.progress - extract graph progress: 267/527
2025-10-12 18:15:13.0090 - INFO - graphrag.logger.progress - extract graph progress: 268/527
2025-10-12 18:15:13.0093 - INFO - graphrag.logger.progress - extract graph progress: 269/527
2025-10-12 18:15:13.0095 - INFO - graphrag.logger.progress - extract graph progress: 270/527
2025-10-12 18:15:13.0097 - INFO - graphrag.logger.progress - extract graph progress: 271/527
2025-10-12 18:15:13.0099 - INFO - graphrag.logger.progress - extract graph progress: 272/527
2025-10-12 18:15:13.0101 - INFO - graphrag.logger.progress - extract graph progress: 273/527
2025-10-12 18:15:13.0104 - INFO - graphrag.logger.progress - extract graph progress: 274/527
2025-10-12 18:15:13.0106 - INFO - graphrag.logger.progress - extract graph progress: 275/527
2025-10-12 18:15:13.0108 - INFO - graphrag.logger.progress - extract graph progress: 276/527
2025-10-12 18:15:13.0110 - INFO - graphrag.logger.progress - extract graph progress: 277/527
2025-10-12 18:15:13.0112 - INFO - graphrag.logger.progress - extract graph progress: 278/527
2025-10-12 18:15:13.0114 - INFO - graphrag.logger.progress - extract graph progress: 279/527
2025-10-12 18:15:13.0117 - INFO - graphrag.logger.progress - extract graph progress: 280/527
2025-10-12 18:15:13.0119 - INFO - graphrag.logger.progress - extract graph progress: 281/527
2025-10-12 18:15:13.0121 - INFO - graphrag.logger.progress - extract graph progress: 282/527
2025-10-12 18:15:13.0123 - INFO - graphrag.logger.progress - extract graph progress: 283/527
2025-10-12 18:15:13.0125 - INFO - graphrag.logger.progress - extract graph progress: 284/527
2025-10-12 18:15:13.0128 - INFO - graphrag.logger.progress - extract graph progress: 285/527
2025-10-12 18:15:13.0130 - INFO - graphrag.logger.progress - extract graph progress: 286/527
2025-10-12 18:15:13.0132 - INFO - graphrag.logger.progress - extract graph progress: 287/527
2025-10-12 18:15:13.0134 - INFO - graphrag.logger.progress - extract graph progress: 288/527
2025-10-12 18:15:13.0137 - INFO - graphrag.logger.progress - extract graph progress: 289/527
2025-10-12 18:15:13.0139 - INFO - graphrag.logger.progress - extract graph progress: 290/527
2025-10-12 18:15:13.0141 - INFO - graphrag.logger.progress - extract graph progress: 291/527
2025-10-12 18:15:13.0143 - INFO - graphrag.logger.progress - extract graph progress: 292/527
2025-10-12 18:15:13.0145 - INFO - graphrag.logger.progress - extract graph progress: 293/527
2025-10-12 18:15:13.0147 - INFO - graphrag.logger.progress - extract graph progress: 294/527
2025-10-12 18:15:13.0150 - INFO - graphrag.logger.progress - extract graph progress: 295/527
2025-10-12 18:15:13.0152 - INFO - graphrag.logger.progress - extract graph progress: 296/527
2025-10-12 18:15:13.0154 - INFO - graphrag.logger.progress - extract graph progress: 297/527
2025-10-12 18:15:13.0156 - INFO - graphrag.logger.progress - extract graph progress: 298/527
2025-10-12 18:15:13.0158 - INFO - graphrag.logger.progress - extract graph progress: 299/527
2025-10-12 18:15:13.0160 - INFO - graphrag.logger.progress - extract graph progress: 300/527
2025-10-12 18:15:13.0163 - INFO - graphrag.logger.progress - extract graph progress: 301/527
2025-10-12 18:15:13.0165 - INFO - graphrag.logger.progress - extract graph progress: 302/527
2025-10-12 18:15:13.0167 - INFO - graphrag.logger.progress - extract graph progress: 303/527
2025-10-12 18:15:13.0169 - INFO - graphrag.logger.progress - extract graph progress: 304/527
2025-10-12 18:15:13.0172 - INFO - graphrag.logger.progress - extract graph progress: 305/527
2025-10-12 18:15:13.0174 - INFO - graphrag.logger.progress - extract graph progress: 306/527
2025-10-12 18:15:13.0176 - INFO - graphrag.logger.progress - extract graph progress: 307/527
2025-10-12 18:15:13.0178 - INFO - graphrag.logger.progress - extract graph progress: 308/527
2025-10-12 18:15:13.0180 - INFO - graphrag.logger.progress - extract graph progress: 309/527
2025-10-12 18:15:13.0183 - INFO - graphrag.logger.progress - extract graph progress: 310/527
2025-10-12 18:15:13.0185 - INFO - graphrag.logger.progress - extract graph progress: 311/527
2025-10-12 18:15:13.0187 - INFO - graphrag.logger.progress - extract graph progress: 312/527
2025-10-12 18:15:13.0189 - INFO - graphrag.logger.progress - extract graph progress: 313/527
2025-10-12 18:15:13.0192 - INFO - graphrag.logger.progress - extract graph progress: 314/527
2025-10-12 18:15:13.0194 - INFO - graphrag.logger.progress - extract graph progress: 315/527
2025-10-12 18:15:13.0196 - INFO - graphrag.logger.progress - extract graph progress: 316/527
2025-10-12 18:15:13.0198 - INFO - graphrag.logger.progress - extract graph progress: 317/527
2025-10-12 18:15:13.0200 - INFO - graphrag.logger.progress - extract graph progress: 318/527
2025-10-12 18:15:13.0202 - INFO - graphrag.logger.progress - extract graph progress: 319/527
2025-10-12 18:15:13.0204 - INFO - graphrag.logger.progress - extract graph progress: 320/527
2025-10-12 18:15:13.0207 - INFO - graphrag.logger.progress - extract graph progress: 321/527
2025-10-12 18:15:13.0209 - INFO - graphrag.logger.progress - extract graph progress: 322/527
2025-10-12 18:15:13.0211 - INFO - graphrag.logger.progress - extract graph progress: 323/527
2025-10-12 18:15:13.0213 - INFO - graphrag.logger.progress - extract graph progress: 324/527
2025-10-12 18:15:13.0215 - INFO - graphrag.logger.progress - extract graph progress: 325/527
2025-10-12 18:15:13.0219 - INFO - graphrag.logger.progress - extract graph progress: 326/527
2025-10-12 18:15:13.0221 - INFO - graphrag.logger.progress - extract graph progress: 327/527
2025-10-12 18:15:13.0223 - INFO - graphrag.logger.progress - extract graph progress: 328/527
2025-10-12 18:15:13.0225 - INFO - graphrag.logger.progress - extract graph progress: 329/527
2025-10-12 18:15:13.0227 - INFO - graphrag.logger.progress - extract graph progress: 330/527
2025-10-12 18:15:13.0229 - INFO - graphrag.logger.progress - extract graph progress: 331/527
2025-10-12 18:15:13.0232 - INFO - graphrag.logger.progress - extract graph progress: 332/527
2025-10-12 18:15:13.0234 - INFO - graphrag.logger.progress - extract graph progress: 333/527
2025-10-12 18:15:13.0236 - INFO - graphrag.logger.progress - extract graph progress: 334/527
2025-10-12 18:15:13.0239 - INFO - graphrag.logger.progress - extract graph progress: 335/527
2025-10-12 18:15:13.0241 - INFO - graphrag.logger.progress - extract graph progress: 336/527
2025-10-12 18:15:13.0243 - INFO - graphrag.logger.progress - extract graph progress: 337/527
2025-10-12 18:15:13.0245 - INFO - graphrag.logger.progress - extract graph progress: 338/527
2025-10-12 18:15:13.0247 - INFO - graphrag.logger.progress - extract graph progress: 339/527
2025-10-12 18:15:13.0250 - INFO - graphrag.logger.progress - extract graph progress: 340/527
2025-10-12 18:15:35.0548 - INFO - graphrag.logger.progress - extract graph progress: 341/527
2025-10-12 18:15:35.0550 - INFO - graphrag.logger.progress - extract graph progress: 342/527
2025-10-12 18:15:35.0553 - INFO - graphrag.logger.progress - extract graph progress: 343/527
2025-10-12 18:15:35.0555 - INFO - graphrag.logger.progress - extract graph progress: 344/527
2025-10-12 18:15:35.0557 - INFO - graphrag.logger.progress - extract graph progress: 345/527
2025-10-12 18:15:35.0559 - INFO - graphrag.logger.progress - extract graph progress: 346/527
2025-10-12 18:15:35.0561 - INFO - graphrag.logger.progress - extract graph progress: 347/527
2025-10-12 18:15:35.0563 - INFO - graphrag.logger.progress - extract graph progress: 348/527
2025-10-12 18:15:35.0565 - INFO - graphrag.logger.progress - extract graph progress: 349/527
2025-10-12 18:15:35.0567 - INFO - graphrag.logger.progress - extract graph progress: 350/527
2025-10-12 18:15:35.0570 - INFO - graphrag.logger.progress - extract graph progress: 351/527
2025-10-12 18:15:35.0572 - INFO - graphrag.logger.progress - extract graph progress: 352/527
2025-10-12 18:15:35.0574 - INFO - graphrag.logger.progress - extract graph progress: 353/527
2025-10-12 18:15:35.0576 - INFO - graphrag.logger.progress - extract graph progress: 354/527
2025-10-12 18:15:35.0578 - INFO - graphrag.logger.progress - extract graph progress: 355/527
2025-10-12 18:15:35.0580 - INFO - graphrag.logger.progress - extract graph progress: 356/527
2025-10-12 18:15:35.0582 - INFO - graphrag.logger.progress - extract graph progress: 357/527
2025-10-12 18:15:35.0585 - INFO - graphrag.logger.progress - extract graph progress: 358/527
2025-10-12 18:15:35.0587 - INFO - graphrag.logger.progress - extract graph progress: 359/527
2025-10-12 18:15:35.0590 - INFO - graphrag.logger.progress - extract graph progress: 360/527
2025-10-12 18:15:35.0592 - INFO - graphrag.logger.progress - extract graph progress: 361/527
2025-10-12 18:15:35.0594 - INFO - graphrag.logger.progress - extract graph progress: 362/527
2025-10-12 18:15:35.0596 - INFO - graphrag.logger.progress - extract graph progress: 363/527
2025-10-12 18:15:35.0598 - INFO - graphrag.logger.progress - extract graph progress: 364/527
2025-10-12 18:15:35.0601 - INFO - graphrag.logger.progress - extract graph progress: 365/527
2025-10-12 18:15:35.0603 - INFO - graphrag.logger.progress - extract graph progress: 366/527
2025-10-12 18:15:35.0605 - INFO - graphrag.logger.progress - extract graph progress: 367/527
2025-10-12 18:15:35.0607 - INFO - graphrag.logger.progress - extract graph progress: 368/527
2025-10-12 18:15:35.0609 - INFO - graphrag.logger.progress - extract graph progress: 369/527
2025-10-12 18:15:35.0611 - INFO - graphrag.logger.progress - extract graph progress: 370/527
2025-10-12 18:15:35.0613 - INFO - graphrag.logger.progress - extract graph progress: 371/527
2025-10-12 18:15:35.0616 - INFO - graphrag.logger.progress - extract graph progress: 372/527
2025-10-12 18:15:35.0618 - INFO - graphrag.logger.progress - extract graph progress: 373/527
2025-10-12 18:15:35.0621 - INFO - graphrag.logger.progress - extract graph progress: 374/527
2025-10-12 18:15:35.0623 - INFO - graphrag.logger.progress - extract graph progress: 375/527
2025-10-12 18:15:35.0625 - INFO - graphrag.logger.progress - extract graph progress: 376/527
2025-10-12 18:15:35.0628 - INFO - graphrag.logger.progress - extract graph progress: 377/527
2025-10-12 18:15:35.0630 - INFO - graphrag.logger.progress - extract graph progress: 378/527
2025-10-12 18:15:35.0632 - INFO - graphrag.logger.progress - extract graph progress: 379/527
2025-10-12 18:15:35.0634 - INFO - graphrag.logger.progress - extract graph progress: 380/527
2025-10-12 18:15:35.0636 - INFO - graphrag.logger.progress - extract graph progress: 381/527
2025-10-12 18:15:35.0639 - INFO - graphrag.logger.progress - extract graph progress: 382/527
2025-10-12 18:15:35.0641 - INFO - graphrag.logger.progress - extract graph progress: 383/527
2025-10-12 18:15:35.0643 - INFO - graphrag.logger.progress - extract graph progress: 384/527
2025-10-12 18:16:06.0307 - INFO - graphrag.logger.progress - extract graph progress: 385/527
2025-10-12 18:16:06.0312 - INFO - graphrag.logger.progress - extract graph progress: 386/527
2025-10-12 18:16:06.0315 - INFO - graphrag.logger.progress - extract graph progress: 387/527
2025-10-12 18:16:06.0318 - INFO - graphrag.logger.progress - extract graph progress: 388/527
2025-10-12 18:16:06.0321 - INFO - graphrag.logger.progress - extract graph progress: 389/527
2025-10-12 18:16:06.0325 - INFO - graphrag.logger.progress - extract graph progress: 390/527
2025-10-12 18:16:24.0449 - INFO - graphrag.logger.progress - extract graph progress: 391/527
2025-10-12 18:16:24.0454 - INFO - graphrag.logger.progress - extract graph progress: 392/527
2025-10-12 18:16:24.0458 - INFO - graphrag.logger.progress - extract graph progress: 393/527
2025-10-12 18:16:24.0463 - INFO - graphrag.logger.progress - extract graph progress: 394/527
2025-10-12 18:16:24.0467 - INFO - graphrag.logger.progress - extract graph progress: 395/527
2025-10-12 18:16:24.0471 - INFO - graphrag.logger.progress - extract graph progress: 396/527
2025-10-12 18:16:24.0475 - INFO - graphrag.logger.progress - extract graph progress: 397/527
2025-10-12 18:16:24.0479 - INFO - graphrag.logger.progress - extract graph progress: 398/527
2025-10-12 18:16:24.0482 - INFO - graphrag.logger.progress - extract graph progress: 399/527
2025-10-12 18:16:24.0486 - INFO - graphrag.logger.progress - extract graph progress: 400/527
2025-10-12 18:16:24.0490 - INFO - graphrag.logger.progress - extract graph progress: 401/527
2025-10-12 18:16:24.0494 - INFO - graphrag.logger.progress - extract graph progress: 402/527
2025-10-12 18:16:24.0497 - INFO - graphrag.logger.progress - extract graph progress: 403/527
2025-10-12 18:16:24.0501 - INFO - graphrag.logger.progress - extract graph progress: 404/527
2025-10-12 18:16:24.0504 - INFO - graphrag.logger.progress - extract graph progress: 405/527
2025-10-12 18:16:24.0507 - INFO - graphrag.logger.progress - extract graph progress: 406/527
2025-10-12 18:16:24.0513 - INFO - graphrag.logger.progress - extract graph progress: 407/527
2025-10-12 18:16:24.0515 - INFO - graphrag.logger.progress - extract graph progress: 408/527
2025-10-12 18:16:24.0518 - INFO - graphrag.logger.progress - extract graph progress: 409/527
2025-10-12 18:16:24.0521 - INFO - graphrag.logger.progress - extract graph progress: 410/527
2025-10-12 18:16:24.0524 - INFO - graphrag.logger.progress - extract graph progress: 411/527
2025-10-12 18:16:24.0527 - INFO - graphrag.logger.progress - extract graph progress: 412/527
2025-10-12 18:16:24.0531 - INFO - graphrag.logger.progress - extract graph progress: 413/527
2025-10-12 18:16:24.0535 - INFO - graphrag.logger.progress - extract graph progress: 414/527
2025-10-12 18:16:24.0538 - INFO - graphrag.logger.progress - extract graph progress: 415/527
2025-10-12 18:16:24.0540 - INFO - graphrag.logger.progress - extract graph progress: 416/527
2025-10-12 18:16:24.0545 - INFO - graphrag.logger.progress - extract graph progress: 417/527
2025-10-12 18:16:24.0547 - INFO - graphrag.logger.progress - extract graph progress: 418/527
2025-10-12 18:16:24.0550 - INFO - graphrag.logger.progress - extract graph progress: 419/527
2025-10-12 18:16:24.0555 - INFO - graphrag.logger.progress - extract graph progress: 420/527
2025-10-12 18:16:24.0559 - INFO - graphrag.logger.progress - extract graph progress: 421/527
2025-10-12 18:16:24.0563 - INFO - graphrag.logger.progress - extract graph progress: 422/527
2025-10-12 18:16:24.0567 - INFO - graphrag.logger.progress - extract graph progress: 423/527
2025-10-12 18:16:24.0570 - INFO - graphrag.logger.progress - extract graph progress: 424/527
2025-10-12 18:16:24.0573 - INFO - graphrag.logger.progress - extract graph progress: 425/527
2025-10-12 18:16:24.0577 - INFO - graphrag.logger.progress - extract graph progress: 426/527
2025-10-12 18:16:24.0582 - INFO - graphrag.logger.progress - extract graph progress: 427/527
2025-10-12 18:16:24.0586 - INFO - graphrag.logger.progress - extract graph progress: 428/527
2025-10-12 18:16:24.0589 - INFO - graphrag.logger.progress - extract graph progress: 429/527
2025-10-12 18:16:24.0593 - INFO - graphrag.logger.progress - extract graph progress: 430/527
2025-10-12 18:16:24.0596 - INFO - graphrag.logger.progress - extract graph progress: 431/527
2025-10-12 18:16:24.0599 - INFO - graphrag.logger.progress - extract graph progress: 432/527
2025-10-12 18:16:24.0603 - INFO - graphrag.logger.progress - extract graph progress: 433/527
2025-10-12 18:16:55.0555 - INFO - graphrag.logger.progress - extract graph progress: 434/527
2025-10-12 18:16:55.0560 - INFO - graphrag.logger.progress - extract graph progress: 435/527
2025-10-12 18:16:55.0564 - INFO - graphrag.logger.progress - extract graph progress: 436/527
2025-10-12 18:16:55.0568 - INFO - graphrag.logger.progress - extract graph progress: 437/527
2025-10-12 18:16:55.0573 - INFO - graphrag.logger.progress - extract graph progress: 438/527
2025-10-12 18:16:55.0576 - INFO - graphrag.logger.progress - extract graph progress: 439/527
2025-10-12 18:16:55.0579 - INFO - graphrag.logger.progress - extract graph progress: 440/527
2025-10-12 18:16:55.0581 - INFO - graphrag.logger.progress - extract graph progress: 441/527
2025-10-12 18:16:55.0583 - INFO - graphrag.logger.progress - extract graph progress: 442/527
2025-10-12 18:16:55.0585 - INFO - graphrag.logger.progress - extract graph progress: 443/527
2025-10-12 18:16:55.0587 - INFO - graphrag.logger.progress - extract graph progress: 444/527
2025-10-12 18:16:55.0589 - INFO - graphrag.logger.progress - extract graph progress: 445/527
2025-10-12 18:16:55.0592 - INFO - graphrag.logger.progress - extract graph progress: 446/527
2025-10-12 18:16:55.0594 - INFO - graphrag.logger.progress - extract graph progress: 447/527
2025-10-12 18:16:55.0596 - INFO - graphrag.logger.progress - extract graph progress: 448/527
2025-10-12 18:16:55.0598 - INFO - graphrag.logger.progress - extract graph progress: 449/527
2025-10-12 18:16:55.0600 - INFO - graphrag.logger.progress - extract graph progress: 450/527
2025-10-12 18:16:55.0603 - INFO - graphrag.logger.progress - extract graph progress: 451/527
2025-10-12 18:16:55.0605 - INFO - graphrag.logger.progress - extract graph progress: 452/527
2025-10-12 18:16:55.0607 - INFO - graphrag.logger.progress - extract graph progress: 453/527
2025-10-12 18:16:55.0609 - INFO - graphrag.logger.progress - extract graph progress: 454/527
2025-10-12 18:16:55.0611 - INFO - graphrag.logger.progress - extract graph progress: 455/527
2025-10-12 18:16:55.0614 - INFO - graphrag.logger.progress - extract graph progress: 456/527
2025-10-12 18:16:55.0616 - INFO - graphrag.logger.progress - extract graph progress: 457/527
2025-10-12 18:16:55.0618 - INFO - graphrag.logger.progress - extract graph progress: 458/527
2025-10-12 18:16:55.0620 - INFO - graphrag.logger.progress - extract graph progress: 459/527
2025-10-12 18:16:55.0623 - INFO - graphrag.logger.progress - extract graph progress: 460/527
2025-10-12 18:16:55.0625 - INFO - graphrag.logger.progress - extract graph progress: 461/527
2025-10-12 18:16:55.0627 - INFO - graphrag.logger.progress - extract graph progress: 462/527
2025-10-12 18:16:55.0629 - INFO - graphrag.logger.progress - extract graph progress: 463/527
2025-10-12 18:16:55.0631 - INFO - graphrag.logger.progress - extract graph progress: 464/527
2025-10-12 18:16:55.0634 - INFO - graphrag.logger.progress - extract graph progress: 465/527
2025-10-12 18:16:55.0636 - INFO - graphrag.logger.progress - extract graph progress: 466/527
2025-10-12 18:16:55.0638 - INFO - graphrag.logger.progress - extract graph progress: 467/527
2025-10-12 18:16:55.0640 - INFO - graphrag.logger.progress - extract graph progress: 468/527
2025-10-12 18:16:55.0643 - INFO - graphrag.logger.progress - extract graph progress: 469/527
2025-10-12 18:16:55.0645 - INFO - graphrag.logger.progress - extract graph progress: 470/527
2025-10-12 18:16:55.0647 - INFO - graphrag.logger.progress - extract graph progress: 471/527
2025-10-12 18:16:55.0649 - INFO - graphrag.logger.progress - extract graph progress: 472/527
2025-10-12 18:16:55.0651 - INFO - graphrag.logger.progress - extract graph progress: 473/527
2025-10-12 18:16:55.0653 - INFO - graphrag.logger.progress - extract graph progress: 474/527
2025-10-12 18:16:55.0656 - INFO - graphrag.logger.progress - extract graph progress: 475/527
2025-10-12 18:16:55.0658 - INFO - graphrag.logger.progress - extract graph progress: 476/527
2025-10-12 18:16:55.0660 - INFO - graphrag.logger.progress - extract graph progress: 477/527
2025-10-12 18:16:55.0662 - INFO - graphrag.logger.progress - extract graph progress: 478/527
2025-10-12 18:16:55.0665 - INFO - graphrag.logger.progress - extract graph progress: 479/527
2025-10-12 18:16:55.0667 - INFO - graphrag.logger.progress - extract graph progress: 480/527
2025-10-12 18:16:55.0669 - INFO - graphrag.logger.progress - extract graph progress: 481/527
2025-10-12 18:16:55.0671 - INFO - graphrag.logger.progress - extract graph progress: 482/527
2025-10-12 18:16:55.0673 - INFO - graphrag.logger.progress - extract graph progress: 483/527
2025-10-12 18:16:55.0676 - INFO - graphrag.logger.progress - extract graph progress: 484/527
2025-10-12 18:16:55.0678 - INFO - graphrag.logger.progress - extract graph progress: 485/527
2025-10-12 18:16:55.0680 - INFO - graphrag.logger.progress - extract graph progress: 486/527
2025-10-12 18:16:55.0682 - INFO - graphrag.logger.progress - extract graph progress: 487/527
2025-10-12 18:16:55.0685 - INFO - graphrag.logger.progress - extract graph progress: 488/527
2025-10-12 18:16:55.0687 - INFO - graphrag.logger.progress - extract graph progress: 489/527
2025-10-12 18:16:55.0689 - INFO - graphrag.logger.progress - extract graph progress: 490/527
2025-10-12 18:16:55.0691 - INFO - graphrag.logger.progress - extract graph progress: 491/527
2025-10-12 18:16:55.0693 - INFO - graphrag.logger.progress - extract graph progress: 492/527
2025-10-12 18:16:55.0695 - INFO - graphrag.logger.progress - extract graph progress: 493/527
2025-10-12 18:16:55.0698 - INFO - graphrag.logger.progress - extract graph progress: 494/527
2025-10-12 18:16:55.0700 - INFO - graphrag.logger.progress - extract graph progress: 495/527
2025-10-12 18:16:55.0702 - INFO - graphrag.logger.progress - extract graph progress: 496/527
2025-10-12 18:16:55.0704 - INFO - graphrag.logger.progress - extract graph progress: 497/527
2025-10-12 18:16:55.0706 - INFO - graphrag.logger.progress - extract graph progress: 498/527
2025-10-12 18:16:55.0709 - INFO - graphrag.logger.progress - extract graph progress: 499/527
2025-10-12 18:16:55.0711 - INFO - graphrag.logger.progress - extract graph progress: 500/527
2025-10-12 18:16:55.0713 - INFO - graphrag.logger.progress - extract graph progress: 501/527
2025-10-12 18:16:55.0715 - INFO - graphrag.logger.progress - extract graph progress: 502/527
2025-10-12 18:16:55.0717 - INFO - graphrag.logger.progress - extract graph progress: 503/527
2025-10-12 18:16:55.0720 - INFO - graphrag.logger.progress - extract graph progress: 504/527
2025-10-12 18:17:01.0199 - INFO - graphrag.logger.progress - extract graph progress: 505/527
2025-10-12 18:17:01.0203 - INFO - graphrag.logger.progress - extract graph progress: 506/527
2025-10-12 18:17:01.0208 - INFO - graphrag.logger.progress - extract graph progress: 507/527
2025-10-12 18:17:01.0210 - INFO - graphrag.logger.progress - extract graph progress: 508/527
2025-10-12 18:17:01.0213 - INFO - graphrag.logger.progress - extract graph progress: 509/527
2025-10-12 18:17:01.0217 - INFO - graphrag.logger.progress - extract graph progress: 510/527
2025-10-12 18:17:01.0220 - INFO - graphrag.logger.progress - extract graph progress: 511/527
2025-10-12 18:17:01.0223 - INFO - graphrag.logger.progress - extract graph progress: 512/527
2025-10-12 18:17:01.0228 - INFO - graphrag.logger.progress - extract graph progress: 513/527
2025-10-12 18:17:01.0231 - INFO - graphrag.logger.progress - extract graph progress: 514/527
2025-10-12 18:17:01.0234 - INFO - graphrag.logger.progress - extract graph progress: 515/527
2025-10-12 18:17:01.0238 - INFO - graphrag.logger.progress - extract graph progress: 516/527
2025-10-12 18:17:01.0241 - INFO - graphrag.logger.progress - extract graph progress: 517/527
2025-10-12 18:17:01.0244 - INFO - graphrag.logger.progress - extract graph progress: 518/527
2025-10-12 18:17:01.0248 - INFO - graphrag.logger.progress - extract graph progress: 519/527
2025-10-12 18:17:01.0251 - INFO - graphrag.logger.progress - extract graph progress: 520/527
2025-10-12 18:17:01.0254 - INFO - graphrag.logger.progress - extract graph progress: 521/527
2025-10-12 18:17:01.0258 - INFO - graphrag.logger.progress - extract graph progress: 522/527
2025-10-12 18:17:01.0262 - INFO - graphrag.logger.progress - extract graph progress: 523/527
2025-10-12 18:17:01.0267 - INFO - graphrag.logger.progress - extract graph progress: 524/527
2025-10-12 18:17:01.0270 - INFO - graphrag.logger.progress - extract graph progress: 525/527
2025-10-12 18:17:01.0274 - INFO - graphrag.logger.progress - extract graph progress: 526/527
2025-10-12 18:17:01.0278 - INFO - graphrag.logger.progress - extract graph progress: 527/527
2025-10-12 18:17:01.0376 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/summarize_descriptions
2025-10-12 18:17:01.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/198
2025-10-12 18:17:01.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/198
2025-10-12 18:17:01.0376 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/198
2025-10-12 18:17:01.0377 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/198
2025-10-12 18:17:02.0339 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/198
2025-10-12 18:17:02.0340 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/198
2025-10-12 18:17:02.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/198
2025-10-12 18:17:02.0966 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/198
2025-10-12 18:17:03.0890 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/198
2025-10-12 18:17:04.0535 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/198
2025-10-12 18:17:06.0762 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/198
2025-10-12 18:17:07.0539 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/198
2025-10-12 18:17:08.0293 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/198
2025-10-12 18:17:09.0238 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/198
2025-10-12 18:17:09.0238 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/198
2025-10-12 18:17:09.0239 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/198
2025-10-12 18:17:09.0716 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/198
2025-10-12 18:17:09.0717 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/198
2025-10-12 18:17:10.0259 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/198
2025-10-12 18:17:10.0260 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/198
2025-10-12 18:17:10.0261 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 123/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 124/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 125/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 126/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 127/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 128/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 129/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 130/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 131/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 132/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 133/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 134/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 135/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 136/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 137/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 138/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 139/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 140/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 141/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 142/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 143/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 144/198
2025-10-12 18:17:10.0262 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 145/198
2025-10-12 18:17:10.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 146/198
2025-10-12 18:17:11.0646 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 147/198
2025-10-12 18:17:12.0534 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 148/198
2025-10-12 18:17:12.0534 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 149/198
2025-10-12 18:17:12.0534 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 150/198
2025-10-12 18:17:13.0275 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 151/198
2025-10-12 18:17:14.0785 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 152/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 153/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 154/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 155/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 156/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 157/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 158/198
2025-10-12 18:17:15.0543 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 159/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 160/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 161/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 162/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 163/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 164/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 165/198
2025-10-12 18:17:15.0544 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 166/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 167/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 168/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 169/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 170/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 171/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 172/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 173/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 174/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 175/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 176/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 177/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 178/198
2025-10-12 18:17:16.0475 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 179/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 180/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 181/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 182/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 183/198
2025-10-12 18:17:16.0938 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 184/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 185/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 186/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 187/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 188/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 189/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 190/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 191/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 192/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 193/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 194/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 195/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 196/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 197/198
2025-10-12 18:17:16.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 198/198
2025-10-12 18:17:16.0950 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2025-10-12 18:17:16.0950 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2025-10-12 18:17:16.0958 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2025-10-12 18:17:16.0958 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:16.0964 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:16.0992 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2025-10-12 18:17:16.0992 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2025-10-12 18:17:17.0000 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2025-10-12 18:17:17.0000 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2025-10-12 18:17:17.0000 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2025-10-12 18:17:17.0000 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2025-10-12 18:17:17.0000 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:17.0005 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:17.0038 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2025-10-12 18:17:17.0038 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2025-10-12 18:17:17.0044 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2025-10-12 18:17:17.0044 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:17:17.0048 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:17.0052 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:17.0090 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2025-10-12 18:17:17.0090 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2025-10-12 18:17:17.0096 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2025-10-12 18:17:17.0097 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2025-10-12 18:17:17.0101 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:17:17.0104 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2025-10-12 18:17:17.0117 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 23
2025-10-12 18:17:17.0148 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 31
2025-10-12 18:17:17.0190 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/community_reporting
2025-10-12 18:17:22.0814 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/4
2025-10-12 18:17:28.0647 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/4
2025-10-12 18:17:34.0335 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 3/4
2025-10-12 18:17:38.0880 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 4/4
2025-10-12 18:17:44.0902 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/4
2025-10-12 18:17:51.0405 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/4
2025-10-12 18:17:57.0506 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/4
2025-10-12 18:18:02.0924 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/4
2025-10-12 18:18:02.0932 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2025-10-12 18:18:02.0932 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2025-10-12 18:18:02.0940 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2025-10-12 18:18:02.0940 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2025-10-12 18:18:02.0941 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:18:02.0950 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2025-10-12 18:18:02.0954 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2025-10-12 18:18:02.0960 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2025-10-12 18:18:02.0960 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2025-10-12 18:18:03.0003 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 18:18:03.0004 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/text_embedding
2025-10-12 18:18:03.0008 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 102 inputs via 102 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:18:17.0080 - INFO - graphrag.logger.progress - generate embeddings progress: 1/7
2025-10-12 18:18:35.0515 - INFO - graphrag.logger.progress - generate embeddings progress: 2/7
2025-10-12 18:18:53.0001 - INFO - graphrag.logger.progress - generate embeddings progress: 3/7
2025-10-12 18:19:05.0231 - INFO - graphrag.logger.progress - generate embeddings progress: 4/7
2025-10-12 18:19:21.0092 - INFO - graphrag.logger.progress - generate embeddings progress: 5/7
2025-10-12 18:19:35.0962 - INFO - graphrag.logger.progress - generate embeddings progress: 6/7
2025-10-12 18:19:40.0750 - INFO - graphrag.logger.progress - generate embeddings progress: 7/7
2025-10-12 18:19:40.0880 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2025-10-12 18:19:40.0884 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2025-10-12 18:19:40.0886 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 8 inputs via 8 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:19:41.0020 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2025-10-12 18:19:41.0082 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2025-10-12 18:19:41.0085 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/2 of size 500 to vector store
2025-10-12 18:19:41.0088 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 500 inputs via 500 snippets using 32 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:19:57.0588 - INFO - graphrag.logger.progress - generate embeddings progress: 1/32
2025-10-12 18:20:16.0986 - INFO - graphrag.logger.progress - generate embeddings progress: 2/32
2025-10-12 18:20:16.0989 - INFO - graphrag.logger.progress - generate embeddings progress: 3/32
2025-10-12 18:20:36.0978 - INFO - graphrag.logger.progress - generate embeddings progress: 4/32
2025-10-12 18:20:36.0984 - INFO - graphrag.logger.progress - generate embeddings progress: 5/32
2025-10-12 18:20:57.0063 - INFO - graphrag.logger.progress - generate embeddings progress: 6/32
2025-10-12 18:21:15.0820 - INFO - graphrag.logger.progress - generate embeddings progress: 7/32
2025-10-12 18:21:35.0454 - INFO - graphrag.logger.progress - generate embeddings progress: 8/32
2025-10-12 18:21:35.0456 - INFO - graphrag.logger.progress - generate embeddings progress: 9/32
2025-10-12 18:21:55.0066 - INFO - graphrag.logger.progress - generate embeddings progress: 10/32
2025-10-12 18:22:14.0397 - INFO - graphrag.logger.progress - generate embeddings progress: 11/32
2025-10-12 18:22:33.0341 - INFO - graphrag.logger.progress - generate embeddings progress: 12/32
2025-10-12 18:22:53.0800 - INFO - graphrag.logger.progress - generate embeddings progress: 13/32
2025-10-12 18:22:53.0803 - INFO - graphrag.logger.progress - generate embeddings progress: 14/32
2025-10-12 18:23:11.0649 - INFO - graphrag.logger.progress - generate embeddings progress: 15/32
2025-10-12 18:23:28.0338 - INFO - graphrag.logger.progress - generate embeddings progress: 16/32
2025-10-12 18:23:28.0340 - INFO - graphrag.logger.progress - generate embeddings progress: 17/32
2025-10-12 18:23:28.0342 - INFO - graphrag.logger.progress - generate embeddings progress: 18/32
2025-10-12 18:23:48.0297 - INFO - graphrag.logger.progress - generate embeddings progress: 19/32
2025-10-12 18:24:06.0163 - INFO - graphrag.logger.progress - generate embeddings progress: 20/32
2025-10-12 18:24:26.0176 - INFO - graphrag.logger.progress - generate embeddings progress: 21/32
2025-10-12 18:24:45.0885 - INFO - graphrag.logger.progress - generate embeddings progress: 22/32
2025-10-12 18:24:45.0888 - INFO - graphrag.logger.progress - generate embeddings progress: 23/32
2025-10-12 18:25:04.0494 - INFO - graphrag.logger.progress - generate embeddings progress: 24/32
2025-10-12 18:25:25.0000 - INFO - graphrag.logger.progress - generate embeddings progress: 25/32
2025-10-12 18:25:45.0343 - INFO - graphrag.logger.progress - generate embeddings progress: 26/32
2025-10-12 18:26:07.0138 - INFO - graphrag.logger.progress - generate embeddings progress: 27/32
2025-10-12 18:26:25.0301 - INFO - graphrag.logger.progress - generate embeddings progress: 28/32
2025-10-12 18:26:42.0616 - INFO - graphrag.logger.progress - generate embeddings progress: 29/32
2025-10-12 18:26:59.0727 - INFO - graphrag.logger.progress - generate embeddings progress: 30/32
2025-10-12 18:27:18.0115 - INFO - graphrag.logger.progress - generate embeddings progress: 31/32
2025-10-12 18:27:18.0118 - INFO - graphrag.logger.progress - generate embeddings progress: 32/32
2025-10-12 18:27:18.0209 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 2/2 of size 500 to vector store
2025-10-12 18:27:18.0209 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 27 inputs via 27 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
2025-10-12 18:27:35.0472 - INFO - graphrag.logger.progress - generate embeddings progress: 1/2
2025-10-12 18:27:48.0884 - INFO - graphrag.logger.progress - generate embeddings progress: 2/2
2025-10-12 18:27:48.0903 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2025-10-12 18:27:48.0903 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2025-10-12 18:27:48.0918 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2025-10-12 18:27:48.0923 - INFO - graphrag.cli.index - All workflows completed successfully.
2025-10-12 18:58:17.0948 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-12 18:58:19.0996 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-12 18:58:19.0996 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-12 18:58:19.0997 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "llama3:70b",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/projects/dsci435/fmcsafetyevents_fa25/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "EQUIPMENT",
            "LOCATION",
            "ORGANIZATION",
            "DATE"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-12 18:58:19.0999 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-12 18:58:19.0999 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-12 18:58:19.0999 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:58:19.0999 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/output
2025-10-12 18:58:20.0000 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG
2025-10-12 18:58:20.0000 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache
2025-10-12 18:58:20.0003 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-12 18:58:20.0003 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-12 18:58:20.0006 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-12 18:58:20.0006 - INFO - graphrag.index.input.factory - loading input from root_dir=/projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:58:20.0006 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-12 18:58:20.0006 - INFO - graphrag.index.input.csv - Loading csv files from /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input
2025-10-12 18:58:20.0006 - INFO - graphrag.storage.file_pipeline_storage - search /projects/dsci435/fmcsafetyevents_fa25/graphRAG/input for files matching .*\.csv$
2025-10-12 18:58:20.0140 - INFO - graphrag.index.input.util - Found 1 InputFileType.csv files, loading 1
2025-10-12 18:58:20.0140 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 718
2025-10-12 18:58:20.0140 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 718
2025-10-12 18:58:20.0193 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-12 18:58:20.0223 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-12 18:58:20.0223 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:58:20.0277 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 527 documents
2025-10-12 18:58:20.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/527
2025-10-12 18:58:20.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/527
2025-10-12 18:58:20.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/527
2025-10-12 18:58:20.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/527
2025-10-12 18:58:20.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/527
2025-10-12 18:58:20.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/527
2025-10-12 18:58:20.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/527
2025-10-12 18:58:20.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/527
2025-10-12 18:58:20.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/527
2025-10-12 18:58:20.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/527
2025-10-12 18:58:20.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/527
2025-10-12 18:58:20.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/527
2025-10-12 18:58:20.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/527
2025-10-12 18:58:20.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/527
2025-10-12 18:58:20.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/527
2025-10-12 18:58:20.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/527
2025-10-12 18:58:20.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/527
2025-10-12 18:58:20.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/527
2025-10-12 18:58:20.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/527
2025-10-12 18:58:20.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/527
2025-10-12 18:58:20.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/527
2025-10-12 18:58:20.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/527
2025-10-12 18:58:20.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/527
2025-10-12 18:58:20.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/527
2025-10-12 18:58:20.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/527
2025-10-12 18:58:20.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/527
2025-10-12 18:58:20.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/527
2025-10-12 18:58:20.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/527
2025-10-12 18:58:20.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/527
2025-10-12 18:58:20.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/527
2025-10-12 18:58:20.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/527
2025-10-12 18:58:20.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/527
2025-10-12 18:58:20.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/527
2025-10-12 18:58:20.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/527
2025-10-12 18:58:20.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/527
2025-10-12 18:58:20.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/527
2025-10-12 18:58:20.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/527
2025-10-12 18:58:20.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/527
2025-10-12 18:58:20.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/527
2025-10-12 18:58:20.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/527
2025-10-12 18:58:20.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/527
2025-10-12 18:58:20.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/527
2025-10-12 18:58:20.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/527
2025-10-12 18:58:20.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/527
2025-10-12 18:58:20.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/527
2025-10-12 18:58:20.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/527
2025-10-12 18:58:20.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/527
2025-10-12 18:58:20.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/527
2025-10-12 18:58:20.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/527
2025-10-12 18:58:20.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/527
2025-10-12 18:58:20.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/527
2025-10-12 18:58:20.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/527
2025-10-12 18:58:20.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/527
2025-10-12 18:58:20.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/527
2025-10-12 18:58:20.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/527
2025-10-12 18:58:20.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/527
2025-10-12 18:58:20.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/527
2025-10-12 18:58:20.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/527
2025-10-12 18:58:20.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/527
2025-10-12 18:58:20.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/527
2025-10-12 18:58:20.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/527
2025-10-12 18:58:20.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/527
2025-10-12 18:58:20.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/527
2025-10-12 18:58:20.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/527
2025-10-12 18:58:20.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/527
2025-10-12 18:58:20.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/527
2025-10-12 18:58:20.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/527
2025-10-12 18:58:20.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/527
2025-10-12 18:58:20.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  69/527
2025-10-12 18:58:20.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  70/527
2025-10-12 18:58:20.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  71/527
2025-10-12 18:58:20.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  72/527
2025-10-12 18:58:20.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  73/527
2025-10-12 18:58:20.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  74/527
2025-10-12 18:58:20.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  75/527
2025-10-12 18:58:20.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  76/527
2025-10-12 18:58:20.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  77/527
2025-10-12 18:58:20.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  78/527
2025-10-12 18:58:20.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  79/527
2025-10-12 18:58:20.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  80/527
2025-10-12 18:58:20.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  81/527
2025-10-12 18:58:20.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  82/527
2025-10-12 18:58:20.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  83/527
2025-10-12 18:58:20.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  84/527
2025-10-12 18:58:20.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  85/527
2025-10-12 18:58:20.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  86/527
2025-10-12 18:58:20.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  87/527
2025-10-12 18:58:20.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  88/527
2025-10-12 18:58:20.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  89/527
2025-10-12 18:58:20.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  90/527
2025-10-12 18:58:20.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  91/527
2025-10-12 18:58:20.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  92/527
2025-10-12 18:58:20.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  93/527
2025-10-12 18:58:20.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  94/527
2025-10-12 18:58:20.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  95/527
2025-10-12 18:58:20.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  96/527
2025-10-12 18:58:20.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  97/527
2025-10-12 18:58:20.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  98/527
2025-10-12 18:58:20.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  99/527
2025-10-12 18:58:20.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  100/527
2025-10-12 18:58:20.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  101/527
2025-10-12 18:58:20.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  102/527
2025-10-12 18:58:20.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  103/527
2025-10-12 18:58:20.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  104/527
2025-10-12 18:58:20.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  105/527
2025-10-12 18:58:20.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  106/527
2025-10-12 18:58:20.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  107/527
2025-10-12 18:58:20.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  108/527
2025-10-12 18:58:20.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  109/527
2025-10-12 18:58:20.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  110/527
2025-10-12 18:58:20.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  111/527
2025-10-12 18:58:20.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  112/527
2025-10-12 18:58:20.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  113/527
2025-10-12 18:58:20.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  114/527
2025-10-12 18:58:20.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  115/527
2025-10-12 18:58:20.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  116/527
2025-10-12 18:58:20.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  117/527
2025-10-12 18:58:20.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  118/527
2025-10-12 18:58:20.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  119/527
2025-10-12 18:58:20.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  120/527
2025-10-12 18:58:20.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  121/527
2025-10-12 18:58:20.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  122/527
2025-10-12 18:58:20.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  123/527
2025-10-12 18:58:20.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  124/527
2025-10-12 18:58:20.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  125/527
2025-10-12 18:58:20.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  126/527
2025-10-12 18:58:20.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  127/527
2025-10-12 18:58:20.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  128/527
2025-10-12 18:58:20.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  129/527
2025-10-12 18:58:20.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  130/527
2025-10-12 18:58:20.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  131/527
2025-10-12 18:58:20.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  132/527
2025-10-12 18:58:20.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  133/527
2025-10-12 18:58:20.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  134/527
2025-10-12 18:58:20.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  135/527
2025-10-12 18:58:20.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  136/527
2025-10-12 18:58:20.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  137/527
2025-10-12 18:58:20.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  138/527
2025-10-12 18:58:20.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  139/527
2025-10-12 18:58:20.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  140/527
2025-10-12 18:58:20.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  141/527
2025-10-12 18:58:20.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  142/527
2025-10-12 18:58:20.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  143/527
2025-10-12 18:58:20.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  144/527
2025-10-12 18:58:20.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  145/527
2025-10-12 18:58:20.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  146/527
2025-10-12 18:58:20.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  147/527
2025-10-12 18:58:20.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  148/527
2025-10-12 18:58:20.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  149/527
2025-10-12 18:58:20.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  150/527
2025-10-12 18:58:20.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  151/527
2025-10-12 18:58:20.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  152/527
2025-10-12 18:58:20.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  153/527
2025-10-12 18:58:20.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  154/527
2025-10-12 18:58:20.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  155/527
2025-10-12 18:58:20.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  156/527
2025-10-12 18:58:20.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  157/527
2025-10-12 18:58:20.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  158/527
2025-10-12 18:58:20.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  159/527
2025-10-12 18:58:20.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  160/527
2025-10-12 18:58:20.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  161/527
2025-10-12 18:58:20.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  162/527
2025-10-12 18:58:20.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  163/527
2025-10-12 18:58:20.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  164/527
2025-10-12 18:58:20.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  165/527
2025-10-12 18:58:20.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  166/527
2025-10-12 18:58:20.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  167/527
2025-10-12 18:58:20.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  168/527
2025-10-12 18:58:20.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  169/527
2025-10-12 18:58:20.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  170/527
2025-10-12 18:58:20.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  171/527
2025-10-12 18:58:20.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  172/527
2025-10-12 18:58:20.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  173/527
2025-10-12 18:58:20.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  174/527
2025-10-12 18:58:20.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  175/527
2025-10-12 18:58:20.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  176/527
2025-10-12 18:58:20.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  177/527
2025-10-12 18:58:20.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  178/527
2025-10-12 18:58:20.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  179/527
2025-10-12 18:58:20.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  180/527
2025-10-12 18:58:20.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  181/527
2025-10-12 18:58:20.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  182/527
2025-10-12 18:58:20.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  183/527
2025-10-12 18:58:20.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  184/527
2025-10-12 18:58:20.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  185/527
2025-10-12 18:58:20.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  186/527
2025-10-12 18:58:20.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  187/527
2025-10-12 18:58:20.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  188/527
2025-10-12 18:58:20.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  189/527
2025-10-12 18:58:20.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  190/527
2025-10-12 18:58:20.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  191/527
2025-10-12 18:58:20.0377 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  192/527
2025-10-12 18:58:20.0377 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  193/527
2025-10-12 18:58:20.0378 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  194/527
2025-10-12 18:58:20.0378 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  195/527
2025-10-12 18:58:20.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  196/527
2025-10-12 18:58:20.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  197/527
2025-10-12 18:58:20.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  198/527
2025-10-12 18:58:20.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  199/527
2025-10-12 18:58:20.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  200/527
2025-10-12 18:58:20.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  201/527
2025-10-12 18:58:20.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  202/527
2025-10-12 18:58:20.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  203/527
2025-10-12 18:58:20.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  204/527
2025-10-12 18:58:20.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  205/527
2025-10-12 18:58:20.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  206/527
2025-10-12 18:58:20.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  207/527
2025-10-12 18:58:20.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  208/527
2025-10-12 18:58:20.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  209/527
2025-10-12 18:58:20.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  210/527
2025-10-12 18:58:20.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  211/527
2025-10-12 18:58:20.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  212/527
2025-10-12 18:58:20.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  213/527
2025-10-12 18:58:20.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  214/527
2025-10-12 18:58:20.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  215/527
2025-10-12 18:58:20.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  216/527
2025-10-12 18:58:20.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  217/527
2025-10-12 18:58:20.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  218/527
2025-10-12 18:58:20.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  219/527
2025-10-12 18:58:20.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  220/527
2025-10-12 18:58:20.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  221/527
2025-10-12 18:58:20.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  222/527
2025-10-12 18:58:20.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  223/527
2025-10-12 18:58:20.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  224/527
2025-10-12 18:58:20.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  225/527
2025-10-12 18:58:20.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  226/527
2025-10-12 18:58:20.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  227/527
2025-10-12 18:58:20.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  228/527
2025-10-12 18:58:20.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  229/527
2025-10-12 18:58:20.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  230/527
2025-10-12 18:58:20.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  231/527
2025-10-12 18:58:20.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  232/527
2025-10-12 18:58:20.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  233/527
2025-10-12 18:58:20.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  234/527
2025-10-12 18:58:20.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  235/527
2025-10-12 18:58:20.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  236/527
2025-10-12 18:58:20.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  237/527
2025-10-12 18:58:20.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  238/527
2025-10-12 18:58:20.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  239/527
2025-10-12 18:58:20.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  240/527
2025-10-12 18:58:20.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  241/527
2025-10-12 18:58:20.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  242/527
2025-10-12 18:58:20.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  243/527
2025-10-12 18:58:20.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  244/527
2025-10-12 18:58:20.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  245/527
2025-10-12 18:58:20.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  246/527
2025-10-12 18:58:20.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  247/527
2025-10-12 18:58:20.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  248/527
2025-10-12 18:58:20.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  249/527
2025-10-12 18:58:20.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  250/527
2025-10-12 18:58:20.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  251/527
2025-10-12 18:58:20.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  252/527
2025-10-12 18:58:20.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  253/527
2025-10-12 18:58:20.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  254/527
2025-10-12 18:58:20.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  255/527
2025-10-12 18:58:20.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  256/527
2025-10-12 18:58:20.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  257/527
2025-10-12 18:58:20.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  258/527
2025-10-12 18:58:20.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  259/527
2025-10-12 18:58:20.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  260/527
2025-10-12 18:58:20.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  261/527
2025-10-12 18:58:20.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  262/527
2025-10-12 18:58:20.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  263/527
2025-10-12 18:58:20.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  264/527
2025-10-12 18:58:20.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  265/527
2025-10-12 18:58:20.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  266/527
2025-10-12 18:58:20.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  267/527
2025-10-12 18:58:20.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  268/527
2025-10-12 18:58:20.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  269/527
2025-10-12 18:58:20.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  270/527
2025-10-12 18:58:20.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  271/527
2025-10-12 18:58:20.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  272/527
2025-10-12 18:58:20.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  273/527
2025-10-12 18:58:20.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  274/527
2025-10-12 18:58:20.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  275/527
2025-10-12 18:58:20.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  276/527
2025-10-12 18:58:20.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  277/527
2025-10-12 18:58:20.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  278/527
2025-10-12 18:58:20.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  279/527
2025-10-12 18:58:20.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  280/527
2025-10-12 18:58:20.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  281/527
2025-10-12 18:58:20.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  282/527
2025-10-12 18:58:20.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  283/527
2025-10-12 18:58:20.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  284/527
2025-10-12 18:58:20.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  285/527
2025-10-12 18:58:20.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  286/527
2025-10-12 18:58:20.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  287/527
2025-10-12 18:58:20.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  288/527
2025-10-12 18:58:20.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  289/527
2025-10-12 18:58:20.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  290/527
2025-10-12 18:58:20.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  291/527
2025-10-12 18:58:20.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  292/527
2025-10-12 18:58:20.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  293/527
2025-10-12 18:58:20.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  294/527
2025-10-12 18:58:20.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  295/527
2025-10-12 18:58:20.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  296/527
2025-10-12 18:58:20.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  297/527
2025-10-12 18:58:20.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  298/527
2025-10-12 18:58:20.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  299/527
2025-10-12 18:58:20.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  300/527
2025-10-12 18:58:20.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  301/527
2025-10-12 18:58:20.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  302/527
2025-10-12 18:58:20.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  303/527
2025-10-12 18:58:20.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  304/527
2025-10-12 18:58:20.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  305/527
2025-10-12 18:58:20.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  306/527
2025-10-12 18:58:20.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  307/527
2025-10-12 18:58:20.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  308/527
2025-10-12 18:58:20.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  309/527
2025-10-12 18:58:20.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  310/527
2025-10-12 18:58:20.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  311/527
2025-10-12 18:58:20.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  312/527
2025-10-12 18:58:20.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  313/527
2025-10-12 18:58:20.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  314/527
2025-10-12 18:58:20.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  315/527
2025-10-12 18:58:20.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  316/527
2025-10-12 18:58:20.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  317/527
2025-10-12 18:58:20.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  318/527
2025-10-12 18:58:20.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  319/527
2025-10-12 18:58:20.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  320/527
2025-10-12 18:58:20.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  321/527
2025-10-12 18:58:20.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  322/527
2025-10-12 18:58:20.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  323/527
2025-10-12 18:58:20.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  324/527
2025-10-12 18:58:20.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  325/527
2025-10-12 18:58:20.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  326/527
2025-10-12 18:58:20.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  327/527
2025-10-12 18:58:20.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  328/527
2025-10-12 18:58:20.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  329/527
2025-10-12 18:58:20.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  330/527
2025-10-12 18:58:20.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  331/527
2025-10-12 18:58:20.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  332/527
2025-10-12 18:58:20.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  333/527
2025-10-12 18:58:20.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  334/527
2025-10-12 18:58:20.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  335/527
2025-10-12 18:58:20.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  336/527
2025-10-12 18:58:20.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  337/527
2025-10-12 18:58:20.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  338/527
2025-10-12 18:58:20.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  339/527
2025-10-12 18:58:20.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  340/527
2025-10-12 18:58:20.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  341/527
2025-10-12 18:58:20.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  342/527
2025-10-12 18:58:20.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  343/527
2025-10-12 18:58:20.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  344/527
2025-10-12 18:58:20.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  345/527
2025-10-12 18:58:20.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  346/527
2025-10-12 18:58:20.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  347/527
2025-10-12 18:58:20.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  348/527
2025-10-12 18:58:20.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  349/527
2025-10-12 18:58:20.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  350/527
2025-10-12 18:58:20.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  351/527
2025-10-12 18:58:20.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  352/527
2025-10-12 18:58:20.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  353/527
2025-10-12 18:58:20.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  354/527
2025-10-12 18:58:20.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  355/527
2025-10-12 18:58:20.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  356/527
2025-10-12 18:58:20.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  357/527
2025-10-12 18:58:20.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  358/527
2025-10-12 18:58:20.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  359/527
2025-10-12 18:58:20.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  360/527
2025-10-12 18:58:20.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  361/527
2025-10-12 18:58:20.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  362/527
2025-10-12 18:58:20.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  363/527
2025-10-12 18:58:20.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  364/527
2025-10-12 18:58:20.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  365/527
2025-10-12 18:58:20.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  366/527
2025-10-12 18:58:20.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  367/527
2025-10-12 18:58:20.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  368/527
2025-10-12 18:58:20.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  369/527
2025-10-12 18:58:20.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  370/527
2025-10-12 18:58:20.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  371/527
2025-10-12 18:58:20.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  372/527
2025-10-12 18:58:20.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  373/527
2025-10-12 18:58:20.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  374/527
2025-10-12 18:58:20.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  375/527
2025-10-12 18:58:20.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  376/527
2025-10-12 18:58:20.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  377/527
2025-10-12 18:58:20.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  378/527
2025-10-12 18:58:20.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  379/527
2025-10-12 18:58:20.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  380/527
2025-10-12 18:58:20.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  381/527
2025-10-12 18:58:20.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  382/527
2025-10-12 18:58:20.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  383/527
2025-10-12 18:58:20.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  384/527
2025-10-12 18:58:20.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  385/527
2025-10-12 18:58:20.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  386/527
2025-10-12 18:58:20.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  387/527
2025-10-12 18:58:20.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  388/527
2025-10-12 18:58:20.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  389/527
2025-10-12 18:58:20.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  390/527
2025-10-12 18:58:20.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  391/527
2025-10-12 18:58:20.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  392/527
2025-10-12 18:58:20.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  393/527
2025-10-12 18:58:20.0479 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  394/527
2025-10-12 18:58:20.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  395/527
2025-10-12 18:58:20.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  396/527
2025-10-12 18:58:20.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  397/527
2025-10-12 18:58:20.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  398/527
2025-10-12 18:58:20.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  399/527
2025-10-12 18:58:20.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  400/527
2025-10-12 18:58:20.0483 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  401/527
2025-10-12 18:58:20.0483 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  402/527
2025-10-12 18:58:20.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  403/527
2025-10-12 18:58:20.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  404/527
2025-10-12 18:58:20.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  405/527
2025-10-12 18:58:20.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  406/527
2025-10-12 18:58:20.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  407/527
2025-10-12 18:58:20.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  408/527
2025-10-12 18:58:20.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  409/527
2025-10-12 18:58:20.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  410/527
2025-10-12 18:58:20.0488 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  411/527
2025-10-12 18:58:20.0488 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  412/527
2025-10-12 18:58:20.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  413/527
2025-10-12 18:58:20.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  414/527
2025-10-12 18:58:20.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  415/527
2025-10-12 18:58:20.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  416/527
2025-10-12 18:58:20.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  417/527
2025-10-12 18:58:20.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  418/527
2025-10-12 18:58:20.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  419/527
2025-10-12 18:58:20.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  420/527
2025-10-12 18:58:20.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  421/527
2025-10-12 18:58:20.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  422/527
2025-10-12 18:58:20.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  423/527
2025-10-12 18:58:20.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  424/527
2025-10-12 18:58:20.0495 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  425/527
2025-10-12 18:58:20.0495 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  426/527
2025-10-12 18:58:20.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  427/527
2025-10-12 18:58:20.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  428/527
2025-10-12 18:58:20.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  429/527
2025-10-12 18:58:20.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  430/527
2025-10-12 18:58:20.0498 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  431/527
2025-10-12 18:58:20.0498 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  432/527
2025-10-12 18:58:20.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  433/527
2025-10-12 18:58:20.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  434/527
2025-10-12 18:58:20.0500 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  435/527
2025-10-12 18:58:20.0500 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  436/527
2025-10-12 18:58:20.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  437/527
2025-10-12 18:58:20.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  438/527
2025-10-12 18:58:20.0502 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  439/527
2025-10-12 18:58:20.0502 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  440/527
2025-10-12 18:58:20.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  441/527
2025-10-12 18:58:20.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  442/527
2025-10-12 18:58:20.0504 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  443/527
2025-10-12 18:58:20.0504 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  444/527
2025-10-12 18:58:20.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  445/527
2025-10-12 18:58:20.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  446/527
2025-10-12 18:58:20.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  447/527
2025-10-12 18:58:20.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  448/527
2025-10-12 18:58:20.0507 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  449/527
2025-10-12 18:58:20.0507 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  450/527
2025-10-12 18:58:20.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  451/527
2025-10-12 18:58:20.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  452/527
2025-10-12 18:58:20.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  453/527
2025-10-12 18:58:20.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  454/527
2025-10-12 18:58:20.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  455/527
2025-10-12 18:58:20.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  456/527
2025-10-12 18:58:20.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  457/527
2025-10-12 18:58:20.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  458/527
2025-10-12 18:58:20.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  459/527
2025-10-12 18:58:20.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  460/527
2025-10-12 18:58:20.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  461/527
2025-10-12 18:58:20.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  462/527
2025-10-12 18:58:20.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  463/527
2025-10-12 18:58:20.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  464/527
2025-10-12 18:58:20.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  465/527
2025-10-12 18:58:20.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  466/527
2025-10-12 18:58:20.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  467/527
2025-10-12 18:58:20.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  468/527
2025-10-12 18:58:20.0517 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  469/527
2025-10-12 18:58:20.0518 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  470/527
2025-10-12 18:58:20.0518 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  471/527
2025-10-12 18:58:20.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  472/527
2025-10-12 18:58:20.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  473/527
2025-10-12 18:58:20.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  474/527
2025-10-12 18:58:20.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  475/527
2025-10-12 18:58:20.0521 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  476/527
2025-10-12 18:58:20.0521 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  477/527
2025-10-12 18:58:20.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  478/527
2025-10-12 18:58:20.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  479/527
2025-10-12 18:58:20.0523 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  480/527
2025-10-12 18:58:20.0523 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  481/527
2025-10-12 18:58:20.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  482/527
2025-10-12 18:58:20.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  483/527
2025-10-12 18:58:20.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  484/527
2025-10-12 18:58:20.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  485/527
2025-10-12 18:58:20.0526 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  486/527
2025-10-12 18:58:20.0526 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  487/527
2025-10-12 18:58:20.0527 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  488/527
2025-10-12 18:58:20.0527 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  489/527
2025-10-12 18:58:20.0528 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  490/527
2025-10-12 18:58:20.0528 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  491/527
2025-10-12 18:58:20.0529 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  492/527
2025-10-12 18:58:20.0529 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  493/527
2025-10-12 18:58:20.0719 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  494/527
2025-10-12 18:58:20.0720 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  495/527
2025-10-12 18:58:20.0721 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  496/527
2025-10-12 18:58:20.0722 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  497/527
2025-10-12 18:58:20.0722 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  498/527
2025-10-12 18:58:20.0723 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  499/527
2025-10-12 18:58:20.0723 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  500/527
2025-10-12 18:58:20.0724 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  501/527
2025-10-12 18:58:20.0724 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  502/527
2025-10-12 18:58:20.0725 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  503/527
2025-10-12 18:58:20.0725 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  504/527
2025-10-12 18:58:20.0726 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  505/527
2025-10-12 18:58:20.0726 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  506/527
2025-10-12 18:58:20.0727 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  507/527
2025-10-12 18:58:20.0727 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  508/527
2025-10-12 18:58:20.0728 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  509/527
2025-10-12 18:58:20.0729 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  510/527
2025-10-12 18:58:20.0729 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  511/527
2025-10-12 18:58:20.0730 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  512/527
2025-10-12 18:58:20.0730 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  513/527
2025-10-12 18:58:20.0731 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  514/527
2025-10-12 18:58:20.0731 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  515/527
2025-10-12 18:58:20.0732 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  516/527
2025-10-12 18:58:20.0732 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  517/527
2025-10-12 18:58:20.0733 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  518/527
2025-10-12 18:58:20.0733 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  519/527
2025-10-12 18:58:20.0734 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  520/527
2025-10-12 18:58:20.0734 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  521/527
2025-10-12 18:58:20.0735 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  522/527
2025-10-12 18:58:20.0735 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  523/527
2025-10-12 18:58:20.0736 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  524/527
2025-10-12 18:58:20.0736 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  525/527
2025-10-12 18:58:20.0737 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  526/527
2025-10-12 18:58:20.0737 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  527/527
2025-10-12 18:58:20.0759 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-12 18:58:20.0760 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-12 18:58:20.0763 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-12 18:58:20.0763 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-12 18:58:20.0780 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:58:20.0818 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-12 18:58:20.0818 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-12 18:58:20.0822 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-12 18:58:20.0822 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-12 18:58:20.0856 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /projects/dsci435/fmcsafetyevents_fa25/graphRAG/cache/extract_graph
2025-10-12 18:58:34.0685 - INFO - graphrag.logger.progress - extract graph progress: 1/527
2025-10-12 18:58:34.0689 - INFO - graphrag.logger.progress - extract graph progress: 2/527
2025-10-12 18:58:34.0691 - INFO - graphrag.logger.progress - extract graph progress: 3/527
2025-10-12 18:58:34.0693 - INFO - graphrag.logger.progress - extract graph progress: 4/527
2025-10-12 18:58:34.0695 - INFO - graphrag.logger.progress - extract graph progress: 5/527
2025-10-12 18:58:34.0697 - INFO - graphrag.logger.progress - extract graph progress: 6/527
2025-10-12 18:58:34.0701 - INFO - graphrag.logger.progress - extract graph progress: 7/527
2025-10-12 18:58:34.0705 - INFO - graphrag.logger.progress - extract graph progress: 8/527
2025-10-12 18:58:34.0709 - INFO - graphrag.logger.progress - extract graph progress: 9/527
2025-10-12 18:58:34.0713 - INFO - graphrag.logger.progress - extract graph progress: 10/527
2025-10-12 18:58:34.0716 - INFO - graphrag.logger.progress - extract graph progress: 11/527
2025-10-12 18:58:34.0719 - INFO - graphrag.logger.progress - extract graph progress: 12/527
2025-10-12 18:58:34.0721 - INFO - graphrag.logger.progress - extract graph progress: 13/527
2025-10-12 18:58:34.0723 - INFO - graphrag.logger.progress - extract graph progress: 14/527
2025-10-12 18:58:34.0725 - INFO - graphrag.logger.progress - extract graph progress: 15/527
2025-10-12 18:58:34.0728 - INFO - graphrag.logger.progress - extract graph progress: 16/527
2025-10-12 18:58:34.0731 - INFO - graphrag.logger.progress - extract graph progress: 17/527
2025-10-12 18:58:34.0734 - INFO - graphrag.logger.progress - extract graph progress: 18/527
2025-10-12 18:58:34.0736 - INFO - graphrag.logger.progress - extract graph progress: 19/527
2025-10-12 18:58:34.0737 - INFO - graphrag.logger.progress - extract graph progress: 20/527
2025-10-12 18:58:34.0739 - INFO - graphrag.logger.progress - extract graph progress: 21/527
2025-10-12 18:58:34.0741 - INFO - graphrag.logger.progress - extract graph progress: 22/527
2025-10-12 18:58:34.0743 - INFO - graphrag.logger.progress - extract graph progress: 23/527
2025-10-12 18:58:34.0746 - INFO - graphrag.logger.progress - extract graph progress: 24/527
2025-10-12 18:58:34.0749 - INFO - graphrag.logger.progress - extract graph progress: 25/527
2025-10-12 18:58:34.0753 - INFO - graphrag.logger.progress - extract graph progress: 26/527
2025-10-12 18:58:34.0757 - INFO - graphrag.logger.progress - extract graph progress: 27/527
2025-10-12 18:58:34.0760 - INFO - graphrag.logger.progress - extract graph progress: 28/527
2025-10-12 18:58:34.0763 - INFO - graphrag.logger.progress - extract graph progress: 29/527
2025-10-12 18:58:34.0765 - INFO - graphrag.logger.progress - extract graph progress: 30/527
2025-10-12 18:58:44.0642 - INFO - graphrag.logger.progress - extract graph progress: 31/527
2025-10-12 18:58:44.0645 - INFO - graphrag.logger.progress - extract graph progress: 32/527
2025-10-12 18:58:44.0647 - INFO - graphrag.logger.progress - extract graph progress: 33/527
2025-10-12 18:58:44.0649 - INFO - graphrag.logger.progress - extract graph progress: 34/527
2025-10-12 18:58:44.0651 - INFO - graphrag.logger.progress - extract graph progress: 35/527
2025-10-12 18:58:44.0652 - INFO - graphrag.logger.progress - extract graph progress: 36/527
2025-10-12 18:58:44.0654 - INFO - graphrag.logger.progress - extract graph progress: 37/527
2025-10-12 18:58:44.0656 - INFO - graphrag.logger.progress - extract graph progress: 38/527
2025-10-12 18:58:44.0658 - INFO - graphrag.logger.progress - extract graph progress: 39/527
2025-10-12 18:58:44.0660 - INFO - graphrag.logger.progress - extract graph progress: 40/527
2025-10-12 18:58:44.0662 - INFO - graphrag.logger.progress - extract graph progress: 41/527
2025-10-12 18:58:44.0663 - INFO - graphrag.logger.progress - extract graph progress: 42/527
2025-10-12 18:58:44.0665 - INFO - graphrag.logger.progress - extract graph progress: 43/527
2025-10-12 18:58:44.0667 - INFO - graphrag.logger.progress - extract graph progress: 44/527
2025-10-12 18:58:44.0669 - INFO - graphrag.logger.progress - extract graph progress: 45/527
2025-10-12 18:58:44.0671 - INFO - graphrag.logger.progress - extract graph progress: 46/527
2025-10-12 18:58:44.0673 - INFO - graphrag.logger.progress - extract graph progress: 47/527
2025-10-12 18:58:44.0675 - INFO - graphrag.logger.progress - extract graph progress: 48/527
2025-10-12 18:58:44.0676 - INFO - graphrag.logger.progress - extract graph progress: 49/527
2025-10-12 18:58:44.0678 - INFO - graphrag.logger.progress - extract graph progress: 50/527
2025-10-12 18:58:44.0680 - INFO - graphrag.logger.progress - extract graph progress: 51/527
2025-10-12 18:58:44.0682 - INFO - graphrag.logger.progress - extract graph progress: 52/527
2025-10-12 18:58:44.0684 - INFO - graphrag.logger.progress - extract graph progress: 53/527
2025-10-12 18:58:44.0686 - INFO - graphrag.logger.progress - extract graph progress: 54/527
2025-10-12 18:58:44.0687 - INFO - graphrag.logger.progress - extract graph progress: 55/527
2025-10-12 18:58:53.0673 - INFO - graphrag.logger.progress - extract graph progress: 56/527
2025-10-12 18:58:53.0678 - INFO - graphrag.logger.progress - extract graph progress: 57/527
2025-10-12 18:58:53.0682 - INFO - graphrag.logger.progress - extract graph progress: 58/527
2025-10-12 18:58:53.0685 - INFO - graphrag.logger.progress - extract graph progress: 59/527
2025-10-12 18:58:53.0687 - INFO - graphrag.logger.progress - extract graph progress: 60/527
2025-10-12 18:58:53.0688 - INFO - graphrag.logger.progress - extract graph progress: 61/527
2025-10-12 18:58:53.0690 - INFO - graphrag.logger.progress - extract graph progress: 62/527
2025-10-12 18:58:53.0693 - INFO - graphrag.logger.progress - extract graph progress: 63/527
2025-10-12 18:58:53.0696 - INFO - graphrag.logger.progress - extract graph progress: 64/527
2025-10-12 18:58:53.0698 - INFO - graphrag.logger.progress - extract graph progress: 65/527
2025-10-12 18:58:53.0700 - INFO - graphrag.logger.progress - extract graph progress: 66/527
2025-10-12 18:58:53.0702 - INFO - graphrag.logger.progress - extract graph progress: 67/527
2025-10-12 18:58:53.0707 - INFO - graphrag.logger.progress - extract graph progress: 68/527
2025-10-12 18:58:53.0710 - INFO - graphrag.logger.progress - extract graph progress: 69/527
2025-10-12 18:58:53.0713 - INFO - graphrag.logger.progress - extract graph progress: 70/527
2025-10-12 18:58:53.0714 - INFO - graphrag.logger.progress - extract graph progress: 71/527
2025-10-12 18:58:53.0716 - INFO - graphrag.logger.progress - extract graph progress: 72/527
2025-10-12 18:58:53.0719 - INFO - graphrag.logger.progress - extract graph progress: 73/527
2025-10-12 18:58:53.0722 - INFO - graphrag.logger.progress - extract graph progress: 74/527
2025-10-12 18:58:53.0726 - INFO - graphrag.logger.progress - extract graph progress: 75/527
2025-10-12 18:58:53.0727 - INFO - graphrag.logger.progress - extract graph progress: 76/527
2025-10-12 18:58:53.0729 - INFO - graphrag.logger.progress - extract graph progress: 77/527
2025-10-12 18:58:53.0732 - INFO - graphrag.logger.progress - extract graph progress: 78/527
2025-10-12 18:58:53.0736 - INFO - graphrag.logger.progress - extract graph progress: 79/527
2025-10-12 18:58:53.0739 - INFO - graphrag.logger.progress - extract graph progress: 80/527
2025-10-12 18:58:53.0743 - INFO - graphrag.logger.progress - extract graph progress: 81/527
2025-10-12 18:58:53.0748 - INFO - graphrag.logger.progress - extract graph progress: 82/527
2025-10-12 18:58:53.0752 - INFO - graphrag.logger.progress - extract graph progress: 83/527
2025-10-12 18:58:53.0755 - INFO - graphrag.logger.progress - extract graph progress: 84/527
2025-10-12 18:58:53.0759 - INFO - graphrag.logger.progress - extract graph progress: 85/527
2025-10-12 18:58:53.0763 - INFO - graphrag.logger.progress - extract graph progress: 86/527
2025-10-12 18:58:53.0766 - INFO - graphrag.logger.progress - extract graph progress: 87/527
2025-10-12 18:58:53.0769 - INFO - graphrag.logger.progress - extract graph progress: 88/527
2025-10-12 18:58:53.0773 - INFO - graphrag.logger.progress - extract graph progress: 89/527
2025-10-12 18:58:53.0777 - INFO - graphrag.logger.progress - extract graph progress: 90/527
2025-10-12 18:58:53.0781 - INFO - graphrag.logger.progress - extract graph progress: 91/527
2025-10-12 18:58:53.0784 - INFO - graphrag.logger.progress - extract graph progress: 92/527
2025-10-12 18:58:53.0788 - INFO - graphrag.logger.progress - extract graph progress: 93/527
2025-10-12 18:58:53.0792 - INFO - graphrag.logger.progress - extract graph progress: 94/527
2025-10-12 18:58:53.0796 - INFO - graphrag.logger.progress - extract graph progress: 95/527
2025-10-12 18:58:53.0799 - INFO - graphrag.logger.progress - extract graph progress: 96/527
2025-10-12 18:58:53.0803 - INFO - graphrag.logger.progress - extract graph progress: 97/527
2025-10-12 18:58:53.0805 - INFO - graphrag.logger.progress - extract graph progress: 98/527
2025-10-12 18:58:53.0809 - INFO - graphrag.logger.progress - extract graph progress: 99/527
2025-10-12 18:58:53.0813 - INFO - graphrag.logger.progress - extract graph progress: 100/527
2025-10-12 18:58:53.0817 - INFO - graphrag.logger.progress - extract graph progress: 101/527
2025-10-12 18:58:53.0819 - INFO - graphrag.logger.progress - extract graph progress: 102/527
2025-10-12 18:58:53.0820 - INFO - graphrag.logger.progress - extract graph progress: 103/527
2025-10-12 18:58:53.0822 - INFO - graphrag.logger.progress - extract graph progress: 104/527
2025-10-12 18:58:53.0825 - INFO - graphrag.logger.progress - extract graph progress: 105/527
2025-10-12 18:58:53.0829 - INFO - graphrag.logger.progress - extract graph progress: 106/527
2025-10-12 18:58:53.0831 - INFO - graphrag.logger.progress - extract graph progress: 107/527
2025-10-12 18:58:53.0833 - INFO - graphrag.logger.progress - extract graph progress: 108/527
2025-10-12 18:58:53.0835 - INFO - graphrag.logger.progress - extract graph progress: 109/527
2025-10-12 18:58:53.0836 - INFO - graphrag.logger.progress - extract graph progress: 110/527
2025-10-12 18:58:53.0838 - INFO - graphrag.logger.progress - extract graph progress: 111/527
2025-10-12 18:58:53.0840 - INFO - graphrag.logger.progress - extract graph progress: 112/527
2025-10-12 18:58:53.0842 - INFO - graphrag.logger.progress - extract graph progress: 113/527
2025-10-12 18:58:53.0844 - INFO - graphrag.logger.progress - extract graph progress: 114/527
2025-10-12 18:58:53.0846 - INFO - graphrag.logger.progress - extract graph progress: 115/527
2025-10-12 18:58:53.0848 - INFO - graphrag.logger.progress - extract graph progress: 116/527
2025-10-12 18:58:53.0849 - INFO - graphrag.logger.progress - extract graph progress: 117/527
2025-10-12 18:58:53.0851 - INFO - graphrag.logger.progress - extract graph progress: 118/527
2025-10-12 18:58:53.0853 - INFO - graphrag.logger.progress - extract graph progress: 119/527
2025-10-12 18:58:53.0855 - INFO - graphrag.logger.progress - extract graph progress: 120/527
2025-10-12 18:58:53.0857 - INFO - graphrag.logger.progress - extract graph progress: 121/527
2025-10-12 18:59:03.0728 - INFO - graphrag.logger.progress - extract graph progress: 122/527
2025-10-12 18:59:03.0730 - INFO - graphrag.logger.progress - extract graph progress: 123/527
2025-10-12 18:59:03.0732 - INFO - graphrag.logger.progress - extract graph progress: 124/527
2025-10-12 18:59:03.0734 - INFO - graphrag.logger.progress - extract graph progress: 125/527
2025-10-12 18:59:14.0433 - INFO - graphrag.logger.progress - extract graph progress: 126/527
2025-10-12 18:59:14.0436 - INFO - graphrag.logger.progress - extract graph progress: 127/527
2025-10-12 18:59:14.0438 - INFO - graphrag.logger.progress - extract graph progress: 128/527
2025-10-12 18:59:14.0440 - INFO - graphrag.logger.progress - extract graph progress: 129/527
2025-10-12 18:59:14.0442 - INFO - graphrag.logger.progress - extract graph progress: 130/527
2025-10-12 18:59:14.0444 - INFO - graphrag.logger.progress - extract graph progress: 131/527
2025-10-12 18:59:14.0446 - INFO - graphrag.logger.progress - extract graph progress: 132/527
2025-10-12 18:59:14.0448 - INFO - graphrag.logger.progress - extract graph progress: 133/527
2025-10-12 18:59:14.0450 - INFO - graphrag.logger.progress - extract graph progress: 134/527
2025-10-12 18:59:14.0451 - INFO - graphrag.logger.progress - extract graph progress: 135/527
2025-10-12 18:59:14.0454 - INFO - graphrag.logger.progress - extract graph progress: 136/527
2025-10-12 18:59:14.0457 - INFO - graphrag.logger.progress - extract graph progress: 137/527
2025-10-12 18:59:14.0461 - INFO - graphrag.logger.progress - extract graph progress: 138/527
2025-10-12 18:59:14.0463 - INFO - graphrag.logger.progress - extract graph progress: 139/527
2025-10-12 18:59:14.0465 - INFO - graphrag.logger.progress - extract graph progress: 140/527
2025-10-12 18:59:14.0468 - INFO - graphrag.logger.progress - extract graph progress: 141/527
2025-10-12 18:59:14.0472 - INFO - graphrag.logger.progress - extract graph progress: 142/527
2025-10-12 18:59:14.0475 - INFO - graphrag.logger.progress - extract graph progress: 143/527
2025-10-12 18:59:14.0478 - INFO - graphrag.logger.progress - extract graph progress: 144/527
2025-10-12 18:59:14.0480 - INFO - graphrag.logger.progress - extract graph progress: 145/527
2025-10-12 18:59:14.0481 - INFO - graphrag.logger.progress - extract graph progress: 146/527
2025-10-12 18:59:14.0483 - INFO - graphrag.logger.progress - extract graph progress: 147/527
2025-10-12 18:59:14.0486 - INFO - graphrag.logger.progress - extract graph progress: 148/527
2025-10-12 18:59:14.0489 - INFO - graphrag.logger.progress - extract graph progress: 149/527
2025-10-12 18:59:20.0728 - INFO - graphrag.logger.progress - extract graph progress: 150/527
2025-10-12 18:59:20.0730 - INFO - graphrag.logger.progress - extract graph progress: 151/527
2025-10-12 18:59:20.0732 - INFO - graphrag.logger.progress - extract graph progress: 152/527
2025-10-12 18:59:20.0734 - INFO - graphrag.logger.progress - extract graph progress: 153/527
2025-10-12 18:59:32.0587 - INFO - graphrag.logger.progress - extract graph progress: 154/527
2025-10-12 18:59:32.0591 - INFO - graphrag.logger.progress - extract graph progress: 155/527
2025-10-12 18:59:32.0595 - INFO - graphrag.logger.progress - extract graph progress: 156/527
2025-10-12 18:59:32.0598 - INFO - graphrag.logger.progress - extract graph progress: 157/527
2025-10-12 18:59:32.0602 - INFO - graphrag.logger.progress - extract graph progress: 158/527
2025-10-12 18:59:32.0605 - INFO - graphrag.logger.progress - extract graph progress: 159/527
2025-10-12 18:59:32.0608 - INFO - graphrag.logger.progress - extract graph progress: 160/527
2025-10-12 18:59:32.0609 - INFO - graphrag.logger.progress - extract graph progress: 161/527
2025-10-12 18:59:32.0611 - INFO - graphrag.logger.progress - extract graph progress: 162/527
2025-10-12 18:59:32.0614 - INFO - graphrag.logger.progress - extract graph progress: 163/527
2025-10-12 18:59:32.0617 - INFO - graphrag.logger.progress - extract graph progress: 164/527
2025-10-12 18:59:32.0620 - INFO - graphrag.logger.progress - extract graph progress: 165/527
2025-10-12 18:59:32.0621 - INFO - graphrag.logger.progress - extract graph progress: 166/527
2025-10-12 18:59:32.0623 - INFO - graphrag.logger.progress - extract graph progress: 167/527
2025-10-12 18:59:32.0625 - INFO - graphrag.logger.progress - extract graph progress: 168/527
2025-10-12 18:59:32.0629 - INFO - graphrag.logger.progress - extract graph progress: 169/527
2025-10-12 18:59:32.0632 - INFO - graphrag.logger.progress - extract graph progress: 170/527
2025-10-12 18:59:43.0889 - INFO - graphrag.logger.progress - extract graph progress: 171/527
2025-10-12 18:59:43.0892 - INFO - graphrag.logger.progress - extract graph progress: 172/527
2025-10-12 18:59:43.0896 - INFO - graphrag.logger.progress - extract graph progress: 173/527
2025-10-12 18:59:43.0899 - INFO - graphrag.logger.progress - extract graph progress: 174/527
2025-10-12 18:59:43.0902 - INFO - graphrag.logger.progress - extract graph progress: 175/527
2025-10-12 18:59:43.0905 - INFO - graphrag.logger.progress - extract graph progress: 176/527
2025-10-12 18:59:43.0909 - INFO - graphrag.logger.progress - extract graph progress: 177/527
2025-10-12 18:59:43.0912 - INFO - graphrag.logger.progress - extract graph progress: 178/527
2025-10-12 18:59:43.0916 - INFO - graphrag.logger.progress - extract graph progress: 179/527
2025-10-12 18:59:43.0920 - INFO - graphrag.logger.progress - extract graph progress: 180/527
2025-10-12 18:59:43.0923 - INFO - graphrag.logger.progress - extract graph progress: 181/527
2025-10-12 18:59:43.0928 - INFO - graphrag.logger.progress - extract graph progress: 182/527
2025-10-12 18:59:43.0930 - INFO - graphrag.logger.progress - extract graph progress: 183/527
2025-10-12 18:59:43.0932 - INFO - graphrag.logger.progress - extract graph progress: 184/527
2025-10-12 18:59:43.0935 - INFO - graphrag.logger.progress - extract graph progress: 185/527
2025-10-12 18:59:43.0938 - INFO - graphrag.logger.progress - extract graph progress: 186/527
2025-10-12 18:59:43.0941 - INFO - graphrag.logger.progress - extract graph progress: 187/527
2025-10-12 18:59:43.0942 - INFO - graphrag.logger.progress - extract graph progress: 188/527
2025-10-12 18:59:43.0947 - INFO - graphrag.logger.progress - extract graph progress: 189/527
2025-10-12 18:59:43.0951 - INFO - graphrag.logger.progress - extract graph progress: 190/527
2025-10-12 18:59:43.0954 - INFO - graphrag.logger.progress - extract graph progress: 191/527
2025-10-12 18:59:43.0957 - INFO - graphrag.logger.progress - extract graph progress: 192/527
2025-10-12 18:59:43.0960 - INFO - graphrag.logger.progress - extract graph progress: 193/527
2025-10-12 18:59:43.0961 - INFO - graphrag.logger.progress - extract graph progress: 194/527
2025-10-12 18:59:43.0963 - INFO - graphrag.logger.progress - extract graph progress: 195/527
2025-10-12 18:59:43.0966 - INFO - graphrag.logger.progress - extract graph progress: 196/527
2025-10-12 18:59:43.0970 - INFO - graphrag.logger.progress - extract graph progress: 197/527
2025-10-12 18:59:43.0973 - INFO - graphrag.logger.progress - extract graph progress: 198/527
2025-10-12 18:59:43.0977 - INFO - graphrag.logger.progress - extract graph progress: 199/527
2025-10-12 18:59:43.0981 - INFO - graphrag.logger.progress - extract graph progress: 200/527
2025-10-12 18:59:43.0984 - INFO - graphrag.logger.progress - extract graph progress: 201/527
2025-10-12 18:59:43.0987 - INFO - graphrag.logger.progress - extract graph progress: 202/527
2025-10-12 18:59:43.0988 - INFO - graphrag.logger.progress - extract graph progress: 203/527
2025-10-12 18:59:43.0990 - INFO - graphrag.logger.progress - extract graph progress: 204/527
2025-10-12 18:59:43.0993 - INFO - graphrag.logger.progress - extract graph progress: 205/527
2025-10-12 18:59:43.0996 - INFO - graphrag.logger.progress - extract graph progress: 206/527
2025-10-12 18:59:43.0999 - INFO - graphrag.logger.progress - extract graph progress: 207/527
2025-10-12 18:59:44.0000 - INFO - graphrag.logger.progress - extract graph progress: 208/527
2025-10-12 18:59:44.0002 - INFO - graphrag.logger.progress - extract graph progress: 209/527
2025-10-12 18:59:44.0005 - INFO - graphrag.logger.progress - extract graph progress: 210/527
2025-10-12 18:59:44.0008 - INFO - graphrag.logger.progress - extract graph progress: 211/527
2025-10-12 18:59:44.0011 - INFO - graphrag.logger.progress - extract graph progress: 212/527
2025-10-12 18:59:44.0013 - INFO - graphrag.logger.progress - extract graph progress: 213/527
2025-10-12 18:59:44.0015 - INFO - graphrag.logger.progress - extract graph progress: 214/527
2025-10-12 18:59:44.0018 - INFO - graphrag.logger.progress - extract graph progress: 215/527
2025-10-12 18:59:44.0022 - INFO - graphrag.logger.progress - extract graph progress: 216/527
2025-10-12 18:59:44.0025 - INFO - graphrag.logger.progress - extract graph progress: 217/527
2025-10-12 18:59:44.0028 - INFO - graphrag.logger.progress - extract graph progress: 218/527
2025-10-12 18:59:44.0030 - INFO - graphrag.logger.progress - extract graph progress: 219/527
2025-10-12 18:59:44.0031 - INFO - graphrag.logger.progress - extract graph progress: 220/527
2025-10-12 18:59:44.0033 - INFO - graphrag.logger.progress - extract graph progress: 221/527
2025-10-12 18:59:44.0035 - INFO - graphrag.logger.progress - extract graph progress: 222/527
2025-10-12 18:59:44.0040 - INFO - graphrag.logger.progress - extract graph progress: 223/527
2025-10-12 18:59:44.0042 - INFO - graphrag.logger.progress - extract graph progress: 224/527
2025-10-12 18:59:44.0045 - INFO - graphrag.logger.progress - extract graph progress: 225/527
2025-10-12 18:59:44.0048 - INFO - graphrag.logger.progress - extract graph progress: 226/527
2025-10-12 18:59:44.0051 - INFO - graphrag.logger.progress - extract graph progress: 227/527
2025-10-12 18:59:44.0052 - INFO - graphrag.logger.progress - extract graph progress: 228/527
2025-10-12 18:59:44.0054 - INFO - graphrag.logger.progress - extract graph progress: 229/527
2025-10-12 18:59:44.0056 - INFO - graphrag.logger.progress - extract graph progress: 230/527
2025-10-12 18:59:44.0060 - INFO - graphrag.logger.progress - extract graph progress: 231/527
2025-10-12 18:59:44.0062 - INFO - graphrag.logger.progress - extract graph progress: 232/527
2025-10-12 18:59:44.0064 - INFO - graphrag.logger.progress - extract graph progress: 233/527
2025-10-12 18:59:44.0067 - INFO - graphrag.logger.progress - extract graph progress: 234/527
2025-10-12 18:59:44.0070 - INFO - graphrag.logger.progress - extract graph progress: 235/527
2025-10-12 18:59:44.0073 - INFO - graphrag.logger.progress - extract graph progress: 236/527
2025-10-12 18:59:44.0074 - INFO - graphrag.logger.progress - extract graph progress: 237/527
2025-10-12 18:59:44.0076 - INFO - graphrag.logger.progress - extract graph progress: 238/527
2025-10-12 18:59:44.0079 - INFO - graphrag.logger.progress - extract graph progress: 239/527
2025-10-12 18:59:44.0082 - INFO - graphrag.logger.progress - extract graph progress: 240/527
2025-10-12 18:59:44.0085 - INFO - graphrag.logger.progress - extract graph progress: 241/527
2025-10-12 18:59:44.0086 - INFO - graphrag.logger.progress - extract graph progress: 242/527
2025-10-12 18:59:44.0089 - INFO - graphrag.logger.progress - extract graph progress: 243/527
2025-10-12 18:59:44.0092 - INFO - graphrag.logger.progress - extract graph progress: 244/527
2025-10-12 18:59:44.0095 - INFO - graphrag.logger.progress - extract graph progress: 245/527
2025-10-12 18:59:44.0096 - INFO - graphrag.logger.progress - extract graph progress: 246/527
2025-10-12 18:59:44.0099 - INFO - graphrag.logger.progress - extract graph progress: 247/527
2025-10-12 18:59:44.0102 - INFO - graphrag.logger.progress - extract graph progress: 248/527
2025-10-12 18:59:44.0104 - INFO - graphrag.logger.progress - extract graph progress: 249/527
2025-10-12 18:59:44.0107 - INFO - graphrag.logger.progress - extract graph progress: 250/527
2025-10-12 18:59:44.0110 - INFO - graphrag.logger.progress - extract graph progress: 251/527
2025-10-12 18:59:44.0114 - INFO - graphrag.logger.progress - extract graph progress: 252/527
2025-10-12 18:59:44.0117 - INFO - graphrag.logger.progress - extract graph progress: 253/527
2025-10-12 18:59:44.0119 - INFO - graphrag.logger.progress - extract graph progress: 254/527
2025-10-12 18:59:44.0123 - INFO - graphrag.logger.progress - extract graph progress: 255/527
2025-10-12 18:59:44.0126 - INFO - graphrag.logger.progress - extract graph progress: 256/527
2025-10-12 18:59:44.0128 - INFO - graphrag.logger.progress - extract graph progress: 257/527
2025-10-12 18:59:44.0129 - INFO - graphrag.logger.progress - extract graph progress: 258/527
2025-10-12 18:59:44.0131 - INFO - graphrag.logger.progress - extract graph progress: 259/527
2025-10-12 18:59:44.0133 - INFO - graphrag.logger.progress - extract graph progress: 260/527
2025-10-12 18:59:44.0136 - INFO - graphrag.logger.progress - extract graph progress: 261/527
2025-10-12 18:59:44.0140 - INFO - graphrag.logger.progress - extract graph progress: 262/527
2025-10-12 18:59:44.0142 - INFO - graphrag.logger.progress - extract graph progress: 263/527
2025-10-12 18:59:44.0143 - INFO - graphrag.logger.progress - extract graph progress: 264/527
2025-10-12 18:59:44.0145 - INFO - graphrag.logger.progress - extract graph progress: 265/527
2025-10-12 18:59:44.0147 - INFO - graphrag.logger.progress - extract graph progress: 266/527
2025-10-12 18:59:44.0151 - INFO - graphrag.logger.progress - extract graph progress: 267/527
2025-10-12 18:59:44.0154 - INFO - graphrag.logger.progress - extract graph progress: 268/527
2025-10-12 18:59:44.0158 - INFO - graphrag.logger.progress - extract graph progress: 269/527
2025-10-12 18:59:44.0161 - INFO - graphrag.logger.progress - extract graph progress: 270/527
2025-10-12 18:59:44.0164 - INFO - graphrag.logger.progress - extract graph progress: 271/527
2025-10-12 18:59:44.0168 - INFO - graphrag.logger.progress - extract graph progress: 272/527
2025-10-12 18:59:44.0171 - INFO - graphrag.logger.progress - extract graph progress: 273/527
2025-10-12 18:59:44.0173 - INFO - graphrag.logger.progress - extract graph progress: 274/527
2025-10-12 18:59:44.0177 - INFO - graphrag.logger.progress - extract graph progress: 275/527
2025-10-12 18:59:44.0180 - INFO - graphrag.logger.progress - extract graph progress: 276/527
2025-10-12 18:59:44.0184 - INFO - graphrag.logger.progress - extract graph progress: 277/527
2025-10-12 18:59:44.0187 - INFO - graphrag.logger.progress - extract graph progress: 278/527
2025-10-12 18:59:44.0191 - INFO - graphrag.logger.progress - extract graph progress: 279/527
2025-10-12 18:59:44.0194 - INFO - graphrag.logger.progress - extract graph progress: 280/527
2025-10-12 18:59:44.0196 - INFO - graphrag.logger.progress - extract graph progress: 281/527
2025-10-12 18:59:44.0197 - INFO - graphrag.logger.progress - extract graph progress: 282/527
2025-10-12 18:59:44.0199 - INFO - graphrag.logger.progress - extract graph progress: 283/527
2025-10-12 18:59:44.0202 - INFO - graphrag.logger.progress - extract graph progress: 284/527
2025-10-12 18:59:44.0205 - INFO - graphrag.logger.progress - extract graph progress: 285/527
2025-10-12 18:59:44.0207 - INFO - graphrag.logger.progress - extract graph progress: 286/527
2025-10-12 18:59:44.0210 - INFO - graphrag.logger.progress - extract graph progress: 287/527
2025-10-12 18:59:44.0213 - INFO - graphrag.logger.progress - extract graph progress: 288/527
2025-10-12 18:59:44.0215 - INFO - graphrag.logger.progress - extract graph progress: 289/527
2025-10-12 18:59:44.0216 - INFO - graphrag.logger.progress - extract graph progress: 290/527
2025-10-12 18:59:44.0218 - INFO - graphrag.logger.progress - extract graph progress: 291/527
2025-10-12 18:59:44.0221 - INFO - graphrag.logger.progress - extract graph progress: 292/527
2025-10-12 18:59:44.0225 - INFO - graphrag.logger.progress - extract graph progress: 293/527
2025-10-12 18:59:44.0227 - INFO - graphrag.logger.progress - extract graph progress: 294/527
2025-10-12 18:59:44.0228 - INFO - graphrag.logger.progress - extract graph progress: 295/527
2025-10-12 18:59:44.0230 - INFO - graphrag.logger.progress - extract graph progress: 296/527
2025-10-12 18:59:44.0234 - INFO - graphrag.logger.progress - extract graph progress: 297/527
2025-10-12 18:59:44.0238 - INFO - graphrag.logger.progress - extract graph progress: 298/527
2025-10-12 18:59:44.0241 - INFO - graphrag.logger.progress - extract graph progress: 299/527
2025-10-12 18:59:44.0244 - INFO - graphrag.logger.progress - extract graph progress: 300/527
2025-10-12 18:59:44.0247 - INFO - graphrag.logger.progress - extract graph progress: 301/527
2025-10-12 18:59:44.0250 - INFO - graphrag.logger.progress - extract graph progress: 302/527
2025-10-12 18:59:44.0251 - INFO - graphrag.logger.progress - extract graph progress: 303/527
2025-10-12 18:59:44.0253 - INFO - graphrag.logger.progress - extract graph progress: 304/527
2025-10-12 18:59:44.0255 - INFO - graphrag.logger.progress - extract graph progress: 305/527
2025-10-12 18:59:44.0259 - INFO - graphrag.logger.progress - extract graph progress: 306/527
2025-10-12 18:59:44.0262 - INFO - graphrag.logger.progress - extract graph progress: 307/527
2025-10-12 18:59:44.0264 - INFO - graphrag.logger.progress - extract graph progress: 308/527
2025-10-12 18:59:44.0265 - INFO - graphrag.logger.progress - extract graph progress: 309/527
2025-10-12 18:59:44.0268 - INFO - graphrag.logger.progress - extract graph progress: 310/527
2025-10-12 18:59:44.0272 - INFO - graphrag.logger.progress - extract graph progress: 311/527
2025-10-12 18:59:44.0276 - INFO - graphrag.logger.progress - extract graph progress: 312/527
2025-10-12 18:59:44.0279 - INFO - graphrag.logger.progress - extract graph progress: 313/527
2025-10-12 18:59:44.0283 - INFO - graphrag.logger.progress - extract graph progress: 314/527
2025-10-12 18:59:44.0285 - INFO - graphrag.logger.progress - extract graph progress: 315/527
2025-10-12 18:59:44.0286 - INFO - graphrag.logger.progress - extract graph progress: 316/527
2025-10-12 18:59:44.0288 - INFO - graphrag.logger.progress - extract graph progress: 317/527
2025-10-12 18:59:44.0292 - INFO - graphrag.logger.progress - extract graph progress: 318/527
2025-10-12 18:59:44.0295 - INFO - graphrag.logger.progress - extract graph progress: 319/527
2025-10-12 18:59:44.0297 - INFO - graphrag.logger.progress - extract graph progress: 320/527
2025-10-12 18:59:44.0299 - INFO - graphrag.logger.progress - extract graph progress: 321/527
2025-10-12 18:59:44.0302 - INFO - graphrag.logger.progress - extract graph progress: 322/527
2025-10-12 18:59:44.0305 - INFO - graphrag.logger.progress - extract graph progress: 323/527
2025-10-12 18:59:44.0306 - INFO - graphrag.logger.progress - extract graph progress: 324/527
2025-10-12 18:59:44.0309 - INFO - graphrag.logger.progress - extract graph progress: 325/527
2025-10-12 18:59:44.0314 - INFO - graphrag.logger.progress - extract graph progress: 326/527
2025-10-12 18:59:44.0317 - INFO - graphrag.logger.progress - extract graph progress: 327/527
2025-10-12 18:59:44.0321 - INFO - graphrag.logger.progress - extract graph progress: 328/527
2025-10-12 18:59:44.0323 - INFO - graphrag.logger.progress - extract graph progress: 329/527
2025-10-12 18:59:44.0325 - INFO - graphrag.logger.progress - extract graph progress: 330/527
2025-10-12 18:59:44.0326 - INFO - graphrag.logger.progress - extract graph progress: 331/527
2025-10-12 18:59:44.0329 - INFO - graphrag.logger.progress - extract graph progress: 332/527
2025-10-12 18:59:44.0332 - INFO - graphrag.logger.progress - extract graph progress: 333/527
2025-10-12 18:59:44.0335 - INFO - graphrag.logger.progress - extract graph progress: 334/527
2025-10-12 18:59:44.0337 - INFO - graphrag.logger.progress - extract graph progress: 335/527
2025-10-12 18:59:44.0338 - INFO - graphrag.logger.progress - extract graph progress: 336/527
2025-10-12 18:59:44.0340 - INFO - graphrag.logger.progress - extract graph progress: 337/527
2025-10-12 18:59:44.0344 - INFO - graphrag.logger.progress - extract graph progress: 338/527
2025-10-12 18:59:44.0346 - INFO - graphrag.logger.progress - extract graph progress: 339/527
2025-10-12 18:59:44.0348 - INFO - graphrag.logger.progress - extract graph progress: 340/527
2025-10-12 18:59:53.0553 - INFO - graphrag.logger.progress - extract graph progress: 341/527
2025-10-12 18:59:53.0558 - INFO - graphrag.logger.progress - extract graph progress: 342/527
2025-10-12 18:59:53.0561 - INFO - graphrag.logger.progress - extract graph progress: 343/527
2025-10-12 18:59:53.0565 - INFO - graphrag.logger.progress - extract graph progress: 344/527
2025-10-12 18:59:53.0569 - INFO - graphrag.logger.progress - extract graph progress: 345/527
2025-10-12 18:59:53.0572 - INFO - graphrag.logger.progress - extract graph progress: 346/527
2025-10-12 18:59:53.0576 - INFO - graphrag.logger.progress - extract graph progress: 347/527
2025-10-12 18:59:53.0580 - INFO - graphrag.logger.progress - extract graph progress: 348/527
2025-10-12 18:59:53.0583 - INFO - graphrag.logger.progress - extract graph progress: 349/527
2025-10-12 18:59:53.0587 - INFO - graphrag.logger.progress - extract graph progress: 350/527
2025-10-12 18:59:53.0590 - INFO - graphrag.logger.progress - extract graph progress: 351/527
2025-10-12 18:59:53.0594 - INFO - graphrag.logger.progress - extract graph progress: 352/527
2025-10-12 18:59:53.0598 - INFO - graphrag.logger.progress - extract graph progress: 353/527
2025-10-12 18:59:53.0601 - INFO - graphrag.logger.progress - extract graph progress: 354/527
2025-10-12 18:59:53.0605 - INFO - graphrag.logger.progress - extract graph progress: 355/527
2025-10-12 18:59:53.0609 - INFO - graphrag.logger.progress - extract graph progress: 356/527
2025-10-12 18:59:53.0612 - INFO - graphrag.logger.progress - extract graph progress: 357/527
2025-10-12 18:59:53.0617 - INFO - graphrag.logger.progress - extract graph progress: 358/527
2025-10-12 18:59:53.0620 - INFO - graphrag.logger.progress - extract graph progress: 359/527
2025-10-12 18:59:53.0624 - INFO - graphrag.logger.progress - extract graph progress: 360/527
2025-10-12 18:59:53.0628 - INFO - graphrag.logger.progress - extract graph progress: 361/527
2025-10-12 18:59:53.0631 - INFO - graphrag.logger.progress - extract graph progress: 362/527
2025-10-12 18:59:53.0635 - INFO - graphrag.logger.progress - extract graph progress: 363/527
2025-10-12 18:59:53.0639 - INFO - graphrag.logger.progress - extract graph progress: 364/527
2025-10-12 18:59:53.0642 - INFO - graphrag.logger.progress - extract graph progress: 365/527
2025-10-12 18:59:53.0646 - INFO - graphrag.logger.progress - extract graph progress: 366/527
2025-10-12 18:59:53.0650 - INFO - graphrag.logger.progress - extract graph progress: 367/527
2025-10-12 18:59:53.0653 - INFO - graphrag.logger.progress - extract graph progress: 368/527
2025-10-12 18:59:53.0657 - INFO - graphrag.logger.progress - extract graph progress: 369/527
2025-10-12 18:59:53.0661 - INFO - graphrag.logger.progress - extract graph progress: 370/527
2025-10-12 18:59:53.0664 - INFO - graphrag.logger.progress - extract graph progress: 371/527
2025-10-12 18:59:53.0668 - INFO - graphrag.logger.progress - extract graph progress: 372/527
2025-10-12 18:59:53.0671 - INFO - graphrag.logger.progress - extract graph progress: 373/527
2025-10-12 18:59:53.0675 - INFO - graphrag.logger.progress - extract graph progress: 374/527
2025-10-12 18:59:53.0679 - INFO - graphrag.logger.progress - extract graph progress: 375/527
2025-10-12 18:59:53.0682 - INFO - graphrag.logger.progress - extract graph progress: 376/527
2025-10-12 18:59:53.0686 - INFO - graphrag.logger.progress - extract graph progress: 377/527
2025-10-12 18:59:53.0690 - INFO - graphrag.logger.progress - extract graph progress: 378/527
2025-10-12 18:59:53.0693 - INFO - graphrag.logger.progress - extract graph progress: 379/527
2025-10-12 18:59:53.0697 - INFO - graphrag.logger.progress - extract graph progress: 380/527
2025-10-12 18:59:53.0701 - INFO - graphrag.logger.progress - extract graph progress: 381/527
2025-10-12 18:59:53.0704 - INFO - graphrag.logger.progress - extract graph progress: 382/527
2025-10-12 18:59:53.0708 - INFO - graphrag.logger.progress - extract graph progress: 383/527
2025-10-12 18:59:53.0712 - INFO - graphrag.logger.progress - extract graph progress: 384/527
2025-10-12 18:59:58.0970 - INFO - graphrag.logger.progress - extract graph progress: 385/527
2025-10-12 18:59:58.0975 - INFO - graphrag.logger.progress - extract graph progress: 386/527
2025-10-12 18:59:58.0980 - INFO - graphrag.logger.progress - extract graph progress: 387/527
2025-10-12 18:59:58.0982 - INFO - graphrag.logger.progress - extract graph progress: 388/527
2025-10-12 18:59:58.0983 - INFO - graphrag.logger.progress - extract graph progress: 389/527
2025-10-12 18:59:58.0985 - INFO - graphrag.logger.progress - extract graph progress: 390/527
2025-10-12 19:00:08.0668 - INFO - graphrag.logger.progress - extract graph progress: 391/527
2025-10-12 19:00:08.0670 - INFO - graphrag.logger.progress - extract graph progress: 392/527
2025-10-12 19:00:08.0672 - INFO - graphrag.logger.progress - extract graph progress: 393/527
2025-10-12 19:00:08.0675 - INFO - graphrag.logger.progress - extract graph progress: 394/527
2025-10-12 19:00:08.0676 - INFO - graphrag.logger.progress - extract graph progress: 395/527
2025-10-12 19:00:08.0678 - INFO - graphrag.logger.progress - extract graph progress: 396/527
2025-10-12 19:00:08.0680 - INFO - graphrag.logger.progress - extract graph progress: 397/527
2025-10-12 19:00:08.0682 - INFO - graphrag.logger.progress - extract graph progress: 398/527
2025-10-12 19:00:08.0684 - INFO - graphrag.logger.progress - extract graph progress: 399/527
2025-10-12 19:00:08.0686 - INFO - graphrag.logger.progress - extract graph progress: 400/527
2025-10-12 19:00:08.0688 - INFO - graphrag.logger.progress - extract graph progress: 401/527
2025-10-12 19:00:08.0690 - INFO - graphrag.logger.progress - extract graph progress: 402/527
2025-10-12 19:00:08.0691 - INFO - graphrag.logger.progress - extract graph progress: 403/527
2025-10-12 19:00:08.0693 - INFO - graphrag.logger.progress - extract graph progress: 404/527
2025-10-12 19:00:08.0695 - INFO - graphrag.logger.progress - extract graph progress: 405/527
2025-10-12 19:00:08.0697 - INFO - graphrag.logger.progress - extract graph progress: 406/527
2025-10-12 19:00:08.0700 - INFO - graphrag.logger.progress - extract graph progress: 407/527
2025-10-12 19:00:08.0701 - INFO - graphrag.logger.progress - extract graph progress: 408/527
2025-10-12 19:00:08.0703 - INFO - graphrag.logger.progress - extract graph progress: 409/527
2025-10-12 19:00:08.0705 - INFO - graphrag.logger.progress - extract graph progress: 410/527
2025-10-12 19:00:08.0707 - INFO - graphrag.logger.progress - extract graph progress: 411/527
2025-10-12 19:00:08.0709 - INFO - graphrag.logger.progress - extract graph progress: 412/527
2025-10-12 19:00:08.0711 - INFO - graphrag.logger.progress - extract graph progress: 413/527
2025-10-12 19:00:08.0712 - INFO - graphrag.logger.progress - extract graph progress: 414/527
2025-10-12 19:00:08.0714 - INFO - graphrag.logger.progress - extract graph progress: 415/527
2025-10-12 19:00:08.0716 - INFO - graphrag.logger.progress - extract graph progress: 416/527
2025-10-12 19:00:08.0718 - INFO - graphrag.logger.progress - extract graph progress: 417/527
2025-10-12 19:00:08.0720 - INFO - graphrag.logger.progress - extract graph progress: 418/527
2025-10-12 19:00:08.0722 - INFO - graphrag.logger.progress - extract graph progress: 419/527
2025-10-12 19:00:08.0724 - INFO - graphrag.logger.progress - extract graph progress: 420/527
2025-10-12 19:00:08.0725 - INFO - graphrag.logger.progress - extract graph progress: 421/527
2025-10-12 19:00:08.0727 - INFO - graphrag.logger.progress - extract graph progress: 422/527
2025-10-12 19:00:08.0729 - INFO - graphrag.logger.progress - extract graph progress: 423/527
2025-10-12 19:00:08.0731 - INFO - graphrag.logger.progress - extract graph progress: 424/527
2025-10-12 19:00:08.0733 - INFO - graphrag.logger.progress - extract graph progress: 425/527
2025-10-12 19:00:08.0735 - INFO - graphrag.logger.progress - extract graph progress: 426/527
2025-10-12 19:00:08.0738 - INFO - graphrag.logger.progress - extract graph progress: 427/527
2025-10-12 19:00:08.0739 - INFO - graphrag.logger.progress - extract graph progress: 428/527
2025-10-12 19:00:08.0741 - INFO - graphrag.logger.progress - extract graph progress: 429/527
2025-10-12 19:00:08.0743 - INFO - graphrag.logger.progress - extract graph progress: 430/527
2025-10-12 19:00:08.0745 - INFO - graphrag.logger.progress - extract graph progress: 431/527
2025-10-12 19:00:08.0747 - INFO - graphrag.logger.progress - extract graph progress: 432/527
2025-10-12 19:00:08.0749 - INFO - graphrag.logger.progress - extract graph progress: 433/527
2025-10-12 19:00:18.0670 - INFO - graphrag.logger.progress - extract graph progress: 434/527
2025-10-12 19:00:18.0672 - INFO - graphrag.logger.progress - extract graph progress: 435/527
2025-10-12 19:00:18.0673 - INFO - graphrag.logger.progress - extract graph progress: 436/527
2025-10-12 19:00:18.0675 - INFO - graphrag.logger.progress - extract graph progress: 437/527
2025-10-12 19:00:18.0677 - INFO - graphrag.logger.progress - extract graph progress: 438/527
2025-10-12 19:00:18.0679 - INFO - graphrag.logger.progress - extract graph progress: 439/527
2025-10-12 19:00:18.0681 - INFO - graphrag.logger.progress - extract graph progress: 440/527
2025-10-12 19:00:18.0683 - INFO - graphrag.logger.progress - extract graph progress: 441/527
2025-10-12 19:00:18.0685 - INFO - graphrag.logger.progress - extract graph progress: 442/527
2025-10-12 19:00:18.0686 - INFO - graphrag.logger.progress - extract graph progress: 443/527
2025-10-12 19:00:18.0689 - INFO - graphrag.logger.progress - extract graph progress: 444/527
2025-10-12 19:00:18.0690 - INFO - graphrag.logger.progress - extract graph progress: 445/527
2025-10-12 19:00:18.0692 - INFO - graphrag.logger.progress - extract graph progress: 446/527
2025-10-12 19:00:18.0694 - INFO - graphrag.logger.progress - extract graph progress: 447/527
2025-10-12 19:00:18.0696 - INFO - graphrag.logger.progress - extract graph progress: 448/527
2025-10-12 19:00:18.0698 - INFO - graphrag.logger.progress - extract graph progress: 449/527
2025-10-12 19:00:18.0700 - INFO - graphrag.logger.progress - extract graph progress: 450/527
2025-10-12 19:00:18.0702 - INFO - graphrag.logger.progress - extract graph progress: 451/527
2025-10-12 19:00:18.0704 - INFO - graphrag.logger.progress - extract graph progress: 452/527
2025-10-12 19:00:18.0705 - INFO - graphrag.logger.progress - extract graph progress: 453/527
2025-10-12 19:00:18.0707 - INFO - graphrag.logger.progress - extract graph progress: 454/527
2025-10-12 19:00:18.0709 - INFO - graphrag.logger.progress - extract graph progress: 455/527
2025-10-12 19:00:18.0711 - INFO - graphrag.logger.progress - extract graph progress: 456/527
2025-10-12 19:00:18.0713 - INFO - graphrag.logger.progress - extract graph progress: 457/527
2025-10-12 19:00:18.0714 - INFO - graphrag.logger.progress - extract graph progress: 458/527
2025-10-12 19:00:18.0716 - INFO - graphrag.logger.progress - extract graph progress: 459/527
2025-10-12 19:00:18.0718 - INFO - graphrag.logger.progress - extract graph progress: 460/527
2025-10-12 19:00:18.0719 - INFO - graphrag.logger.progress - extract graph progress: 461/527
2025-10-12 19:00:18.0721 - INFO - graphrag.logger.progress - extract graph progress: 462/527
2025-10-12 19:00:18.0723 - INFO - graphrag.logger.progress - extract graph progress: 463/527
2025-10-12 19:00:18.0725 - INFO - graphrag.logger.progress - extract graph progress: 464/527
2025-10-12 19:00:18.0726 - INFO - graphrag.logger.progress - extract graph progress: 465/527
2025-10-12 19:00:18.0728 - INFO - graphrag.logger.progress - extract graph progress: 466/527
2025-10-12 19:00:18.0730 - INFO - graphrag.logger.progress - extract graph progress: 467/527
2025-10-12 19:00:18.0731 - INFO - graphrag.logger.progress - extract graph progress: 468/527
2025-10-12 19:00:18.0733 - INFO - graphrag.logger.progress - extract graph progress: 469/527
2025-10-12 19:00:18.0735 - INFO - graphrag.logger.progress - extract graph progress: 470/527
2025-10-12 19:00:18.0736 - INFO - graphrag.logger.progress - extract graph progress: 471/527
2025-10-12 19:00:18.0738 - INFO - graphrag.logger.progress - extract graph progress: 472/527
2025-10-12 19:00:18.0740 - INFO - graphrag.logger.progress - extract graph progress: 473/527
2025-10-12 19:00:18.0742 - INFO - graphrag.logger.progress - extract graph progress: 474/527
2025-10-12 19:00:18.0744 - INFO - graphrag.logger.progress - extract graph progress: 475/527
2025-10-12 19:00:18.0746 - INFO - graphrag.logger.progress - extract graph progress: 476/527
2025-10-12 19:00:18.0747 - INFO - graphrag.logger.progress - extract graph progress: 477/527
2025-10-12 19:00:18.0749 - INFO - graphrag.logger.progress - extract graph progress: 478/527
2025-10-12 19:00:18.0751 - INFO - graphrag.logger.progress - extract graph progress: 479/527
2025-10-12 19:00:18.0753 - INFO - graphrag.logger.progress - extract graph progress: 480/527
2025-10-12 19:00:18.0754 - INFO - graphrag.logger.progress - extract graph progress: 481/527
2025-10-12 19:00:18.0756 - INFO - graphrag.logger.progress - extract graph progress: 482/527
2025-10-12 19:00:18.0758 - INFO - graphrag.logger.progress - extract graph progress: 483/527
2025-10-12 19:00:18.0760 - INFO - graphrag.logger.progress - extract graph progress: 484/527
2025-10-12 19:00:18.0762 - INFO - graphrag.logger.progress - extract graph progress: 485/527
2025-10-12 19:00:18.0764 - INFO - graphrag.logger.progress - extract graph progress: 486/527
2025-10-12 19:00:18.0766 - INFO - graphrag.logger.progress - extract graph progress: 487/527
2025-10-12 19:00:18.0767 - INFO - graphrag.logger.progress - extract graph progress: 488/527
2025-10-12 19:00:18.0769 - INFO - graphrag.logger.progress - extract graph progress: 489/527
2025-10-12 19:00:18.0771 - INFO - graphrag.logger.progress - extract graph progress: 490/527
2025-10-12 19:00:18.0773 - INFO - graphrag.logger.progress - extract graph progress: 491/527
2025-10-12 19:00:18.0775 - INFO - graphrag.logger.progress - extract graph progress: 492/527
2025-10-12 19:00:18.0777 - INFO - graphrag.logger.progress - extract graph progress: 493/527
2025-10-12 19:00:18.0779 - INFO - graphrag.logger.progress - extract graph progress: 494/527
2025-10-12 19:00:18.0781 - INFO - graphrag.logger.progress - extract graph progress: 495/527
2025-10-12 19:00:18.0782 - INFO - graphrag.logger.progress - extract graph progress: 496/527
2025-10-12 19:00:18.0784 - INFO - graphrag.logger.progress - extract graph progress: 497/527
2025-10-12 19:00:18.0786 - INFO - graphrag.logger.progress - extract graph progress: 498/527
2025-10-12 19:00:18.0788 - INFO - graphrag.logger.progress - extract graph progress: 499/527
2025-10-12 19:00:18.0789 - INFO - graphrag.logger.progress - extract graph progress: 500/527
2025-10-12 19:00:18.0791 - INFO - graphrag.logger.progress - extract graph progress: 501/527
2025-10-12 19:00:18.0793 - INFO - graphrag.logger.progress - extract graph progress: 502/527
2025-10-12 19:00:18.0795 - INFO - graphrag.logger.progress - extract graph progress: 503/527
2025-10-12 19:00:18.0797 - INFO - graphrag.logger.progress - extract graph progress: 504/527
2025-10-12 19:00:31.0276 - INFO - graphrag.logger.progress - extract graph progress: 505/527
2025-10-12 19:00:31.0278 - INFO - graphrag.logger.progress - extract graph progress: 506/527
2025-10-12 19:00:31.0280 - INFO - graphrag.logger.progress - extract graph progress: 507/527
2025-10-12 19:00:31.0282 - INFO - graphrag.logger.progress - extract graph progress: 508/527
2025-10-12 19:00:31.0284 - INFO - graphrag.logger.progress - extract graph progress: 509/527
2025-10-12 19:00:31.0286 - INFO - graphrag.logger.progress - extract graph progress: 510/527
2025-10-12 19:00:31.0288 - INFO - graphrag.logger.progress - extract graph progress: 511/527
2025-10-12 19:00:31.0290 - INFO - graphrag.logger.progress - extract graph progress: 512/527
2025-10-12 19:00:31.0292 - INFO - graphrag.logger.progress - extract graph progress: 513/527
2025-10-12 19:00:31.0294 - INFO - graphrag.logger.progress - extract graph progress: 514/527
2025-10-12 19:00:31.0296 - INFO - graphrag.logger.progress - extract graph progress: 515/527
2025-10-12 19:00:31.0297 - INFO - graphrag.logger.progress - extract graph progress: 516/527
2025-10-12 19:00:31.0299 - INFO - graphrag.logger.progress - extract graph progress: 517/527
2025-10-12 19:00:31.0301 - INFO - graphrag.logger.progress - extract graph progress: 518/527
2025-10-12 19:00:31.0303 - INFO - graphrag.logger.progress - extract graph progress: 519/527
2025-10-12 19:00:31.0305 - INFO - graphrag.logger.progress - extract graph progress: 520/527
2025-10-12 19:00:31.0307 - INFO - graphrag.logger.progress - extract graph progress: 521/527
2025-10-12 19:00:31.0309 - INFO - graphrag.logger.progress - extract graph progress: 522/527
2025-10-12 19:00:31.0310 - INFO - graphrag.logger.progress - extract graph progress: 523/527
2025-10-12 19:00:31.0312 - INFO - graphrag.logger.progress - extract graph progress: 524/527
2025-10-12 19:00:31.0314 - INFO - graphrag.logger.progress - extract graph progress: 525/527
2025-10-12 19:00:31.0316 - INFO - graphrag.logger.progress - extract graph progress: 526/527
2025-10-12 19:00:31.0318 - INFO - graphrag.logger.progress - extract graph progress: 527/527
2025-10-12 19:00:31.0382 - ERROR - graphrag.index.run.run_pipeline - error running workflow extract_graph
Traceback (most recent call last):
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/run/run_pipeline.py", line 121, in _run_pipeline
    result = await workflow_function(config, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/extract_graph.py", line 50, in run_workflow
    entities, relationships, raw_entities, raw_relationships = await extract_graph(
                                                               ^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/workflows/extract_graph.py", line 95, in extract_graph
    extracted_entities, extracted_relationships = await extractor(
                                                  ^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 79, in extract_graph
    entities = _merge_entities(entity_dfs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/graphrag/index/operations/extract_graph/extract_graph.py", line 103, in _merge_entities
    all_entities.groupby(["title", "type"], sort=False)
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/frame.py", line 9210, in groupby
    return DataFrameGroupBy(
           ^^^^^^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/groupby/groupby.py", line 1331, in __init__
    grouper, exclusions, obj = get_grouper(
                               ^^^^^^^^^^^^
  File "/home/mlk15/miniforge3/envs/graphrag_env/lib/python3.11/site-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'title'
2025-10-12 19:00:31.0440 - ERROR - graphrag.api.index - Workflow extract_graph completed with errors
2025-10-12 19:00:31.0441 - ERROR - graphrag.cli.index - Errors occurred during the pipeline run, see logs for more details.
2025-10-23 21:10:03.0956 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:06.0810 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:11.0772 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:20.0728 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:10:37.0809 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:11:10.0160 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:12:14.0655 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:14:23.0042 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:18:39.0942 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:27:12.0725 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:34:55.0953 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:34:58.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:35:03.0309 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:35:11.0852 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:35:28.0206 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:36:00.0308 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:37:05.0263 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:39:14.0275 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:43:30.0878 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:17.0594 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:17.0596 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:17.0601 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:40.0100 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:43.0125 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:48.0090 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:44:56.0499 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:45:12.0857 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:45:45.0775 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:46:50.0752 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:48:59.0030 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:52:03.0151 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:53:16.0106 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:59:50.0305 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:59:52.0600 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 21:59:57.0546 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:00:05.0613 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:00:22.0074 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:00:54.0936 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:01:59.0489 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
  2025-10-23 22:04:07.0729 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:33.0757 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:35.0872 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:40.0150 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:07:48.0471 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:08:04.0994 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/grapphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:09:08.0154 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-pacon3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:09:41.0855 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                2025-10-23 22:11:50.0251 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:16:07.0240 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:16:56.0875 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:18:53.0817 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:18:53.0821 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:18:53.0828 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:24:40.0042 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:34:01.0839 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:34:01.0845 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:34:01.0851 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:41:44.0232 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:41:44.0237 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/request_wrappers/with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-23 22:41:44.0243 - ERROR - graphrag.index.validate_config - LLM configuration error detected.
litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:22.0783 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:25.0212 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:30.0001 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:38.0785 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:47:54.0893 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:48:27.0355 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:40.0794 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:43.0615 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:48.0438 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:49:57.0187 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:50:13.0948 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:50:46.0408 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:51:51.0447 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:52:48.0084 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:52:50.0455 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:52:54.0665 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:53:03.0603 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:53:20.0591 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 12:53:53.0014 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:15:59.0589 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:02.0291 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:06.0967 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:15.0254 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:16:31.0526 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:41.0504 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:44.0557 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:49.0452 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:24:58.0137 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:25:15.0064 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:25:47.0946 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 13:26:52.0827 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 823, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 454, in make_openai_chat_completion_request
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 436, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 2603, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1794, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/openai/_base_client.py", line 1594, in request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 587, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/llms/openai/openai.py", line 870, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/services/retry/exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/graphrag/language_model/providers/litellm/chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1632, in wrapper_async
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/utils.py", line 1478, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/main.py", line 606, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2273, in exception_type
    raise e
  File "/home/gcw3/.conda/envs/graphrag_env/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 457, in exception_type
    raise AuthenticationError(
litellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: <API_KEY>. You can find your API key at https://platform.openai.com/account/api-keys.
2025-10-24 14:21:11.0952 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2025-10-24 14:21:15.0118 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2025-10-24 14:21:15.0118 - INFO - graphrag.cli.index - Starting pipeline run. False
2025-10-24 14:21:15.0119 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "/home/gcw3/technipfmc_safety/graphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "ollama",
            "model": "llama3:8b",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "ollama",
            "model": "nomic-embed-text:latest",
            "encoding_model": "",
            "api_base": "http://127.0.0.1:11434",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "/home/gcw3/technipfmc_safety/graphRAG/input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "csv",
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 600,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/home/gcw3/technipfmc_safety/graphRAG/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/home/gcw3/technipfmc_safety/graphRAG/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/home/gcw3/technipfmc_safety/graphRAG/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/home/gcw3/technipfmc_safety/graphRAG/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "INCIDENT_TYPE",
            "INJURY_TYPE",
            "BODY_PART",
            "EQUIPMENT",
            "LOCATION",
            "ORGANIZATION",
            "DATE"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2025-10-24 14:21:15.0120 - INFO - graphrag.api.index - Initializing indexing pipeline...
2025-10-24 14:21:15.0121 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2025-10-24 14:21:15.0121 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/gcw3/technipfmc_safety/graphRAG/input
2025-10-24 14:21:15.0121 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/gcw3/technipfmc_safety/graphRAG/output
2025-10-24 14:21:15.0121 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/gcw3/technipfmc_safety/graphRAG
2025-10-24 14:21:15.0121 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/gcw3/technipfmc_safety/graphRAG/cache
2025-10-24 14:21:15.0134 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2025-10-24 14:21:15.0134 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2025-10-24 14:21:15.0136 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2025-10-24 14:21:15.0137 - INFO - graphrag.index.input.factory - loading input from root_dir=/home/gcw3/technipfmc_safety/graphRAG/input
2025-10-24 14:21:15.0137 - INFO - graphrag.index.input.factory - Loading Input InputFileType.csv
2025-10-24 14:21:15.0137 - INFO - graphrag.index.input.csv - Loading csv files from /home/gcw3/technipfmc_safety/graphRAG/input
2025-10-24 14:21:15.0137 - INFO - graphrag.storage.file_pipeline_storage - search /home/gcw3/technipfmc_safety/graphRAG/input for files matching .*\.csv$
2025-10-24 14:21:15.0208 - WARNING - graphrag.index.input.util - text_column text not found in csv file dev_sample_json.csv
2025-10-24 14:21:15.0242 - INFO - graphrag.index.input.util - Found 2 InputFileType.csv files, loading 2
2025-10-24 14:21:15.0243 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.csv rows: 1683
2025-10-24 14:21:15.0244 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 1683
2025-10-24 14:21:15.0329 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2025-10-24 14:21:15.0353 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2025-10-24 14:21:15.0353 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-24 14:21:15.0388 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 1683 documents
2025-10-24 14:21:15.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/1683
2025-10-24 14:21:15.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  2/1683
2025-10-24 14:21:15.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  3/1683
2025-10-24 14:21:15.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  4/1683
2025-10-24 14:21:15.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  5/1683
2025-10-24 14:21:15.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  6/1683
2025-10-24 14:21:15.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  7/1683
2025-10-24 14:21:15.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  8/1683
2025-10-24 14:21:15.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  9/1683
2025-10-24 14:21:15.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  10/1683
2025-10-24 14:21:15.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  11/1683
2025-10-24 14:21:15.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  12/1683
2025-10-24 14:21:15.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  13/1683
2025-10-24 14:21:15.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  14/1683
2025-10-24 14:21:15.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  15/1683
2025-10-24 14:21:15.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  16/1683
2025-10-24 14:21:15.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  17/1683
2025-10-24 14:21:15.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  18/1683
2025-10-24 14:21:15.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  19/1683
2025-10-24 14:21:15.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  20/1683
2025-10-24 14:21:15.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  21/1683
2025-10-24 14:21:15.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  22/1683
2025-10-24 14:21:15.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  23/1683
2025-10-24 14:21:15.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  24/1683
2025-10-24 14:21:15.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  25/1683
2025-10-24 14:21:15.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  26/1683
2025-10-24 14:21:15.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  27/1683
2025-10-24 14:21:15.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  28/1683
2025-10-24 14:21:15.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  29/1683
2025-10-24 14:21:15.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  30/1683
2025-10-24 14:21:15.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  31/1683
2025-10-24 14:21:15.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  32/1683
2025-10-24 14:21:15.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  33/1683
2025-10-24 14:21:15.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  34/1683
2025-10-24 14:21:15.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  35/1683
2025-10-24 14:21:15.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  36/1683
2025-10-24 14:21:15.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  37/1683
2025-10-24 14:21:15.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  38/1683
2025-10-24 14:21:15.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  39/1683
2025-10-24 14:21:15.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  40/1683
2025-10-24 14:21:15.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  41/1683
2025-10-24 14:21:15.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  42/1683
2025-10-24 14:21:15.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  43/1683
2025-10-24 14:21:15.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  44/1683
2025-10-24 14:21:15.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  45/1683
2025-10-24 14:21:15.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  46/1683
2025-10-24 14:21:15.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  47/1683
2025-10-24 14:21:15.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  48/1683
2025-10-24 14:21:15.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  49/1683
2025-10-24 14:21:15.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  50/1683
2025-10-24 14:21:15.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  51/1683
2025-10-24 14:21:15.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  52/1683
2025-10-24 14:21:15.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  53/1683
2025-10-24 14:21:15.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  54/1683
2025-10-24 14:21:15.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  55/1683
2025-10-24 14:21:15.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  56/1683
2025-10-24 14:21:15.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  57/1683
2025-10-24 14:21:15.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  58/1683
2025-10-24 14:21:15.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  59/1683
2025-10-24 14:21:15.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  60/1683
2025-10-24 14:21:15.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  61/1683
2025-10-24 14:21:15.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  62/1683
2025-10-24 14:21:15.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  63/1683
2025-10-24 14:21:15.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  64/1683
2025-10-24 14:21:15.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  65/1683
2025-10-24 14:21:15.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  66/1683
2025-10-24 14:21:15.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  67/1683
2025-10-24 14:21:15.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  68/1683
2025-10-24 14:21:15.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  69/1683
2025-10-24 14:21:15.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  70/1683
2025-10-24 14:21:15.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  71/1683
2025-10-24 14:21:15.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  72/1683
2025-10-24 14:21:15.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  73/1683
2025-10-24 14:21:15.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  74/1683
2025-10-24 14:21:15.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  75/1683
2025-10-24 14:21:15.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  76/1683
2025-10-24 14:21:15.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  77/1683
2025-10-24 14:21:15.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  78/1683
2025-10-24 14:21:15.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  79/1683
2025-10-24 14:21:15.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  80/1683
2025-10-24 14:21:15.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  81/1683
2025-10-24 14:21:15.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  82/1683
2025-10-24 14:21:15.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  83/1683
2025-10-24 14:21:15.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  84/1683
2025-10-24 14:21:15.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  85/1683
2025-10-24 14:21:15.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  86/1683
2025-10-24 14:21:15.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  87/1683
2025-10-24 14:21:15.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  88/1683
2025-10-24 14:21:15.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  89/1683
2025-10-24 14:21:15.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  90/1683
2025-10-24 14:21:15.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  91/1683
2025-10-24 14:21:15.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  92/1683
2025-10-24 14:21:15.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  93/1683
2025-10-24 14:21:15.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  94/1683
2025-10-24 14:21:15.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  95/1683
2025-10-24 14:21:15.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  96/1683
2025-10-24 14:21:15.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  97/1683
2025-10-24 14:21:15.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  98/1683
2025-10-24 14:21:15.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  99/1683
2025-10-24 14:21:15.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  100/1683
2025-10-24 14:21:15.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  101/1683
2025-10-24 14:21:15.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  102/1683
2025-10-24 14:21:15.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  103/1683
2025-10-24 14:21:15.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  104/1683
2025-10-24 14:21:15.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  105/1683
2025-10-24 14:21:15.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  106/1683
2025-10-24 14:21:15.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  107/1683
2025-10-24 14:21:15.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  108/1683
2025-10-24 14:21:15.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  109/1683
2025-10-24 14:21:15.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  110/1683
2025-10-24 14:21:15.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  111/1683
2025-10-24 14:21:15.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  112/1683
2025-10-24 14:21:15.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  113/1683
2025-10-24 14:21:15.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  114/1683
2025-10-24 14:21:15.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  115/1683
2025-10-24 14:21:15.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  116/1683
2025-10-24 14:21:15.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  117/1683
2025-10-24 14:21:15.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  118/1683
2025-10-24 14:21:15.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  119/1683
2025-10-24 14:21:15.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  120/1683
2025-10-24 14:21:15.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  121/1683
2025-10-24 14:21:15.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  122/1683
2025-10-24 14:21:15.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  123/1683
2025-10-24 14:21:15.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  124/1683
2025-10-24 14:21:15.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  125/1683
2025-10-24 14:21:15.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  126/1683
2025-10-24 14:21:15.0479 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  127/1683
2025-10-24 14:21:15.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  128/1683
2025-10-24 14:21:15.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  129/1683
2025-10-24 14:21:15.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  130/1683
2025-10-24 14:21:15.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  131/1683
2025-10-24 14:21:15.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  132/1683
2025-10-24 14:21:15.0483 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  133/1683
2025-10-24 14:21:15.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  134/1683
2025-10-24 14:21:15.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  135/1683
2025-10-24 14:21:15.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  136/1683
2025-10-24 14:21:15.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  137/1683
2025-10-24 14:21:15.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  138/1683
2025-10-24 14:21:15.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  139/1683
2025-10-24 14:21:15.0488 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  140/1683
2025-10-24 14:21:15.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  141/1683
2025-10-24 14:21:15.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  142/1683
2025-10-24 14:21:15.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  143/1683
2025-10-24 14:21:15.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  144/1683
2025-10-24 14:21:15.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  145/1683
2025-10-24 14:21:15.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  146/1683
2025-10-24 14:21:15.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  147/1683
2025-10-24 14:21:15.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  148/1683
2025-10-24 14:21:15.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  149/1683
2025-10-24 14:21:15.0495 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  150/1683
2025-10-24 14:21:15.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  151/1683
2025-10-24 14:21:15.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  152/1683
2025-10-24 14:21:15.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  153/1683
2025-10-24 14:21:15.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  154/1683
2025-10-24 14:21:15.0498 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  155/1683
2025-10-24 14:21:15.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  156/1683
2025-10-24 14:21:15.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  157/1683
2025-10-24 14:21:15.0500 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  158/1683
2025-10-24 14:21:15.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  159/1683
2025-10-24 14:21:15.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  160/1683
2025-10-24 14:21:15.0502 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  161/1683
2025-10-24 14:21:15.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  162/1683
2025-10-24 14:21:15.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  163/1683
2025-10-24 14:21:15.0504 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  164/1683
2025-10-24 14:21:15.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  165/1683
2025-10-24 14:21:15.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  166/1683
2025-10-24 14:21:15.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  167/1683
2025-10-24 14:21:15.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  168/1683
2025-10-24 14:21:15.0507 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  169/1683
2025-10-24 14:21:15.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  170/1683
2025-10-24 14:21:15.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  171/1683
2025-10-24 14:21:15.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  172/1683
2025-10-24 14:21:15.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  173/1683
2025-10-24 14:21:15.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  174/1683
2025-10-24 14:21:15.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  175/1683
2025-10-24 14:21:15.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  176/1683
2025-10-24 14:21:15.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  177/1683
2025-10-24 14:21:15.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  178/1683
2025-10-24 14:21:15.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  179/1683
2025-10-24 14:21:15.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  180/1683
2025-10-24 14:21:15.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  181/1683
2025-10-24 14:21:15.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  182/1683
2025-10-24 14:21:15.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  183/1683
2025-10-24 14:21:15.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  184/1683
2025-10-24 14:21:15.0517 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  185/1683
2025-10-24 14:21:15.0518 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  186/1683
2025-10-24 14:21:15.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  187/1683
2025-10-24 14:21:15.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  188/1683
2025-10-24 14:21:15.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  189/1683
2025-10-24 14:21:15.0521 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  190/1683
2025-10-24 14:21:15.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  191/1683
2025-10-24 14:21:15.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  192/1683
2025-10-24 14:21:15.0523 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  193/1683
2025-10-24 14:21:15.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  194/1683
2025-10-24 14:21:15.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  195/1683
2025-10-24 14:21:15.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  196/1683
2025-10-24 14:21:15.0526 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  197/1683
2025-10-24 14:21:15.0526 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  198/1683
2025-10-24 14:21:15.0527 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  199/1683
2025-10-24 14:21:15.0528 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  200/1683
2025-10-24 14:21:15.0528 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  201/1683
2025-10-24 14:21:15.0529 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  202/1683
2025-10-24 14:21:15.0529 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  203/1683
2025-10-24 14:21:15.0530 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  204/1683
2025-10-24 14:21:15.0531 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  205/1683
2025-10-24 14:21:15.0532 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  206/1683
2025-10-24 14:21:15.0533 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  207/1683
2025-10-24 14:21:15.0533 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  208/1683
2025-10-24 14:21:15.0534 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  209/1683
2025-10-24 14:21:15.0535 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  210/1683
2025-10-24 14:21:15.0535 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  211/1683
2025-10-24 14:21:15.0536 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  212/1683
2025-10-24 14:21:15.0537 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  213/1683
2025-10-24 14:21:15.0537 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  214/1683
2025-10-24 14:21:15.0538 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  215/1683
2025-10-24 14:21:15.0539 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  216/1683
2025-10-24 14:21:15.0540 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  217/1683
2025-10-24 14:21:15.0540 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  218/1683
2025-10-24 14:21:15.0541 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  219/1683
2025-10-24 14:21:15.0541 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  220/1683
2025-10-24 14:21:15.0542 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  221/1683
2025-10-24 14:21:15.0542 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  222/1683
2025-10-24 14:21:15.0543 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  223/1683
2025-10-24 14:21:15.0544 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  224/1683
2025-10-24 14:21:15.0545 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  225/1683
2025-10-24 14:21:15.0545 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  226/1683
2025-10-24 14:21:15.0546 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  227/1683
2025-10-24 14:21:15.0547 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  228/1683
2025-10-24 14:21:15.0547 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  229/1683
2025-10-24 14:21:15.0548 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  230/1683
2025-10-24 14:21:15.0549 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  231/1683
2025-10-24 14:21:15.0550 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  232/1683
2025-10-24 14:21:15.0550 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  233/1683
2025-10-24 14:21:15.0551 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  234/1683
2025-10-24 14:21:15.0552 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  235/1683
2025-10-24 14:21:15.0553 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  236/1683
2025-10-24 14:21:15.0553 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  237/1683
2025-10-24 14:21:15.0554 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  238/1683
2025-10-24 14:21:15.0555 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  239/1683
2025-10-24 14:21:15.0555 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  240/1683
2025-10-24 14:21:15.0556 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  241/1683
2025-10-24 14:21:15.0557 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  242/1683
2025-10-24 14:21:15.0558 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  243/1683
2025-10-24 14:21:15.0558 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  244/1683
2025-10-24 14:21:15.0559 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  245/1683
2025-10-24 14:21:15.0559 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  246/1683
2025-10-24 14:21:15.0560 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  247/1683
2025-10-24 14:21:15.0561 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  248/1683
2025-10-24 14:21:15.0561 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  249/1683
2025-10-24 14:21:15.0562 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  250/1683
2025-10-24 14:21:15.0563 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  251/1683
2025-10-24 14:21:15.0563 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  252/1683
2025-10-24 14:21:15.0564 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  253/1683
2025-10-24 14:21:15.0565 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  254/1683
2025-10-24 14:21:15.0565 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  255/1683
2025-10-24 14:21:15.0566 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  256/1683
2025-10-24 14:21:15.0567 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  257/1683
2025-10-24 14:21:15.0568 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  258/1683
2025-10-24 14:21:15.0569 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  259/1683
2025-10-24 14:21:15.0569 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  260/1683
2025-10-24 14:21:15.0570 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  261/1683
2025-10-24 14:21:15.0571 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  262/1683
2025-10-24 14:21:15.0571 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  263/1683
2025-10-24 14:21:15.0572 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  264/1683
2025-10-24 14:21:15.0573 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  265/1683
2025-10-24 14:21:15.0573 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  266/1683
2025-10-24 14:21:15.0574 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  267/1683
2025-10-24 14:21:15.0575 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  268/1683
2025-10-24 14:21:15.0575 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  269/1683
2025-10-24 14:21:15.0576 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  270/1683
2025-10-24 14:21:15.0576 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  271/1683
2025-10-24 14:21:15.0577 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  272/1683
2025-10-24 14:21:15.0578 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  273/1683
2025-10-24 14:21:15.0578 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  274/1683
2025-10-24 14:21:15.0579 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  275/1683
2025-10-24 14:21:15.0579 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  276/1683
2025-10-24 14:21:15.0580 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  277/1683
2025-10-24 14:21:15.0581 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  278/1683
2025-10-24 14:21:15.0581 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  279/1683
2025-10-24 14:21:15.0582 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  280/1683
2025-10-24 14:21:15.0583 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  281/1683
2025-10-24 14:21:15.0583 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  282/1683
2025-10-24 14:21:15.0584 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  283/1683
2025-10-24 14:21:15.0585 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  284/1683
2025-10-24 14:21:15.0585 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  285/1683
2025-10-24 14:21:15.0586 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  286/1683
2025-10-24 14:21:15.0587 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  287/1683
2025-10-24 14:21:15.0587 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  288/1683
2025-10-24 14:21:15.0588 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  289/1683
2025-10-24 14:21:15.0589 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  290/1683
2025-10-24 14:21:15.0589 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  291/1683
2025-10-24 14:21:15.0590 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  292/1683
2025-10-24 14:21:15.0591 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  293/1683
2025-10-24 14:21:15.0591 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  294/1683
2025-10-24 14:21:15.0592 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  295/1683
2025-10-24 14:21:15.0593 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  296/1683
2025-10-24 14:21:15.0594 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  297/1683
2025-10-24 14:21:15.0594 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  298/1683
2025-10-24 14:21:15.0595 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  299/1683
2025-10-24 14:21:15.0596 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  300/1683
2025-10-24 14:21:15.0596 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  301/1683
2025-10-24 14:21:15.0597 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  302/1683
2025-10-24 14:21:15.0598 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  303/1683
2025-10-24 14:21:15.0598 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  304/1683
2025-10-24 14:21:15.0599 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  305/1683
2025-10-24 14:21:15.0599 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  306/1683
2025-10-24 14:21:15.0600 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  307/1683
2025-10-24 14:21:15.0601 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  308/1683
2025-10-24 14:21:15.0601 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  309/1683
2025-10-24 14:21:15.0602 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  310/1683
2025-10-24 14:21:15.0603 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  311/1683
2025-10-24 14:21:15.0603 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  312/1683
2025-10-24 14:21:15.0604 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  313/1683
2025-10-24 14:21:15.0605 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  314/1683
2025-10-24 14:21:15.0606 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  315/1683
2025-10-24 14:21:15.0607 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  316/1683
2025-10-24 14:21:15.0608 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  317/1683
2025-10-24 14:21:15.0608 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  318/1683
2025-10-24 14:21:15.0609 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  319/1683
2025-10-24 14:21:15.0610 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  320/1683
2025-10-24 14:21:15.0610 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  321/1683
2025-10-24 14:21:15.0611 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  322/1683
2025-10-24 14:21:15.0612 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  323/1683
2025-10-24 14:21:15.0612 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  324/1683
2025-10-24 14:21:15.0613 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  325/1683
2025-10-24 14:21:15.0614 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  326/1683
2025-10-24 14:21:15.0615 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  327/1683
2025-10-24 14:21:15.0615 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  328/1683
2025-10-24 14:21:15.0616 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  329/1683
2025-10-24 14:21:15.0617 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  330/1683
2025-10-24 14:21:15.0617 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  331/1683
2025-10-24 14:21:15.0618 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  332/1683
2025-10-24 14:21:15.0619 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  333/1683
2025-10-24 14:21:15.0620 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  334/1683
2025-10-24 14:21:15.0620 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  335/1683
2025-10-24 14:21:15.0621 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  336/1683
2025-10-24 14:21:15.0622 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  337/1683
2025-10-24 14:21:15.0622 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  338/1683
2025-10-24 14:21:15.0623 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  339/1683
2025-10-24 14:21:15.0624 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  340/1683
2025-10-24 14:21:15.0624 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  341/1683
2025-10-24 14:21:15.0625 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  342/1683
2025-10-24 14:21:15.0626 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  343/1683
2025-10-24 14:21:15.0626 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  344/1683
2025-10-24 14:21:15.0627 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  345/1683
2025-10-24 14:21:15.0627 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  346/1683
2025-10-24 14:21:15.0628 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  347/1683
2025-10-24 14:21:15.0628 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  348/1683
2025-10-24 14:21:15.0629 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  349/1683
2025-10-24 14:21:15.0630 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  350/1683
2025-10-24 14:21:15.0631 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  351/1683
2025-10-24 14:21:15.0631 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  352/1683
2025-10-24 14:21:15.0632 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  353/1683
2025-10-24 14:21:15.0632 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  354/1683
2025-10-24 14:21:15.0633 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  355/1683
2025-10-24 14:21:15.0633 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  356/1683
2025-10-24 14:21:15.0634 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  357/1683
2025-10-24 14:21:15.0635 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  358/1683
2025-10-24 14:21:15.0636 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  359/1683
2025-10-24 14:21:15.0636 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  360/1683
2025-10-24 14:21:15.0637 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  361/1683
2025-10-24 14:21:15.0637 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  362/1683
2025-10-24 14:21:15.0638 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  363/1683
2025-10-24 14:21:15.0639 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  364/1683
2025-10-24 14:21:15.0640 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  365/1683
2025-10-24 14:21:15.0641 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  366/1683
2025-10-24 14:21:15.0641 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  367/1683
2025-10-24 14:21:15.0642 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  368/1683
2025-10-24 14:21:15.0643 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  369/1683
2025-10-24 14:21:15.0643 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  370/1683
2025-10-24 14:21:15.0644 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  371/1683
2025-10-24 14:21:15.0645 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  372/1683
2025-10-24 14:21:15.0646 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  373/1683
2025-10-24 14:21:15.0646 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  374/1683
2025-10-24 14:21:15.0647 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  375/1683
2025-10-24 14:21:15.0648 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  376/1683
2025-10-24 14:21:15.0649 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  377/1683
2025-10-24 14:21:15.0649 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  378/1683
2025-10-24 14:21:15.0650 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  379/1683
2025-10-24 14:21:15.0651 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  380/1683
2025-10-24 14:21:15.0651 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  381/1683
2025-10-24 14:21:15.0652 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  382/1683
2025-10-24 14:21:15.0652 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  383/1683
2025-10-24 14:21:15.0653 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  384/1683
2025-10-24 14:21:15.0654 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  385/1683
2025-10-24 14:21:15.0655 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  386/1683
2025-10-24 14:21:15.0655 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  387/1683
2025-10-24 14:21:15.0656 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  388/1683
2025-10-24 14:21:15.0656 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  389/1683
2025-10-24 14:21:15.0658 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  390/1683
2025-10-24 14:21:15.0658 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  391/1683
2025-10-24 14:21:15.0659 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  392/1683
2025-10-24 14:21:15.0660 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  393/1683
2025-10-24 14:21:15.0660 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  394/1683
2025-10-24 14:21:15.0661 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  395/1683
2025-10-24 14:21:15.0662 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  396/1683
2025-10-24 14:21:15.0662 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  397/1683
2025-10-24 14:21:15.0663 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  398/1683
2025-10-24 14:21:15.0663 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  399/1683
2025-10-24 14:21:15.0664 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  400/1683
2025-10-24 14:21:15.0664 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  401/1683
2025-10-24 14:21:15.0665 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  402/1683
2025-10-24 14:21:15.0665 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  403/1683
2025-10-24 14:21:15.0666 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  404/1683
2025-10-24 14:21:15.0667 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  405/1683
2025-10-24 14:21:15.0668 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  406/1683
2025-10-24 14:21:15.0668 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  407/1683
2025-10-24 14:21:15.0669 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  408/1683
2025-10-24 14:21:15.0670 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  409/1683
2025-10-24 14:21:15.0670 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  410/1683
2025-10-24 14:21:15.0671 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  411/1683
2025-10-24 14:21:15.0672 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  412/1683
2025-10-24 14:21:15.0673 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  413/1683
2025-10-24 14:21:15.0673 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  414/1683
2025-10-24 14:21:15.0674 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  415/1683
2025-10-24 14:21:15.0674 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  416/1683
2025-10-24 14:21:15.0675 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  417/1683
2025-10-24 14:21:15.0676 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  418/1683
2025-10-24 14:21:15.0677 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  419/1683
2025-10-24 14:21:15.0678 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  420/1683
2025-10-24 14:21:15.0678 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  421/1683
2025-10-24 14:21:15.0679 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  422/1683
2025-10-24 14:21:15.0679 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  423/1683
2025-10-24 14:21:15.0680 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  424/1683
2025-10-24 14:21:15.0681 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  425/1683
2025-10-24 14:21:15.0682 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  426/1683
2025-10-24 14:21:15.0682 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  427/1683
2025-10-24 14:21:15.0683 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  428/1683
2025-10-24 14:21:15.0684 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  429/1683
2025-10-24 14:21:15.0684 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  430/1683
2025-10-24 14:21:15.0685 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  431/1683
2025-10-24 14:21:15.0686 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  432/1683
2025-10-24 14:21:15.0686 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  433/1683
2025-10-24 14:21:15.0687 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  434/1683
2025-10-24 14:21:15.0688 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  435/1683
2025-10-24 14:21:15.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  436/1683
2025-10-24 14:21:15.0689 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  437/1683
2025-10-24 14:21:15.0690 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  438/1683
2025-10-24 14:21:15.0691 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  439/1683
2025-10-24 14:21:15.0691 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  440/1683
2025-10-24 14:21:15.0692 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  441/1683
2025-10-24 14:21:15.0693 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  442/1683
2025-10-24 14:21:15.0693 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  443/1683
2025-10-24 14:21:15.0694 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  444/1683
2025-10-24 14:21:15.0694 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  445/1683
2025-10-24 14:21:15.0695 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  446/1683
2025-10-24 14:21:15.0696 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  447/1683
2025-10-24 14:21:15.0697 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  448/1683
2025-10-24 14:21:15.0697 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  449/1683
2025-10-24 14:21:15.0698 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  450/1683
2025-10-24 14:21:15.0699 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  451/1683
2025-10-24 14:21:15.0699 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  452/1683
2025-10-24 14:21:15.0700 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  453/1683
2025-10-24 14:21:15.0701 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  454/1683
2025-10-24 14:21:15.0701 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  455/1683
2025-10-24 14:21:15.0702 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  456/1683
2025-10-24 14:21:15.0703 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  457/1683
2025-10-24 14:21:15.0703 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  458/1683
2025-10-24 14:21:15.0704 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  459/1683
2025-10-24 14:21:15.0704 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  460/1683
2025-10-24 14:21:15.0705 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  461/1683
2025-10-24 14:21:15.0706 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  462/1683
2025-10-24 14:21:15.0707 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  463/1683
2025-10-24 14:21:15.0707 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  464/1683
2025-10-24 14:21:15.0708 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  465/1683
2025-10-24 14:21:15.0709 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  466/1683
2025-10-24 14:21:15.0709 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  467/1683
2025-10-24 14:21:15.0710 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  468/1683
2025-10-24 14:21:15.0711 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  469/1683
2025-10-24 14:21:15.0711 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  470/1683
2025-10-24 14:21:15.0712 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  471/1683
2025-10-24 14:21:15.0713 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  472/1683
2025-10-24 14:21:15.0714 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  473/1683
2025-10-24 14:21:15.0714 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  474/1683
2025-10-24 14:21:15.0715 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  475/1683
2025-10-24 14:21:15.0716 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  476/1683
2025-10-24 14:21:15.0717 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  477/1683
2025-10-24 14:21:15.0718 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  478/1683
2025-10-24 14:21:15.0719 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  479/1683
2025-10-24 14:21:15.0719 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  480/1683
2025-10-24 14:21:15.0720 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  481/1683
2025-10-24 14:21:15.0721 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  482/1683
2025-10-24 14:21:15.0721 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  483/1683
2025-10-24 14:21:15.0722 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  484/1683
2025-10-24 14:21:15.0723 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  485/1683
2025-10-24 14:21:15.0724 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  486/1683
2025-10-24 14:21:15.0724 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  487/1683
2025-10-24 14:21:15.0725 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  488/1683
2025-10-24 14:21:15.0726 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  489/1683
2025-10-24 14:21:15.0726 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  490/1683
2025-10-24 14:21:15.0727 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  491/1683
2025-10-24 14:21:15.0728 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  492/1683
2025-10-24 14:21:15.0729 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  493/1683
2025-10-24 14:21:15.0729 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  494/1683
2025-10-24 14:21:15.0730 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  495/1683
2025-10-24 14:21:15.0730 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  496/1683
2025-10-24 14:21:15.0731 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  497/1683
2025-10-24 14:21:15.0732 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  498/1683
2025-10-24 14:21:15.0732 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  499/1683
2025-10-24 14:21:15.0733 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  500/1683
2025-10-24 14:21:15.0734 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  501/1683
2025-10-24 14:21:15.0735 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  502/1683
2025-10-24 14:21:15.0736 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  503/1683
2025-10-24 14:21:15.0736 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  504/1683
2025-10-24 14:21:15.0737 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  505/1683
2025-10-24 14:21:15.0738 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  506/1683
2025-10-24 14:21:15.0739 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  507/1683
2025-10-24 14:21:15.0739 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  508/1683
2025-10-24 14:21:15.0740 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  509/1683
2025-10-24 14:21:15.0741 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  510/1683
2025-10-24 14:21:15.0741 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  511/1683
2025-10-24 14:21:15.0742 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  512/1683
2025-10-24 14:21:15.0743 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  513/1683
2025-10-24 14:21:15.0744 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  514/1683
2025-10-24 14:21:15.0744 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  515/1683
2025-10-24 14:21:15.0745 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  516/1683
2025-10-24 14:21:15.0746 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  517/1683
2025-10-24 14:21:15.0746 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  518/1683
2025-10-24 14:21:15.0747 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  519/1683
2025-10-24 14:21:15.0747 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  520/1683
2025-10-24 14:21:15.0748 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  521/1683
2025-10-24 14:21:15.0749 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  522/1683
2025-10-24 14:21:15.0749 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  523/1683
2025-10-24 14:21:15.0750 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  524/1683
2025-10-24 14:21:15.0751 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  525/1683
2025-10-24 14:21:15.0751 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  526/1683
2025-10-24 14:21:15.0752 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  527/1683
2025-10-24 14:21:15.0753 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  528/1683
2025-10-24 14:21:15.0754 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  529/1683
2025-10-24 14:21:15.0754 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  530/1683
2025-10-24 14:21:15.0755 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  531/1683
2025-10-24 14:21:15.0756 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  532/1683
2025-10-24 14:21:15.0756 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  533/1683
2025-10-24 14:21:15.0757 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  534/1683
2025-10-24 14:21:15.0758 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  535/1683
2025-10-24 14:21:15.0758 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  536/1683
2025-10-24 14:21:15.0759 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  537/1683
2025-10-24 14:21:15.0760 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  538/1683
2025-10-24 14:21:15.0760 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  539/1683
2025-10-24 14:21:15.0761 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  540/1683
2025-10-24 14:21:15.0762 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  541/1683
2025-10-24 14:21:15.0762 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  542/1683
2025-10-24 14:21:15.0763 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  543/1683
2025-10-24 14:21:15.0764 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  544/1683
2025-10-24 14:21:15.0764 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  545/1683
2025-10-24 14:21:15.0765 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  546/1683
2025-10-24 14:21:15.0765 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  547/1683
2025-10-24 14:21:15.0766 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  548/1683
2025-10-24 14:21:15.0767 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  549/1683
2025-10-24 14:21:15.0767 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  550/1683
2025-10-24 14:21:15.0768 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  551/1683
2025-10-24 14:21:15.0769 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  552/1683
2025-10-24 14:21:15.0769 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  553/1683
2025-10-24 14:21:15.0770 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  554/1683
2025-10-24 14:21:15.0770 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  555/1683
2025-10-24 14:21:15.0771 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  556/1683
2025-10-24 14:21:15.0771 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  557/1683
2025-10-24 14:21:15.0772 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  558/1683
2025-10-24 14:21:15.0773 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  559/1683
2025-10-24 14:21:15.0773 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  560/1683
2025-10-24 14:21:15.0774 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  561/1683
2025-10-24 14:21:15.0775 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  562/1683
2025-10-24 14:21:15.0775 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  563/1683
2025-10-24 14:21:15.0776 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  564/1683
2025-10-24 14:21:15.0777 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  565/1683
2025-10-24 14:21:15.0777 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  566/1683
2025-10-24 14:21:15.0778 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  567/1683
2025-10-24 14:21:15.0778 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  568/1683
2025-10-24 14:21:15.0779 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  569/1683
2025-10-24 14:21:15.0780 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  570/1683
2025-10-24 14:21:15.0781 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  571/1683
2025-10-24 14:21:15.0781 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  572/1683
2025-10-24 14:21:15.0782 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  573/1683
2025-10-24 14:21:15.0782 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  574/1683
2025-10-24 14:21:15.0783 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  575/1683
2025-10-24 14:21:15.0783 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  576/1683
2025-10-24 14:21:15.0784 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  577/1683
2025-10-24 14:21:15.0785 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  578/1683
2025-10-24 14:21:15.0785 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  579/1683
2025-10-24 14:21:15.0786 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  580/1683
2025-10-24 14:21:15.0787 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  581/1683
2025-10-24 14:21:15.0787 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  582/1683
2025-10-24 14:21:15.0788 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  583/1683
2025-10-24 14:21:15.0789 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  584/1683
2025-10-24 14:21:15.0789 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  585/1683
2025-10-24 14:21:15.0790 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  586/1683
2025-10-24 14:21:15.0790 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  587/1683
2025-10-24 14:21:15.0791 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  588/1683
2025-10-24 14:21:15.0791 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  589/1683
2025-10-24 14:21:15.0792 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  590/1683
2025-10-24 14:21:15.0793 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  591/1683
2025-10-24 14:21:15.0793 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  592/1683
2025-10-24 14:21:15.0794 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  593/1683
2025-10-24 14:21:15.0795 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  594/1683
2025-10-24 14:21:15.0796 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  595/1683
2025-10-24 14:21:15.0796 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  596/1683
2025-10-24 14:21:15.0797 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  597/1683
2025-10-24 14:21:15.0797 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  598/1683
2025-10-24 14:21:15.0798 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  599/1683
2025-10-24 14:21:15.0799 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  600/1683
2025-10-24 14:21:15.0799 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  601/1683
2025-10-24 14:21:15.0800 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  602/1683
2025-10-24 14:21:15.0800 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  603/1683
2025-10-24 14:21:15.0801 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  604/1683
2025-10-24 14:21:15.0802 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  605/1683
2025-10-24 14:21:15.0803 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  606/1683
2025-10-24 14:21:15.0803 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  607/1683
2025-10-24 14:21:15.0804 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  608/1683
2025-10-24 14:21:15.0805 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  609/1683
2025-10-24 14:21:15.0805 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  610/1683
2025-10-24 14:21:15.0806 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  611/1683
2025-10-24 14:21:15.0807 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  612/1683
2025-10-24 14:21:15.0807 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  613/1683
2025-10-24 14:21:15.0808 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  614/1683
2025-10-24 14:21:15.0808 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  615/1683
2025-10-24 14:21:15.0809 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  616/1683
2025-10-24 14:21:15.0810 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  617/1683
2025-10-24 14:21:15.0811 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  618/1683
2025-10-24 14:21:15.0812 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  619/1683
2025-10-24 14:21:15.0812 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  620/1683
2025-10-24 14:21:15.0813 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  621/1683
2025-10-24 14:21:15.0814 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  622/1683
2025-10-24 14:21:15.0815 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  623/1683
2025-10-24 14:21:15.0815 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  624/1683
2025-10-24 14:21:15.0816 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  625/1683
2025-10-24 14:21:15.0817 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  626/1683
2025-10-24 14:21:15.0817 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  627/1683
2025-10-24 14:21:15.0818 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  628/1683
2025-10-24 14:21:15.0819 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  629/1683
2025-10-24 14:21:15.0819 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  630/1683
2025-10-24 14:21:15.0820 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  631/1683
2025-10-24 14:21:15.0821 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  632/1683
2025-10-24 14:21:15.0821 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  633/1683
2025-10-24 14:21:15.0822 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  634/1683
2025-10-24 14:21:15.0823 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  635/1683
2025-10-24 14:21:15.0823 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  636/1683
2025-10-24 14:21:15.0824 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  637/1683
2025-10-24 14:21:15.0824 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  638/1683
2025-10-24 14:21:15.0825 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  639/1683
2025-10-24 14:21:15.0825 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  640/1683
2025-10-24 14:21:15.0826 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  641/1683
2025-10-24 14:21:15.0827 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  642/1683
2025-10-24 14:21:15.0827 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  643/1683
2025-10-24 14:21:15.0828 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  644/1683
2025-10-24 14:21:15.0829 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  645/1683
2025-10-24 14:21:15.0830 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  646/1683
2025-10-24 14:21:15.0830 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  647/1683
2025-10-24 14:21:15.0831 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  648/1683
2025-10-24 14:21:15.0832 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  649/1683
2025-10-24 14:21:15.0832 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  650/1683
2025-10-24 14:21:15.0833 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  651/1683
2025-10-24 14:21:15.0834 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  652/1683
2025-10-24 14:21:15.0835 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  653/1683
2025-10-24 14:21:15.0836 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  654/1683
2025-10-24 14:21:15.0836 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  655/1683
2025-10-24 14:21:15.0837 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  656/1683
2025-10-24 14:21:15.0837 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  657/1683
2025-10-24 14:21:15.0838 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  658/1683
2025-10-24 14:21:15.0839 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  659/1683
2025-10-24 14:21:15.0840 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  660/1683
2025-10-24 14:21:15.0840 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  661/1683
2025-10-24 14:21:15.0841 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  662/1683
2025-10-24 14:21:15.0842 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  663/1683
2025-10-24 14:21:15.0842 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  664/1683
2025-10-24 14:21:15.0843 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  665/1683
2025-10-24 14:21:15.0844 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  666/1683
2025-10-24 14:21:15.0845 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  667/1683
2025-10-24 14:21:15.0845 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  668/1683
2025-10-24 14:21:15.0846 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  669/1683
2025-10-24 14:21:15.0846 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  670/1683
2025-10-24 14:21:15.0847 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  671/1683
2025-10-24 14:21:15.0848 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  672/1683
2025-10-24 14:21:15.0848 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  673/1683
2025-10-24 14:21:15.0849 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  674/1683
2025-10-24 14:21:15.0850 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  675/1683
2025-10-24 14:21:15.0850 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  676/1683
2025-10-24 14:21:15.0851 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  677/1683
2025-10-24 14:21:15.0852 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  678/1683
2025-10-24 14:21:15.0853 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  679/1683
2025-10-24 14:21:15.0853 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  680/1683
2025-10-24 14:21:15.0854 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  681/1683
2025-10-24 14:21:15.0855 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  682/1683
2025-10-24 14:21:15.0855 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  683/1683
2025-10-24 14:21:15.0856 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  684/1683
2025-10-24 14:21:15.0856 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  685/1683
2025-10-24 14:21:15.0857 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  686/1683
2025-10-24 14:21:15.0858 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  687/1683
2025-10-24 14:21:15.0859 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  688/1683
2025-10-24 14:21:15.0859 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  689/1683
2025-10-24 14:21:15.0860 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  690/1683
2025-10-24 14:21:15.0860 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  691/1683
2025-10-24 14:21:15.0861 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  692/1683
2025-10-24 14:21:15.0862 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  693/1683
2025-10-24 14:21:15.0862 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  694/1683
2025-10-24 14:21:15.0863 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  695/1683
2025-10-24 14:21:15.0864 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  696/1683
2025-10-24 14:21:15.0865 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  697/1683
2025-10-24 14:21:15.0865 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  698/1683
2025-10-24 14:21:15.0866 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  699/1683
2025-10-24 14:21:15.0867 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  700/1683
2025-10-24 14:21:15.0867 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  701/1683
2025-10-24 14:21:15.0868 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  702/1683
2025-10-24 14:21:15.0868 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  703/1683
2025-10-24 14:21:15.0869 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  704/1683
2025-10-24 14:21:15.0869 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  705/1683
2025-10-24 14:21:15.0870 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  706/1683
2025-10-24 14:21:15.0871 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  707/1683
2025-10-24 14:21:15.0871 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  708/1683
2025-10-24 14:21:15.0872 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  709/1683
2025-10-24 14:21:15.0873 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  710/1683
2025-10-24 14:21:15.0873 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  711/1683
2025-10-24 14:21:15.0874 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  712/1683
2025-10-24 14:21:15.0874 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  713/1683
2025-10-24 14:21:15.0875 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  714/1683
2025-10-24 14:21:15.0876 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  715/1683
2025-10-24 14:21:15.0876 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  716/1683
2025-10-24 14:21:15.0877 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  717/1683
2025-10-24 14:21:15.0878 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  718/1683
2025-10-24 14:21:15.0879 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  719/1683
2025-10-24 14:21:15.0879 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  720/1683
2025-10-24 14:21:15.0880 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  721/1683
2025-10-24 14:21:15.0881 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  722/1683
2025-10-24 14:21:15.0882 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  723/1683
2025-10-24 14:21:15.0882 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  724/1683
2025-10-24 14:21:15.0883 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  725/1683
2025-10-24 14:21:15.0884 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  726/1683
2025-10-24 14:21:15.0885 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  727/1683
2025-10-24 14:21:15.0885 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  728/1683
2025-10-24 14:21:15.0886 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  729/1683
2025-10-24 14:21:15.0886 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  730/1683
2025-10-24 14:21:15.0887 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  731/1683
2025-10-24 14:21:15.0888 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  732/1683
2025-10-24 14:21:15.0888 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  733/1683
2025-10-24 14:21:15.0889 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  734/1683
2025-10-24 14:21:15.0890 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  735/1683
2025-10-24 14:21:15.0890 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  736/1683
2025-10-24 14:21:15.0891 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  737/1683
2025-10-24 14:21:15.0891 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  738/1683
2025-10-24 14:21:15.0892 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  739/1683
2025-10-24 14:21:15.0893 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  740/1683
2025-10-24 14:21:15.0893 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  741/1683
2025-10-24 14:21:15.0894 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  742/1683
2025-10-24 14:21:15.0895 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  743/1683
2025-10-24 14:21:15.0895 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  744/1683
2025-10-24 14:21:15.0896 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  745/1683
2025-10-24 14:21:15.0897 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  746/1683
2025-10-24 14:21:15.0898 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  747/1683
2025-10-24 14:21:15.0898 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  748/1683
2025-10-24 14:21:15.0899 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  749/1683
2025-10-24 14:21:15.0900 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  750/1683
2025-10-24 14:21:15.0901 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  751/1683
2025-10-24 14:21:15.0902 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  752/1683
2025-10-24 14:21:15.0902 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  753/1683
2025-10-24 14:21:15.0903 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  754/1683
2025-10-24 14:21:15.0904 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  755/1683
2025-10-24 14:21:15.0905 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  756/1683
2025-10-24 14:21:15.0905 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  757/1683
2025-10-24 14:21:15.0906 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  758/1683
2025-10-24 14:21:15.0907 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  759/1683
2025-10-24 14:21:15.0907 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  760/1683
2025-10-24 14:21:15.0908 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  761/1683
2025-10-24 14:21:15.0908 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  762/1683
2025-10-24 14:21:15.0909 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  763/1683
2025-10-24 14:21:15.0909 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  764/1683
2025-10-24 14:21:15.0910 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  765/1683
2025-10-24 14:21:15.0911 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  766/1683
2025-10-24 14:21:15.0912 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  767/1683
2025-10-24 14:21:15.0912 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  768/1683
2025-10-24 14:21:15.0913 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  769/1683
2025-10-24 14:21:15.0914 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  770/1683
2025-10-24 14:21:15.0914 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  771/1683
2025-10-24 14:21:15.0915 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  772/1683
2025-10-24 14:21:15.0915 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  773/1683
2025-10-24 14:21:15.0916 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  774/1683
2025-10-24 14:21:15.0917 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  775/1683
2025-10-24 14:21:15.0917 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  776/1683
2025-10-24 14:21:15.0918 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  777/1683
2025-10-24 14:21:15.0918 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  778/1683
2025-10-24 14:21:15.0919 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  779/1683
2025-10-24 14:21:15.0920 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  780/1683
2025-10-24 14:21:15.0920 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  781/1683
2025-10-24 14:21:15.0921 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  782/1683
2025-10-24 14:21:15.0922 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  783/1683
2025-10-24 14:21:15.0922 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  784/1683
2025-10-24 14:21:15.0923 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  785/1683
2025-10-24 14:21:15.0924 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  786/1683
2025-10-24 14:21:15.0924 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  787/1683
2025-10-24 14:21:15.0925 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  788/1683
2025-10-24 14:21:15.0926 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  789/1683
2025-10-24 14:21:15.0927 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  790/1683
2025-10-24 14:21:15.0928 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  791/1683
2025-10-24 14:21:15.0928 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  792/1683
2025-10-24 14:21:15.0929 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  793/1683
2025-10-24 14:21:15.0929 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  794/1683
2025-10-24 14:21:15.0930 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  795/1683
2025-10-24 14:21:15.0931 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  796/1683
2025-10-24 14:21:15.0931 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  797/1683
2025-10-24 14:21:15.0932 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  798/1683
2025-10-24 14:21:15.0933 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  799/1683
2025-10-24 14:21:15.0933 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  800/1683
2025-10-24 14:21:15.0934 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  801/1683
2025-10-24 14:21:15.0934 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  802/1683
2025-10-24 14:21:15.0935 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  803/1683
2025-10-24 14:21:15.0936 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  804/1683
2025-10-24 14:21:15.0936 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  805/1683
2025-10-24 14:21:15.0937 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  806/1683
2025-10-24 14:21:15.0938 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  807/1683
2025-10-24 14:21:15.0938 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  808/1683
2025-10-24 14:21:15.0939 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  809/1683
2025-10-24 14:21:15.0940 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  810/1683
2025-10-24 14:21:15.0940 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  811/1683
2025-10-24 14:21:15.0941 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  812/1683
2025-10-24 14:21:15.0941 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  813/1683
2025-10-24 14:21:15.0942 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  814/1683
2025-10-24 14:21:15.0942 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  815/1683
2025-10-24 14:21:15.0943 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  816/1683
2025-10-24 14:21:15.0944 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  817/1683
2025-10-24 14:21:15.0944 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  818/1683
2025-10-24 14:21:15.0945 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  819/1683
2025-10-24 14:21:15.0946 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  820/1683
2025-10-24 14:21:15.0946 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  821/1683
2025-10-24 14:21:15.0947 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  822/1683
2025-10-24 14:21:15.0947 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  823/1683
2025-10-24 14:21:15.0948 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  824/1683
2025-10-24 14:21:15.0949 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  825/1683
2025-10-24 14:21:15.0949 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  826/1683
2025-10-24 14:21:15.0950 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  827/1683
2025-10-24 14:21:15.0951 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  828/1683
2025-10-24 14:21:15.0952 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  829/1683
2025-10-24 14:21:15.0953 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  830/1683
2025-10-24 14:21:15.0953 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  831/1683
2025-10-24 14:21:15.0954 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  832/1683
2025-10-24 14:21:15.0955 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  833/1683
2025-10-24 14:21:15.0955 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  834/1683
2025-10-24 14:21:15.0956 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  835/1683
2025-10-24 14:21:15.0957 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  836/1683
2025-10-24 14:21:15.0957 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  837/1683
2025-10-24 14:21:15.0958 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  838/1683
2025-10-24 14:21:15.0958 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  839/1683
2025-10-24 14:21:15.0959 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  840/1683
2025-10-24 14:21:15.0960 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  841/1683
2025-10-24 14:21:15.0960 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  842/1683
2025-10-24 14:21:15.0961 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  843/1683
2025-10-24 14:21:15.0961 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  844/1683
2025-10-24 14:21:15.0962 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  845/1683
2025-10-24 14:21:15.0962 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  846/1683
2025-10-24 14:21:15.0963 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  847/1683
2025-10-24 14:21:15.0963 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  848/1683
2025-10-24 14:21:15.0964 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  849/1683
2025-10-24 14:21:15.0965 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  850/1683
2025-10-24 14:21:15.0965 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  851/1683
2025-10-24 14:21:15.0966 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  852/1683
2025-10-24 14:21:15.0967 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  853/1683
2025-10-24 14:21:15.0968 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  854/1683
2025-10-24 14:21:15.0968 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  855/1683
2025-10-24 14:21:15.0969 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  856/1683
2025-10-24 14:21:15.0970 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  857/1683
2025-10-24 14:21:15.0970 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  858/1683
2025-10-24 14:21:15.0971 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  859/1683
2025-10-24 14:21:15.0972 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  860/1683
2025-10-24 14:21:15.0972 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  861/1683
2025-10-24 14:21:15.0973 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  862/1683
2025-10-24 14:21:15.0974 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  863/1683
2025-10-24 14:21:15.0975 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  864/1683
2025-10-24 14:21:15.0975 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  865/1683
2025-10-24 14:21:15.0976 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  866/1683
2025-10-24 14:21:15.0976 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  867/1683
2025-10-24 14:21:15.0977 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  868/1683
2025-10-24 14:21:15.0978 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  869/1683
2025-10-24 14:21:15.0978 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  870/1683
2025-10-24 14:21:15.0979 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  871/1683
2025-10-24 14:21:15.0979 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  872/1683
2025-10-24 14:21:15.0980 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  873/1683
2025-10-24 14:21:15.0980 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  874/1683
2025-10-24 14:21:15.0981 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  875/1683
2025-10-24 14:21:15.0982 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  876/1683
2025-10-24 14:21:15.0982 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  877/1683
2025-10-24 14:21:15.0983 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  878/1683
2025-10-24 14:21:15.0984 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  879/1683
2025-10-24 14:21:15.0985 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  880/1683
2025-10-24 14:21:15.0985 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  881/1683
2025-10-24 14:21:15.0986 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  882/1683
2025-10-24 14:21:15.0987 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  883/1683
2025-10-24 14:21:15.0988 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  884/1683
2025-10-24 14:21:15.0988 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  885/1683
2025-10-24 14:21:15.0989 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  886/1683
2025-10-24 14:21:15.0989 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  887/1683
2025-10-24 14:21:15.0990 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  888/1683
2025-10-24 14:21:15.0990 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  889/1683
2025-10-24 14:21:15.0991 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  890/1683
2025-10-24 14:21:15.0992 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  891/1683
2025-10-24 14:21:15.0992 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  892/1683
2025-10-24 14:21:15.0993 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  893/1683
2025-10-24 14:21:15.0994 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  894/1683
2025-10-24 14:21:15.0994 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  895/1683
2025-10-24 14:21:15.0995 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  896/1683
2025-10-24 14:21:15.0995 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  897/1683
2025-10-24 14:21:15.0996 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  898/1683
2025-10-24 14:21:15.0997 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  899/1683
2025-10-24 14:21:15.0997 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  900/1683
2025-10-24 14:21:15.0998 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  901/1683
2025-10-24 14:21:15.0998 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  902/1683
2025-10-24 14:21:15.0999 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  903/1683
2025-10-24 14:21:15.0999 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  904/1683
2025-10-24 14:21:16.0000 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  905/1683
2025-10-24 14:21:16.0001 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  906/1683
2025-10-24 14:21:16.0001 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  907/1683
2025-10-24 14:21:16.0002 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  908/1683
2025-10-24 14:21:16.0003 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  909/1683
2025-10-24 14:21:16.0003 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  910/1683
2025-10-24 14:21:16.0004 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  911/1683
2025-10-24 14:21:16.0005 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  912/1683
2025-10-24 14:21:16.0005 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  913/1683
2025-10-24 14:21:16.0006 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  914/1683
2025-10-24 14:21:16.0007 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  915/1683
2025-10-24 14:21:16.0007 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  916/1683
2025-10-24 14:21:16.0008 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  917/1683
2025-10-24 14:21:16.0009 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  918/1683
2025-10-24 14:21:16.0009 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  919/1683
2025-10-24 14:21:16.0010 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  920/1683
2025-10-24 14:21:16.0011 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  921/1683
2025-10-24 14:21:16.0012 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  922/1683
2025-10-24 14:21:16.0013 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  923/1683
2025-10-24 14:21:16.0013 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  924/1683
2025-10-24 14:21:16.0014 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  925/1683
2025-10-24 14:21:16.0015 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  926/1683
2025-10-24 14:21:16.0016 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  927/1683
2025-10-24 14:21:16.0016 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  928/1683
2025-10-24 14:21:16.0017 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  929/1683
2025-10-24 14:21:16.0017 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  930/1683
2025-10-24 14:21:16.0018 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  931/1683
2025-10-24 14:21:16.0019 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  932/1683
2025-10-24 14:21:16.0019 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  933/1683
2025-10-24 14:21:16.0020 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  934/1683
2025-10-24 14:21:16.0021 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  935/1683
2025-10-24 14:21:16.0021 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  936/1683
2025-10-24 14:21:16.0022 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  937/1683
2025-10-24 14:21:16.0022 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  938/1683
2025-10-24 14:21:16.0023 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  939/1683
2025-10-24 14:21:16.0023 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  940/1683
2025-10-24 14:21:16.0024 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  941/1683
2025-10-24 14:21:16.0025 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  942/1683
2025-10-24 14:21:16.0025 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  943/1683
2025-10-24 14:21:16.0026 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  944/1683
2025-10-24 14:21:16.0027 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  945/1683
2025-10-24 14:21:16.0027 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  946/1683
2025-10-24 14:21:16.0028 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  947/1683
2025-10-24 14:21:16.0028 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  948/1683
2025-10-24 14:21:16.0029 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  949/1683
2025-10-24 14:21:16.0030 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  950/1683
2025-10-24 14:21:16.0031 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  951/1683
2025-10-24 14:21:16.0031 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  952/1683
2025-10-24 14:21:16.0032 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  953/1683
2025-10-24 14:21:16.0033 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  954/1683
2025-10-24 14:21:16.0033 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  955/1683
2025-10-24 14:21:16.0034 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  956/1683
2025-10-24 14:21:16.0035 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  957/1683
2025-10-24 14:21:16.0036 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  958/1683
2025-10-24 14:21:16.0036 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  959/1683
2025-10-24 14:21:16.0037 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  960/1683
2025-10-24 14:21:16.0037 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  961/1683
2025-10-24 14:21:16.0038 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  962/1683
2025-10-24 14:21:16.0039 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  963/1683
2025-10-24 14:21:16.0039 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  964/1683
2025-10-24 14:21:16.0040 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  965/1683
2025-10-24 14:21:16.0040 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  966/1683
2025-10-24 14:21:16.0041 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  967/1683
2025-10-24 14:21:16.0042 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  968/1683
2025-10-24 14:21:16.0043 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  969/1683
2025-10-24 14:21:16.0043 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  970/1683
2025-10-24 14:21:16.0044 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  971/1683
2025-10-24 14:21:16.0044 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  972/1683
2025-10-24 14:21:16.0045 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  973/1683
2025-10-24 14:21:16.0045 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  974/1683
2025-10-24 14:21:16.0046 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  975/1683
2025-10-24 14:21:16.0047 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  976/1683
2025-10-24 14:21:16.0048 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  977/1683
2025-10-24 14:21:16.0048 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  978/1683
2025-10-24 14:21:16.0049 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  979/1683
2025-10-24 14:21:16.0050 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  980/1683
2025-10-24 14:21:16.0051 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  981/1683
2025-10-24 14:21:16.0052 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  982/1683
2025-10-24 14:21:16.0052 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  983/1683
2025-10-24 14:21:16.0053 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  984/1683
2025-10-24 14:21:16.0053 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  985/1683
2025-10-24 14:21:16.0054 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  986/1683
2025-10-24 14:21:16.0055 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  987/1683
2025-10-24 14:21:16.0055 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  988/1683
2025-10-24 14:21:16.0056 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  989/1683
2025-10-24 14:21:16.0056 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  990/1683
2025-10-24 14:21:16.0057 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  991/1683
2025-10-24 14:21:16.0058 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  992/1683
2025-10-24 14:21:16.0059 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  993/1683
2025-10-24 14:21:16.0060 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  994/1683
2025-10-24 14:21:16.0061 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  995/1683
2025-10-24 14:21:16.0061 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  996/1683
2025-10-24 14:21:16.0062 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  997/1683
2025-10-24 14:21:16.0063 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  998/1683
2025-10-24 14:21:16.0064 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  999/1683
2025-10-24 14:21:16.0064 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1000/1683
2025-10-24 14:21:16.0065 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1001/1683
2025-10-24 14:21:16.0066 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1002/1683
2025-10-24 14:21:16.0067 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1003/1683
2025-10-24 14:21:16.0068 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1004/1683
2025-10-24 14:21:16.0069 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1005/1683
2025-10-24 14:21:16.0069 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1006/1683
2025-10-24 14:21:16.0070 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1007/1683
2025-10-24 14:21:16.0071 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1008/1683
2025-10-24 14:21:16.0071 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1009/1683
2025-10-24 14:21:16.0072 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1010/1683
2025-10-24 14:21:16.0073 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1011/1683
2025-10-24 14:21:16.0073 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1012/1683
2025-10-24 14:21:16.0074 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1013/1683
2025-10-24 14:21:16.0075 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1014/1683
2025-10-24 14:21:16.0075 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1015/1683
2025-10-24 14:21:16.0076 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1016/1683
2025-10-24 14:21:16.0077 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1017/1683
2025-10-24 14:21:16.0078 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1018/1683
2025-10-24 14:21:16.0079 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1019/1683
2025-10-24 14:21:16.0079 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1020/1683
2025-10-24 14:21:16.0080 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1021/1683
2025-10-24 14:21:16.0081 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1022/1683
2025-10-24 14:21:16.0081 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1023/1683
2025-10-24 14:21:16.0082 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1024/1683
2025-10-24 14:21:16.0082 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1025/1683
2025-10-24 14:21:16.0083 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1026/1683
2025-10-24 14:21:16.0084 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1027/1683
2025-10-24 14:21:16.0084 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1028/1683
2025-10-24 14:21:16.0085 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1029/1683
2025-10-24 14:21:16.0086 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1030/1683
2025-10-24 14:21:16.0087 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1031/1683
2025-10-24 14:21:16.0087 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1032/1683
2025-10-24 14:21:16.0088 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1033/1683
2025-10-24 14:21:16.0088 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1034/1683
2025-10-24 14:21:16.0089 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1035/1683
2025-10-24 14:21:16.0090 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1036/1683
2025-10-24 14:21:16.0090 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1037/1683
2025-10-24 14:21:16.0091 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1038/1683
2025-10-24 14:21:16.0092 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1039/1683
2025-10-24 14:21:16.0092 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1040/1683
2025-10-24 14:21:16.0093 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1041/1683
2025-10-24 14:21:16.0094 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1042/1683
2025-10-24 14:21:16.0095 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1043/1683
2025-10-24 14:21:16.0095 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1044/1683
2025-10-24 14:21:16.0096 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1045/1683
2025-10-24 14:21:16.0096 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1046/1683
2025-10-24 14:21:16.0097 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1047/1683
2025-10-24 14:21:16.0098 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1048/1683
2025-10-24 14:21:16.0098 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1049/1683
2025-10-24 14:21:16.0099 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1050/1683
2025-10-24 14:21:16.0100 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1051/1683
2025-10-24 14:21:16.0100 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1052/1683
2025-10-24 14:21:16.0101 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1053/1683
2025-10-24 14:21:16.0102 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1054/1683
2025-10-24 14:21:16.0102 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1055/1683
2025-10-24 14:21:16.0103 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1056/1683
2025-10-24 14:21:16.0103 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1057/1683
2025-10-24 14:21:16.0104 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1058/1683
2025-10-24 14:21:16.0105 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1059/1683
2025-10-24 14:21:16.0106 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1060/1683
2025-10-24 14:21:16.0106 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1061/1683
2025-10-24 14:21:16.0107 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1062/1683
2025-10-24 14:21:16.0108 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1063/1683
2025-10-24 14:21:16.0108 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1064/1683
2025-10-24 14:21:16.0109 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1065/1683
2025-10-24 14:21:16.0109 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1066/1683
2025-10-24 14:21:16.0110 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1067/1683
2025-10-24 14:21:16.0111 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1068/1683
2025-10-24 14:21:16.0111 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1069/1683
2025-10-24 14:21:16.0112 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1070/1683
2025-10-24 14:21:16.0112 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1071/1683
2025-10-24 14:21:16.0113 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1072/1683
2025-10-24 14:21:16.0113 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1073/1683
2025-10-24 14:21:16.0114 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1074/1683
2025-10-24 14:21:16.0115 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1075/1683
2025-10-24 14:21:16.0115 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1076/1683
2025-10-24 14:21:16.0116 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1077/1683
2025-10-24 14:21:16.0117 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1078/1683
2025-10-24 14:21:16.0117 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1079/1683
2025-10-24 14:21:16.0118 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1080/1683
2025-10-24 14:21:16.0119 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1081/1683
2025-10-24 14:21:16.0120 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1082/1683
2025-10-24 14:21:16.0120 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1083/1683
2025-10-24 14:21:16.0121 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1084/1683
2025-10-24 14:21:16.0122 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1085/1683
2025-10-24 14:21:16.0122 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1086/1683
2025-10-24 14:21:16.0123 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1087/1683
2025-10-24 14:21:16.0124 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1088/1683
2025-10-24 14:21:16.0124 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1089/1683
2025-10-24 14:21:16.0125 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1090/1683
2025-10-24 14:21:16.0126 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1091/1683
2025-10-24 14:21:16.0126 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1092/1683
2025-10-24 14:21:16.0127 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1093/1683
2025-10-24 14:21:16.0127 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1094/1683
2025-10-24 14:21:16.0128 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1095/1683
2025-10-24 14:21:16.0129 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1096/1683
2025-10-24 14:21:16.0129 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1097/1683
2025-10-24 14:21:16.0130 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1098/1683
2025-10-24 14:21:16.0131 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1099/1683
2025-10-24 14:21:16.0132 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1100/1683
2025-10-24 14:21:16.0132 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1101/1683
2025-10-24 14:21:16.0133 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1102/1683
2025-10-24 14:21:16.0134 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1103/1683
2025-10-24 14:21:16.0135 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1104/1683
2025-10-24 14:21:16.0135 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1105/1683
2025-10-24 14:21:16.0136 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1106/1683
2025-10-24 14:21:16.0137 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1107/1683
2025-10-24 14:21:16.0138 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1108/1683
2025-10-24 14:21:16.0138 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1109/1683
2025-10-24 14:21:16.0139 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1110/1683
2025-10-24 14:21:16.0140 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1111/1683
2025-10-24 14:21:16.0141 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1112/1683
2025-10-24 14:21:16.0142 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1113/1683
2025-10-24 14:21:16.0143 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1114/1683
2025-10-24 14:21:16.0143 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1115/1683
2025-10-24 14:21:16.0144 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1116/1683
2025-10-24 14:21:16.0144 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1117/1683
2025-10-24 14:21:16.0145 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1118/1683
2025-10-24 14:21:16.0145 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1119/1683
2025-10-24 14:21:16.0146 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1120/1683
2025-10-24 14:21:16.0147 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1121/1683
2025-10-24 14:21:16.0147 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1122/1683
2025-10-24 14:21:16.0148 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1123/1683
2025-10-24 14:21:16.0149 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1124/1683
2025-10-24 14:21:16.0150 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1125/1683
2025-10-24 14:21:16.0150 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1126/1683
2025-10-24 14:21:16.0151 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1127/1683
2025-10-24 14:21:16.0151 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1128/1683
2025-10-24 14:21:16.0152 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1129/1683
2025-10-24 14:21:16.0153 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1130/1683
2025-10-24 14:21:16.0154 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1131/1683
2025-10-24 14:21:16.0154 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1132/1683
2025-10-24 14:21:16.0155 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1133/1683
2025-10-24 14:21:16.0155 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1134/1683
2025-10-24 14:21:16.0156 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1135/1683
2025-10-24 14:21:16.0157 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1136/1683
2025-10-24 14:21:16.0158 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1137/1683
2025-10-24 14:21:16.0158 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1138/1683
2025-10-24 14:21:16.0159 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1139/1683
2025-10-24 14:21:16.0159 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1140/1683
2025-10-24 14:21:16.0160 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1141/1683
2025-10-24 14:21:16.0161 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1142/1683
2025-10-24 14:21:16.0162 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1143/1683
2025-10-24 14:21:16.0162 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1144/1683
2025-10-24 14:21:16.0163 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1145/1683
2025-10-24 14:21:16.0164 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1146/1683
2025-10-24 14:21:16.0164 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1147/1683
2025-10-24 14:21:16.0165 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1148/1683
2025-10-24 14:21:16.0165 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1149/1683
2025-10-24 14:21:16.0166 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1150/1683
2025-10-24 14:21:16.0167 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1151/1683
2025-10-24 14:21:16.0167 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1152/1683
2025-10-24 14:21:16.0168 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1153/1683
2025-10-24 14:21:16.0169 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1154/1683
2025-10-24 14:21:16.0169 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1155/1683
2025-10-24 14:21:16.0170 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1156/1683
2025-10-24 14:21:16.0171 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1157/1683
2025-10-24 14:21:16.0172 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1158/1683
2025-10-24 14:21:16.0172 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1159/1683
2025-10-24 14:21:16.0173 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1160/1683
2025-10-24 14:21:16.0174 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1161/1683
2025-10-24 14:21:16.0175 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1162/1683
2025-10-24 14:21:16.0175 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1163/1683
2025-10-24 14:21:16.0176 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1164/1683
2025-10-24 14:21:16.0176 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1165/1683
2025-10-24 14:21:16.0177 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1166/1683
2025-10-24 14:21:16.0177 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1167/1683
2025-10-24 14:21:16.0178 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1168/1683
2025-10-24 14:21:16.0179 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1169/1683
2025-10-24 14:21:16.0179 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1170/1683
2025-10-24 14:21:16.0180 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1171/1683
2025-10-24 14:21:16.0180 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1172/1683
2025-10-24 14:21:16.0181 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1173/1683
2025-10-24 14:21:16.0182 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1174/1683
2025-10-24 14:21:16.0182 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1175/1683
2025-10-24 14:21:16.0183 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1176/1683
2025-10-24 14:21:16.0184 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1177/1683
2025-10-24 14:21:16.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1178/1683
2025-10-24 14:21:16.0185 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1179/1683
2025-10-24 14:21:16.0186 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1180/1683
2025-10-24 14:21:16.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1181/1683
2025-10-24 14:21:16.0187 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1182/1683
2025-10-24 14:21:16.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1183/1683
2025-10-24 14:21:16.0188 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1184/1683
2025-10-24 14:21:16.0189 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1185/1683
2025-10-24 14:21:16.0190 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1186/1683
2025-10-24 14:21:16.0191 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1187/1683
2025-10-24 14:21:16.0191 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1188/1683
2025-10-24 14:21:16.0192 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1189/1683
2025-10-24 14:21:16.0193 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1190/1683
2025-10-24 14:21:16.0193 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1191/1683
2025-10-24 14:21:16.0194 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1192/1683
2025-10-24 14:21:16.0195 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1193/1683
2025-10-24 14:21:16.0196 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1194/1683
2025-10-24 14:21:16.0196 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1195/1683
2025-10-24 14:21:16.0197 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1196/1683
2025-10-24 14:21:16.0198 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1197/1683
2025-10-24 14:21:16.0198 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1198/1683
2025-10-24 14:21:16.0199 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1199/1683
2025-10-24 14:21:16.0200 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1200/1683
2025-10-24 14:21:16.0201 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1201/1683
2025-10-24 14:21:16.0201 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1202/1683
2025-10-24 14:21:16.0202 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1203/1683
2025-10-24 14:21:16.0203 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1204/1683
2025-10-24 14:21:16.0203 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1205/1683
2025-10-24 14:21:16.0204 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1206/1683
2025-10-24 14:21:16.0204 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1207/1683
2025-10-24 14:21:16.0205 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1208/1683
2025-10-24 14:21:16.0206 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1209/1683
2025-10-24 14:21:16.0206 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1210/1683
2025-10-24 14:21:16.0207 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1211/1683
2025-10-24 14:21:16.0208 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1212/1683
2025-10-24 14:21:16.0208 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1213/1683
2025-10-24 14:21:16.0209 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1214/1683
2025-10-24 14:21:16.0210 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1215/1683
2025-10-24 14:21:16.0210 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1216/1683
2025-10-24 14:21:16.0211 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1217/1683
2025-10-24 14:21:16.0212 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1218/1683
2025-10-24 14:21:16.0213 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1219/1683
2025-10-24 14:21:16.0214 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1220/1683
2025-10-24 14:21:16.0214 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1221/1683
2025-10-24 14:21:16.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1222/1683
2025-10-24 14:21:16.0215 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1223/1683
2025-10-24 14:21:16.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1224/1683
2025-10-24 14:21:16.0216 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1225/1683
2025-10-24 14:21:16.0217 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1226/1683
2025-10-24 14:21:16.0218 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1227/1683
2025-10-24 14:21:16.0219 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1228/1683
2025-10-24 14:21:16.0219 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1229/1683
2025-10-24 14:21:16.0220 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1230/1683
2025-10-24 14:21:16.0221 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1231/1683
2025-10-24 14:21:16.0221 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1232/1683
2025-10-24 14:21:16.0222 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1233/1683
2025-10-24 14:21:16.0223 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1234/1683
2025-10-24 14:21:16.0224 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1235/1683
2025-10-24 14:21:16.0224 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1236/1683
2025-10-24 14:21:16.0225 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1237/1683
2025-10-24 14:21:16.0225 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1238/1683
2025-10-24 14:21:16.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1239/1683
2025-10-24 14:21:16.0226 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1240/1683
2025-10-24 14:21:16.0227 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1241/1683
2025-10-24 14:21:16.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1242/1683
2025-10-24 14:21:16.0228 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1243/1683
2025-10-24 14:21:16.0229 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1244/1683
2025-10-24 14:21:16.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1245/1683
2025-10-24 14:21:16.0230 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1246/1683
2025-10-24 14:21:16.0231 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1247/1683
2025-10-24 14:21:16.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1248/1683
2025-10-24 14:21:16.0232 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1249/1683
2025-10-24 14:21:16.0233 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1250/1683
2025-10-24 14:21:16.0233 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1251/1683
2025-10-24 14:21:16.0234 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1252/1683
2025-10-24 14:21:16.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1253/1683
2025-10-24 14:21:16.0235 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1254/1683
2025-10-24 14:21:16.0236 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1255/1683
2025-10-24 14:21:16.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1256/1683
2025-10-24 14:21:16.0237 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1257/1683
2025-10-24 14:21:16.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1258/1683
2025-10-24 14:21:16.0238 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1259/1683
2025-10-24 14:21:16.0239 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1260/1683
2025-10-24 14:21:16.0240 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1261/1683
2025-10-24 14:21:16.0241 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1262/1683
2025-10-24 14:21:16.0242 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1263/1683
2025-10-24 14:21:16.0243 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1264/1683
2025-10-24 14:21:16.0244 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1265/1683
2025-10-24 14:21:16.0244 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1266/1683
2025-10-24 14:21:16.0245 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1267/1683
2025-10-24 14:21:16.0245 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1268/1683
2025-10-24 14:21:16.0246 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1269/1683
2025-10-24 14:21:16.0247 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1270/1683
2025-10-24 14:21:16.0247 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1271/1683
2025-10-24 14:21:16.0248 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1272/1683
2025-10-24 14:21:16.0248 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1273/1683
2025-10-24 14:21:16.0249 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1274/1683
2025-10-24 14:21:16.0250 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1275/1683
2025-10-24 14:21:16.0250 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1276/1683
2025-10-24 14:21:16.0251 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1277/1683
2025-10-24 14:21:16.0251 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1278/1683
2025-10-24 14:21:16.0252 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1279/1683
2025-10-24 14:21:16.0253 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1280/1683
2025-10-24 14:21:16.0254 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1281/1683
2025-10-24 14:21:16.0254 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1282/1683
2025-10-24 14:21:16.0255 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1283/1683
2025-10-24 14:21:16.0256 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1284/1683
2025-10-24 14:21:16.0257 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1285/1683
2025-10-24 14:21:16.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1286/1683
2025-10-24 14:21:16.0258 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1287/1683
2025-10-24 14:21:16.0259 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1288/1683
2025-10-24 14:21:16.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1289/1683
2025-10-24 14:21:16.0260 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1290/1683
2025-10-24 14:21:16.0261 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1291/1683
2025-10-24 14:21:16.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1292/1683
2025-10-24 14:21:16.0262 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1293/1683
2025-10-24 14:21:16.0263 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1294/1683
2025-10-24 14:21:16.0264 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1295/1683
2025-10-24 14:21:16.0265 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1296/1683
2025-10-24 14:21:16.0265 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1297/1683
2025-10-24 14:21:16.0266 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1298/1683
2025-10-24 14:21:16.0267 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1299/1683
2025-10-24 14:21:16.0267 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1300/1683
2025-10-24 14:21:16.0268 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1301/1683
2025-10-24 14:21:16.0269 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1302/1683
2025-10-24 14:21:16.0270 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1303/1683
2025-10-24 14:21:16.0270 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1304/1683
2025-10-24 14:21:16.0271 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1305/1683
2025-10-24 14:21:16.0272 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1306/1683
2025-10-24 14:21:16.0273 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1307/1683
2025-10-24 14:21:16.0273 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1308/1683
2025-10-24 14:21:16.0274 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1309/1683
2025-10-24 14:21:16.0274 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1310/1683
2025-10-24 14:21:16.0275 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1311/1683
2025-10-24 14:21:16.0276 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1312/1683
2025-10-24 14:21:16.0277 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1313/1683
2025-10-24 14:21:16.0277 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1314/1683
2025-10-24 14:21:16.0278 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1315/1683
2025-10-24 14:21:16.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1316/1683
2025-10-24 14:21:16.0279 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1317/1683
2025-10-24 14:21:16.0280 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1318/1683
2025-10-24 14:21:16.0281 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1319/1683
2025-10-24 14:21:16.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1320/1683
2025-10-24 14:21:16.0282 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1321/1683
2025-10-24 14:21:16.0283 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1322/1683
2025-10-24 14:21:16.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1323/1683
2025-10-24 14:21:16.0284 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1324/1683
2025-10-24 14:21:16.0285 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1325/1683
2025-10-24 14:21:16.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1326/1683
2025-10-24 14:21:16.0286 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1327/1683
2025-10-24 14:21:16.0287 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1328/1683
2025-10-24 14:21:16.0288 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1329/1683
2025-10-24 14:21:16.0289 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1330/1683
2025-10-24 14:21:16.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1331/1683
2025-10-24 14:21:16.0290 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1332/1683
2025-10-24 14:21:16.0291 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1333/1683
2025-10-24 14:21:16.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1334/1683
2025-10-24 14:21:16.0292 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1335/1683
2025-10-24 14:21:16.0293 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1336/1683
2025-10-24 14:21:16.0294 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1337/1683
2025-10-24 14:21:16.0295 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1338/1683
2025-10-24 14:21:16.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1339/1683
2025-10-24 14:21:16.0296 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1340/1683
2025-10-24 14:21:16.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1341/1683
2025-10-24 14:21:16.0297 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1342/1683
2025-10-24 14:21:16.0298 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1343/1683
2025-10-24 14:21:16.0299 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1344/1683
2025-10-24 14:21:16.0300 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1345/1683
2025-10-24 14:21:16.0301 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1346/1683
2025-10-24 14:21:16.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1347/1683
2025-10-24 14:21:16.0302 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1348/1683
2025-10-24 14:21:16.0303 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1349/1683
2025-10-24 14:21:16.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1350/1683
2025-10-24 14:21:16.0304 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1351/1683
2025-10-24 14:21:16.0305 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1352/1683
2025-10-24 14:21:16.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1353/1683
2025-10-24 14:21:16.0306 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1354/1683
2025-10-24 14:21:16.0307 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1355/1683
2025-10-24 14:21:16.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1356/1683
2025-10-24 14:21:16.0308 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1357/1683
2025-10-24 14:21:16.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1358/1683
2025-10-24 14:21:16.0309 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1359/1683
2025-10-24 14:21:16.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1360/1683
2025-10-24 14:21:16.0310 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1361/1683
2025-10-24 14:21:16.0311 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1362/1683
2025-10-24 14:21:16.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1363/1683
2025-10-24 14:21:16.0312 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1364/1683
2025-10-24 14:21:16.0313 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1365/1683
2025-10-24 14:21:16.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1366/1683
2025-10-24 14:21:16.0314 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1367/1683
2025-10-24 14:21:16.0315 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1368/1683
2025-10-24 14:21:16.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1369/1683
2025-10-24 14:21:16.0316 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1370/1683
2025-10-24 14:21:16.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1371/1683
2025-10-24 14:21:16.0317 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1372/1683
2025-10-24 14:21:16.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1373/1683
2025-10-24 14:21:16.0318 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1374/1683
2025-10-24 14:21:16.0319 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1375/1683
2025-10-24 14:21:16.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1376/1683
2025-10-24 14:21:16.0320 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1377/1683
2025-10-24 14:21:16.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1378/1683
2025-10-24 14:21:16.0321 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1379/1683
2025-10-24 14:21:16.0322 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1380/1683
2025-10-24 14:21:16.0323 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1381/1683
2025-10-24 14:21:16.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1382/1683
2025-10-24 14:21:16.0324 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1383/1683
2025-10-24 14:21:16.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1384/1683
2025-10-24 14:21:16.0325 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1385/1683
2025-10-24 14:21:16.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1386/1683
2025-10-24 14:21:16.0326 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1387/1683
2025-10-24 14:21:16.0327 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1388/1683
2025-10-24 14:21:16.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1389/1683
2025-10-24 14:21:16.0328 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1390/1683
2025-10-24 14:21:16.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1391/1683
2025-10-24 14:21:16.0329 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1392/1683
2025-10-24 14:21:16.0330 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1393/1683
2025-10-24 14:21:16.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1394/1683
2025-10-24 14:21:16.0331 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1395/1683
2025-10-24 14:21:16.0332 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1396/1683
2025-10-24 14:21:16.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1397/1683
2025-10-24 14:21:16.0333 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1398/1683
2025-10-24 14:21:16.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1399/1683
2025-10-24 14:21:16.0334 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1400/1683
2025-10-24 14:21:16.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1401/1683
2025-10-24 14:21:16.0335 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1402/1683
2025-10-24 14:21:16.0336 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1403/1683
2025-10-24 14:21:16.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1404/1683
2025-10-24 14:21:16.0337 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1405/1683
2025-10-24 14:21:16.0338 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1406/1683
2025-10-24 14:21:16.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1407/1683
2025-10-24 14:21:16.0339 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1408/1683
2025-10-24 14:21:16.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1409/1683
2025-10-24 14:21:16.0340 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1410/1683
2025-10-24 14:21:16.0341 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1411/1683
2025-10-24 14:21:16.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1412/1683
2025-10-24 14:21:16.0342 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1413/1683
2025-10-24 14:21:16.0343 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1414/1683
2025-10-24 14:21:16.0344 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1415/1683
2025-10-24 14:21:16.0345 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1416/1683
2025-10-24 14:21:16.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1417/1683
2025-10-24 14:21:16.0346 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1418/1683
2025-10-24 14:21:16.0347 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1419/1683
2025-10-24 14:21:16.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1420/1683
2025-10-24 14:21:16.0348 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1421/1683
2025-10-24 14:21:16.0349 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1422/1683
2025-10-24 14:21:16.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1423/1683
2025-10-24 14:21:16.0350 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1424/1683
2025-10-24 14:21:16.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1425/1683
2025-10-24 14:21:16.0351 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1426/1683
2025-10-24 14:21:16.0352 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1427/1683
2025-10-24 14:21:16.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1428/1683
2025-10-24 14:21:16.0353 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1429/1683
2025-10-24 14:21:16.0354 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1430/1683
2025-10-24 14:21:16.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1431/1683
2025-10-24 14:21:16.0355 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1432/1683
2025-10-24 14:21:16.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1433/1683
2025-10-24 14:21:16.0356 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1434/1683
2025-10-24 14:21:16.0357 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1435/1683
2025-10-24 14:21:16.0358 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1436/1683
2025-10-24 14:21:16.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1437/1683
2025-10-24 14:21:16.0359 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1438/1683
2025-10-24 14:21:16.0360 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1439/1683
2025-10-24 14:21:16.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1440/1683
2025-10-24 14:21:16.0361 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1441/1683
2025-10-24 14:21:16.0362 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1442/1683
2025-10-24 14:21:16.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1443/1683
2025-10-24 14:21:16.0363 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1444/1683
2025-10-24 14:21:16.0364 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1445/1683
2025-10-24 14:21:16.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1446/1683
2025-10-24 14:21:16.0365 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1447/1683
2025-10-24 14:21:16.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1448/1683
2025-10-24 14:21:16.0366 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1449/1683
2025-10-24 14:21:16.0367 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1450/1683
2025-10-24 14:21:16.0368 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1451/1683
2025-10-24 14:21:16.0369 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1452/1683
2025-10-24 14:21:16.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1453/1683
2025-10-24 14:21:16.0370 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1454/1683
2025-10-24 14:21:16.0371 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1455/1683
2025-10-24 14:21:16.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1456/1683
2025-10-24 14:21:16.0372 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1457/1683
2025-10-24 14:21:16.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1458/1683
2025-10-24 14:21:16.0373 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1459/1683
2025-10-24 14:21:16.0374 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1460/1683
2025-10-24 14:21:16.0375 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1461/1683
2025-10-24 14:21:16.0376 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1462/1683
2025-10-24 14:21:16.0377 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1463/1683
2025-10-24 14:21:16.0377 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1464/1683
2025-10-24 14:21:16.0378 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1465/1683
2025-10-24 14:21:16.0378 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1466/1683
2025-10-24 14:21:16.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1467/1683
2025-10-24 14:21:16.0379 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1468/1683
2025-10-24 14:21:16.0380 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1469/1683
2025-10-24 14:21:16.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1470/1683
2025-10-24 14:21:16.0381 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1471/1683
2025-10-24 14:21:16.0382 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1472/1683
2025-10-24 14:21:16.0383 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1473/1683
2025-10-24 14:21:16.0384 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1474/1683
2025-10-24 14:21:16.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1475/1683
2025-10-24 14:21:16.0385 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1476/1683
2025-10-24 14:21:16.0386 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1477/1683
2025-10-24 14:21:16.0387 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1478/1683
2025-10-24 14:21:16.0388 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1479/1683
2025-10-24 14:21:16.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1480/1683
2025-10-24 14:21:16.0389 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1481/1683
2025-10-24 14:21:16.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1482/1683
2025-10-24 14:21:16.0390 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1483/1683
2025-10-24 14:21:16.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1484/1683
2025-10-24 14:21:16.0391 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1485/1683
2025-10-24 14:21:16.0392 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1486/1683
2025-10-24 14:21:16.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1487/1683
2025-10-24 14:21:16.0393 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1488/1683
2025-10-24 14:21:16.0394 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1489/1683
2025-10-24 14:21:16.0395 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1490/1683
2025-10-24 14:21:16.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1491/1683
2025-10-24 14:21:16.0396 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1492/1683
2025-10-24 14:21:16.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1493/1683
2025-10-24 14:21:16.0397 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1494/1683
2025-10-24 14:21:16.0398 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1495/1683
2025-10-24 14:21:16.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1496/1683
2025-10-24 14:21:16.0399 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1497/1683
2025-10-24 14:21:16.0400 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1498/1683
2025-10-24 14:21:16.0401 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1499/1683
2025-10-24 14:21:16.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1500/1683
2025-10-24 14:21:16.0402 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1501/1683
2025-10-24 14:21:16.0403 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1502/1683
2025-10-24 14:21:16.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1503/1683
2025-10-24 14:21:16.0404 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1504/1683
2025-10-24 14:21:16.0405 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1505/1683
2025-10-24 14:21:16.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1506/1683
2025-10-24 14:21:16.0406 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1507/1683
2025-10-24 14:21:16.0407 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1508/1683
2025-10-24 14:21:16.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1509/1683
2025-10-24 14:21:16.0408 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1510/1683
2025-10-24 14:21:16.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1511/1683
2025-10-24 14:21:16.0409 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1512/1683
2025-10-24 14:21:16.0410 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1513/1683
2025-10-24 14:21:16.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1514/1683
2025-10-24 14:21:16.0411 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1515/1683
2025-10-24 14:21:16.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1516/1683
2025-10-24 14:21:16.0412 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1517/1683
2025-10-24 14:21:16.0413 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1518/1683
2025-10-24 14:21:16.0414 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1519/1683
2025-10-24 14:21:16.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1520/1683
2025-10-24 14:21:16.0415 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1521/1683
2025-10-24 14:21:16.0416 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1522/1683
2025-10-24 14:21:16.0417 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1523/1683
2025-10-24 14:21:16.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1524/1683
2025-10-24 14:21:16.0418 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1525/1683
2025-10-24 14:21:16.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1526/1683
2025-10-24 14:21:16.0419 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1527/1683
2025-10-24 14:21:16.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1528/1683
2025-10-24 14:21:16.0420 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1529/1683
2025-10-24 14:21:16.0421 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1530/1683
2025-10-24 14:21:16.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1531/1683
2025-10-24 14:21:16.0422 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1532/1683
2025-10-24 14:21:16.0423 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1533/1683
2025-10-24 14:21:16.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1534/1683
2025-10-24 14:21:16.0424 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1535/1683
2025-10-24 14:21:16.0425 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1536/1683
2025-10-24 14:21:16.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1537/1683
2025-10-24 14:21:16.0426 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1538/1683
2025-10-24 14:21:16.0427 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1539/1683
2025-10-24 14:21:16.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1540/1683
2025-10-24 14:21:16.0428 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1541/1683
2025-10-24 14:21:16.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1542/1683
2025-10-24 14:21:16.0429 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1543/1683
2025-10-24 14:21:16.0430 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1544/1683
2025-10-24 14:21:16.0431 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1545/1683
2025-10-24 14:21:16.0432 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1546/1683
2025-10-24 14:21:16.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1547/1683
2025-10-24 14:21:16.0433 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1548/1683
2025-10-24 14:21:16.0434 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1549/1683
2025-10-24 14:21:16.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1550/1683
2025-10-24 14:21:16.0435 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1551/1683
2025-10-24 14:21:16.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1552/1683
2025-10-24 14:21:16.0436 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1553/1683
2025-10-24 14:21:16.0437 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1554/1683
2025-10-24 14:21:16.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1555/1683
2025-10-24 14:21:16.0438 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1556/1683
2025-10-24 14:21:16.0439 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1557/1683
2025-10-24 14:21:16.0440 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1558/1683
2025-10-24 14:21:16.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1559/1683
2025-10-24 14:21:16.0441 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1560/1683
2025-10-24 14:21:16.0442 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1561/1683
2025-10-24 14:21:16.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1562/1683
2025-10-24 14:21:16.0443 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1563/1683
2025-10-24 14:21:16.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1564/1683
2025-10-24 14:21:16.0444 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1565/1683
2025-10-24 14:21:16.0445 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1566/1683
2025-10-24 14:21:16.0446 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1567/1683
2025-10-24 14:21:16.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1568/1683
2025-10-24 14:21:16.0447 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1569/1683
2025-10-24 14:21:16.0448 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1570/1683
2025-10-24 14:21:16.0449 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1571/1683
2025-10-24 14:21:16.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1572/1683
2025-10-24 14:21:16.0450 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1573/1683
2025-10-24 14:21:16.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1574/1683
2025-10-24 14:21:16.0451 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1575/1683
2025-10-24 14:21:16.0452 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1576/1683
2025-10-24 14:21:16.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1577/1683
2025-10-24 14:21:16.0453 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1578/1683
2025-10-24 14:21:16.0454 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1579/1683
2025-10-24 14:21:16.0455 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1580/1683
2025-10-24 14:21:16.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1581/1683
2025-10-24 14:21:16.0456 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1582/1683
2025-10-24 14:21:16.0457 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1583/1683
2025-10-24 14:21:16.0458 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1584/1683
2025-10-24 14:21:16.0459 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1585/1683
2025-10-24 14:21:16.0460 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1586/1683
2025-10-24 14:21:16.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1587/1683
2025-10-24 14:21:16.0461 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1588/1683
2025-10-24 14:21:16.0462 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1589/1683
2025-10-24 14:21:16.0463 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1590/1683
2025-10-24 14:21:16.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1591/1683
2025-10-24 14:21:16.0464 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1592/1683
2025-10-24 14:21:16.0465 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1593/1683
2025-10-24 14:21:16.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1594/1683
2025-10-24 14:21:16.0466 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1595/1683
2025-10-24 14:21:16.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1596/1683
2025-10-24 14:21:16.0467 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1597/1683
2025-10-24 14:21:16.0468 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1598/1683
2025-10-24 14:21:16.0469 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1599/1683
2025-10-24 14:21:16.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1600/1683
2025-10-24 14:21:16.0470 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1601/1683
2025-10-24 14:21:16.0471 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1602/1683
2025-10-24 14:21:16.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1603/1683
2025-10-24 14:21:16.0472 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1604/1683
2025-10-24 14:21:16.0473 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1605/1683
2025-10-24 14:21:16.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1606/1683
2025-10-24 14:21:16.0474 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1607/1683
2025-10-24 14:21:16.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1608/1683
2025-10-24 14:21:16.0475 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1609/1683
2025-10-24 14:21:16.0476 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1610/1683
2025-10-24 14:21:16.0477 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1611/1683
2025-10-24 14:21:16.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1612/1683
2025-10-24 14:21:16.0478 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1613/1683
2025-10-24 14:21:16.0479 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1614/1683
2025-10-24 14:21:16.0479 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1615/1683
2025-10-24 14:21:16.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1616/1683
2025-10-24 14:21:16.0480 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1617/1683
2025-10-24 14:21:16.0481 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1618/1683
2025-10-24 14:21:16.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1619/1683
2025-10-24 14:21:16.0482 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1620/1683
2025-10-24 14:21:16.0483 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1621/1683
2025-10-24 14:21:16.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1622/1683
2025-10-24 14:21:16.0484 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1623/1683
2025-10-24 14:21:16.0485 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1624/1683
2025-10-24 14:21:16.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1625/1683
2025-10-24 14:21:16.0486 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1626/1683
2025-10-24 14:21:16.0487 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1627/1683
2025-10-24 14:21:16.0488 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1628/1683
2025-10-24 14:21:16.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1629/1683
2025-10-24 14:21:16.0489 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1630/1683
2025-10-24 14:21:16.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1631/1683
2025-10-24 14:21:16.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1632/1683
2025-10-24 14:21:16.0491 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1633/1683
2025-10-24 14:21:16.0492 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1634/1683
2025-10-24 14:21:16.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1635/1683
2025-10-24 14:21:16.0493 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1636/1683
2025-10-24 14:21:16.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1637/1683
2025-10-24 14:21:16.0494 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1638/1683
2025-10-24 14:21:16.0495 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1639/1683
2025-10-24 14:21:16.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1640/1683
2025-10-24 14:21:16.0496 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1641/1683
2025-10-24 14:21:16.0497 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1642/1683
2025-10-24 14:21:16.0498 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1643/1683
2025-10-24 14:21:16.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1644/1683
2025-10-24 14:21:16.0499 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1645/1683
2025-10-24 14:21:16.0500 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1646/1683
2025-10-24 14:21:16.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1647/1683
2025-10-24 14:21:16.0501 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1648/1683
2025-10-24 14:21:16.0502 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1649/1683
2025-10-24 14:21:16.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1650/1683
2025-10-24 14:21:16.0503 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1651/1683
2025-10-24 14:21:16.0504 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1652/1683
2025-10-24 14:21:16.0505 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1653/1683
2025-10-24 14:21:16.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1654/1683
2025-10-24 14:21:16.0506 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1655/1683
2025-10-24 14:21:16.0507 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1656/1683
2025-10-24 14:21:16.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1657/1683
2025-10-24 14:21:16.0508 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1658/1683
2025-10-24 14:21:16.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1659/1683
2025-10-24 14:21:16.0509 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1660/1683
2025-10-24 14:21:16.0510 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1661/1683
2025-10-24 14:21:16.0511 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1662/1683
2025-10-24 14:21:16.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1663/1683
2025-10-24 14:21:16.0512 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1664/1683
2025-10-24 14:21:16.0513 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1665/1683
2025-10-24 14:21:16.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1666/1683
2025-10-24 14:21:16.0514 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1667/1683
2025-10-24 14:21:16.0515 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1668/1683
2025-10-24 14:21:16.0516 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1669/1683
2025-10-24 14:21:16.0517 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1670/1683
2025-10-24 14:21:16.0517 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1671/1683
2025-10-24 14:21:16.0518 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1672/1683
2025-10-24 14:21:16.0519 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1673/1683
2025-10-24 14:21:16.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1674/1683
2025-10-24 14:21:16.0520 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1675/1683
2025-10-24 14:21:16.0521 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1676/1683
2025-10-24 14:21:16.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1677/1683
2025-10-24 14:21:16.0522 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1678/1683
2025-10-24 14:21:16.0523 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1679/1683
2025-10-24 14:21:16.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1680/1683
2025-10-24 14:21:16.0524 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1681/1683
2025-10-24 14:21:16.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1682/1683
2025-10-24 14:21:16.0525 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1683/1683
2025-10-24 14:21:16.0883 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2025-10-24 14:21:16.0884 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2025-10-24 14:21:16.0887 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2025-10-24 14:21:16.0888 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2025-10-24 14:21:16.0899 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-24 14:21:16.0945 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2025-10-24 14:21:16.0946 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2025-10-24 14:21:16.0950 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2025-10-24 14:21:16.0950 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2025-10-24 14:21:17.0078 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at /home/gcw3/technipfmc_safety/graphRAG/cache/extract_graph
2025-10-24 14:21:33.0423 - INFO - graphrag.logger.progress - extract graph progress: 1/1956
2025-10-24 14:21:40.0242 - INFO - graphrag.logger.progress - extract graph progress: 2/1956
2025-10-24 14:21:50.0112 - INFO - graphrag.logger.progress - extract graph progress: 3/1956
2025-10-24 14:22:01.0850 - INFO - graphrag.logger.progress - extract graph progress: 4/1956
2025-10-24 14:22:01.0855 - INFO - graphrag.logger.progress - extract graph progress: 5/1956
2025-10-24 14:22:01.0858 - INFO - graphrag.logger.progress - extract graph progress: 6/1956
2025-10-24 14:22:16.0265 - INFO - graphrag.logger.progress - extract graph progress: 7/1956
2025-10-24 14:22:16.0271 - INFO - graphrag.logger.progress - extract graph progress: 8/1956
2025-10-24 14:22:29.0492 - INFO - graphrag.logger.progress - extract graph progress: 9/1956
2025-10-24 14:22:45.0452 - INFO - graphrag.logger.progress - extract graph progress: 10/1956
2025-10-24 14:22:45.0456 - INFO - graphrag.logger.progress - extract graph progress: 11/1956
2025-10-24 14:22:45.0458 - INFO - graphrag.logger.progress - extract graph progress: 12/1956
2025-10-24 14:23:08.0714 - INFO - graphrag.logger.progress - extract graph progress: 13/1956
2025-10-24 14:23:08.0718 - INFO - graphrag.logger.progress - extract graph progress: 14/1956
2025-10-24 14:23:08.0720 - INFO - graphrag.logger.progress - extract graph progress: 15/1956
